<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ying的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://ying-zhang.github.io/"/>
  <updated>2018-12-01T16:51:36.293Z</updated>
  <id>https://ying-zhang.github.io/</id>
  
  <author>
    <name>Ying ZHANG</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>DDIA中文版上架了</title>
    <link href="https://ying-zhang.github.io/yi/2018/DDIA_ch9/"/>
    <id>https://ying-zhang.github.io/yi/2018/DDIA_ch9/</id>
    <published>2018-11-30T16:00:00.000Z</published>
    <updated>2018-12-01T16:51:36.293Z</updated>
    
    <content type="html"><![CDATA[<p>《设计数据密集型应用（影印版）Designing data-intensive applications》，中文版是《数据密集型应用系统设计》。<br>这本书9月份就由中国电力出版社出版了。因为我习惯在互动出版网浏览新书，而它没有跟中国电力出版社合作，所以最近才发现。</p><a id="more"></a><hr><blockquote><p>在买影印版之前，我已经从PDF文件读了几章。影印版到手后，从头至尾通读了一遍。<br>PDF很早就泄露出来了，一直关注何时中文版上架。寒假前还尝试联系几家出版社，看看能不能参与翻译。结果收到的答复是已经有出版社着手翻译了，但不知是哪家。<br>于是静候。又怕落到不靠谱的译者手里，所以想试着翻译一点，选了第9章，主要是因为这章偏理论，此外还有一段关于CAP理论（定理）的评价。译了三四天，进展太慢，到 “图 9-4” 就搁置（放弃）了。我是先把PDF转成纯文本，然后粘到 Google 翻译，之后再修订。Google 翻译的质量很高了，但有一些比较绕的句子，也不太容易修订通顺。还有就是一些名词，Google 翻译也能比较准确的翻译一些名词，当然还是有需要修订的。比如 Linearizability，会被翻译为 <strong>线性化</strong>，我则译为 <strong>线性一致性</strong>； Leader 都译为主节点；Quorum 是一个比较头疼的词，译成 <strong>法定人数</strong> 太长了，又没有找到两三个字的词。</p><p>收到中文版后，对照了一下第9章，总体来说翻译质量还可以吧，毕竟自己体会到翻译一本书的困难了。<br>下面是自己几个月前翻译的那点儿，感兴趣的读者可以比较一下。<br>另外放上 DDIA 的 <a href="/doc/DDIA_ch9.pdf">第9章原文</a></p></blockquote><hr><p>此外，还想引用一下书中 Alan Kay 的一段话（接受美国Dr. Dobb 杂志采访，2012）</p><blockquote><p>在我看来，计算机技术是一种流行文化。流行文化只在乎认同感和参与感，活在当下，从不关心合作、过去或未来。我认为大部分为金钱而编写代码的人也是如此。他们不了解他们的文化来自哪里。</p></blockquote><hr><h1 id="第9章-一致性和共识"><a href="#第9章-一致性和共识" class="headerlink" title="第9章 一致性和共识"></a>第9章 一致性和共识</h1><blockquote><p>是要错误地活着，还是正确地死去?<br>—— Jay Kreps, 关于Kafka 和Jepsen的若干说明 (2013)</p></blockquote><p>正如第8章所讨论的，分布式系统中可能会出现很多故障。处理这些故障最简单的方法是直接让整个服务失效，并向用户显示错误信息。如果无法接受这个解决方案，我们需要找到一些方法来容忍错误，即某些内部组件出现故障时仍能保持服务正常运行。</p><p>我们将在本章讨论一些示例算法和协议，来构建容错的分布式系统。我们将假定第8章中的所有故障都有可能发生: 数据包可能丢失、乱序、重复或在网络上延迟任意时间; 时钟是近似的; 节点可以在任意时刻停顿 (例如，发生了内存垃圾收集) 或崩溃。</p><p>构建容错系统最好的方法是找到一些可以提供若干有用保证（Guarantee）的通用抽象。一旦实现了这些抽象，就可以基于其上构建应用程序，获得相应的保证。这与我们在第7章中关于事务的思路相同: 通过使用事务，应用程序可以假装没有崩溃 (原子性)，没有其他人同时访问数据库 (隔离)，并且存储设备是绝对可靠的 (持久性)。即使发生了崩溃、竞态条件和磁盘故障，事务抽象也会屏蔽这些问题，应用程序无需操心。</p><p>现在我们沿着这个思路，寻求能够让应用程序忽略分布式系统中某些故障的抽象。例如，分布式系统中最重要的抽象之一是 <strong>共识（Consensus）</strong> ：即让所有的节点都达成一致意见。我们将在本章发现，在网络故障及进程故障的情况下，可靠地达成共识是非常棘手的。</p><p>一旦实现了共识算法，应用程序就可以将其用于多种目的。例如，对单主多副本的数据库，如果主节点宕机了，需要故障转移到另一个节点。其余节点可以用共识算法来选出新的主节点。正如第5章“处理节点宕机”(第156页)中讨论的，被所有节点都认可的主节点仅有一个是很重要的。如果有两个节点都分别认为自己是主节点，这种情况称为脑裂，经常导致数据丢失。正确实现的共识算法有助于避免此类问题。</p><p>在本章的“分布式事务和共识”小节（第352页），我们将研究解决共识问题的算法以及相关的问题。不过我们首先需要探究分布式系统中可以提供哪些抽象，以及何种程度的保证。</p><p>我们需要了解哪些事情是可行的，哪些是不可行的: 某些情况下，系统可以容忍故障并继续工作; 在其它情况下则是不可能的。理论和实践已经深入探索了可能和不可能的界限。我们将在本章概述这些根本限制。</p><p>这些主题已经在分布式系统领域研究了几十年，因此有很多资料 —— 我们只能介绍一点皮毛。本书无法详细介绍形式模型和证明的细节，我们将采用非正式的直观介绍。如果你感兴趣，参考文献提供了大量的深入内容。</p><h2 id="一致性保证"><a href="#一致性保证" class="headerlink" title="一致性保证"></a>一致性保证</h2><p>在第5章的“副本滞后问题”小节（第161页），我们讨论了多副本数据库中发生的一些时序问题。如果在同一时刻查看两个数据库节点，那么你可能会在这两个节点看到不同的数据，因为写入请求到达这两个节点的时刻可能是不同的。无论数据库使用哪种复制方法（单个主节点，多个主节点或无主节点），不一致的情况都可能出现。</p><p>大多数多副本数据库至少都提供了 <strong>最终一致性</strong>（Eventual consistency）。这意味着，如果你停止数据库写入操作并等待一段不确定的时间，那么最终所有读请求都会返回相同的值[1]。换句话说，不一致是暂时的，最终会自行化解（假设网络中的任何故障最终都会修复）。将最终一致性称为 <strong>收敛性</strong> （Convergence）可能更合适，因为我们预料所有的副本最终会收敛到相同的值[2]。</p><p>然而，这是一个非常弱的保证 —— 它没有说 <strong>什么时候</strong> 副本将收敛。在收敛之前，读操作可能会返回任何值或空值[1]。例如，如果你写了一个值，然后立即再次读取，则不能保证你能看到刚写入的值，因为读取可能会被转发到不同的副本（请参阅第5章的“写后读Reading Your Own Writes”，第152页 ）。</p><p>最终一致性对于应用程序开发人员来说很难，因为它与普通单线程程序中变量的行为有很大不同。如果将值赋给一个变量，稍后再读取它，单线程的程序不会读到旧值或读取失败。表面上看数据库像是可以读写的变量，但事实上它的语义要复杂的多[3]。</p><p>使用仅提供较弱保证的数据库时，你需要时刻了解其局限性，而不是无意中做了太多假设。涉及的错误通常很微妙的，很难通过测试发现，因为应用程序在大多数情况下可能运行良好。当系统遇到故障（例如网络中断）或高并发时，最终一致性的特例才会显现出来。</p><p>在本章中，我们将探讨数据系统可能提供的更强的一致性模型。更强的一致性不是没有成本的：与较弱保证的系统相比，系统性能可能更差或容错性更低。尽管如此，更强大的保证可能更具吸引力，因为它们更容易正确使用。了解了几种不同的一致性模型后，你将能更好地决定哪一种最适合你的需求。</p><p>分布式一致性模型与我们先前讨论的事务隔离级别的层次结构有一些相似之处[4，5]（请参见第7章“弱隔离级别”，第233页）。虽然存在一些重叠，但它们关注的是不同的方面：事务隔离主要是为了避免由于并发执行事务而导致的竞态，而分布式一致性主要是在延迟和故障时协调副本的状态。</p><p>本章涵盖了范围广泛的主题，但我们将会看到，这些领域实际上是有深刻联系的：</p><ul><li>我们首先介绍通常用到的最强的一致性模型，线性一致性（Linearizability），并讨论其优缺点。</li><li>然后，我们将讨论分布式系统中事件顺序的问题（“顺序保证”，第319页），特别是关于因果序和全序的问题。</li><li>在第三部分（“分布式事务和共识”，第352页），我们将探讨如何原子的提交分布式事务，这将最终引导我们找到共识问题的解决方案。</li></ul><h2 id="线性一致性"><a href="#线性一致性" class="headerlink" title="线性一致性"></a>线性一致性</h2><p>在提供最终一致性的数据库中，如果你同时对两个不同的副本发起同一个查询，可能会得到两个不同的答案。这让人迷惑。如果数据库能够让人感觉只有一个副本（即只有一份数据），那么不就简单多了？这样每个客户端都会有相同的数据视图，并且不必担心副本滞后。</p><p>这就是 <strong>线性一致性</strong> （linearizability）[6]的想法（也称为 <strong>原子一致性</strong> （atomic consistency）[7]，<strong>强一致性</strong> （strong consistency），<strong>即时一致性</strong> （immediate consistency）或 <strong>外部一致性</strong> （external consistency）[8]）。线性一致性的准确定义涉及很多细节，我们将用这一小节来探讨。但基本的想法是让系统看起来好像只有一个数据副本，并且其上的所有操作都是原子的。有了这个保证，尽管实际上可能有多个副本，应用程序也不需要操心它们。</p><p>在可线性化的系统中，只要客户端成功完成写入，所有从数据库进行读取的客户端必须能够看到刚写入的值。保持数据单一副本的假象意味着保证读取到的值是最新的值，不是来自陈旧的缓存或副本。换句话说，线性一致性是对 <strong>新近性</strong> （recency）的保证。为了说明情况，我们来看一个非线性一致系统的例子。</p><p>&lt;图 9-1.&gt; 非线性一致的系统，导致了球迷的困惑</p><p>图9-1显示了一个非线性一致的体育网站的例子[9]。Alice和Bob正坐在同一个房间里，他们都在各自的手机查看2014年FIFA世界杯决赛的结果。在最后比分公布后，Alice刷新页面，看到已经宣布了获胜队，并兴奋地告诉Bob。Bob难以置信地刷新自己的手机，但是他的请求被发送到一个滞后的数据库副本，结果他的手机显示比赛还没结束。</p><p>如果Alice和Bob在同一时刻刷新页面，但获得了两个不同的查询结果，那么还不那么令人惊讶，因为他们不确定服务器先处理的哪个请求。然而，Bob明明知道他是在听到Alice对最后比分的欢呼之后才点击了刷新按钮（发起了他的查询），因此他期望他的查询结果至少与Alice一样新。他的查询返回旧结果的这个事实违反了线性一致性。</p><h3 id="什么使系统可线性化？-What-Makes-a-System-Linearizable"><a href="#什么使系统可线性化？-What-Makes-a-System-Linearizable" class="headerlink" title="什么使系统可线性化？ What Makes a System Linearizable?"></a>什么使系统可线性化？ What Makes a System Linearizable?</h3><p>线性一致性背后的基本思想很简单：使系统看起来好像只有一个数据副本。然而，需要仔细考虑才能精确地说明其涵义。为了更好地理解线性一致性，让我们多看几个例子。</p><p>图9-2显示了三个客户端同时在可线性化数据库中读写相同的键 <script type="math/tex">x</script>。在分布式系统论文中，<script type="math/tex">x</script> 被称为寄存器（register） —— 实际上，它可以是键值存储中的一个键，关系数据库中的一行或文档数据库中的一个文档。</p><p>&lt;图 9-2.&gt; 如果读取请求与写入请求是并发的，那么旧值或新值都可能被返回。</p><p>简单起见，图9-2仅显示了来自客户端的请求，不考虑数据库。每段横条都是客户端发出的请求，首端是发出请求的时间，末端是客户端收到响应的时间。由于不定的网络延迟，客户端无法确定数据库何时处理其请求 —— 只知道必定是从发出请求到接收响应这段时间之内处理的。（脚注：图中一个微妙的细节是，假定存在着一个以水平轴表示的全局时钟。尽管真实系统通常没有准确的时钟（请参阅第8章“不可靠的时钟”，第287页），但这种假设是可行的：为了分析分布式算法，我们可以假设存在精确的全局时钟，只要算法不使用它即可[47]。算法只能看到由石英晶振和NTP产生的近似值。）</p><p>在这个例子中，寄存器有两种类型的操作：</p><ul><li><script type="math/tex">read(x) ⇒ v</script> 表示客户端请求读取寄存器 <script type="math/tex">x</script> 的值，数据库返回值 <script type="math/tex">v</script>。</li><li><script type="math/tex">write(x, v) ⇒ r</script> 表示客户端请求将寄存器 <script type="math/tex">x</script> 赋值为 <script type="math/tex">v</script>，数据库返回响应 <script type="math/tex">r</script>（可以是正常或错误）。</li></ul><p>在图9-2中，<script type="math/tex">x</script> 的初始值为 0，客户端C向其写入1。在写入过程中，客户端A和B反复轮询数据库以读取最新值。A和B可能读到哪些值呢？</p><ul><li>客户端A的第一个读取操作在C写入开始之前就完成了，因此必须返回旧值0。</li><li>客户端A最后的读操作在C写入完成后才开始，所以如果数据库是线性一致的，它肯定必须返回新的值1：我们知道具体的写入必然是在对应请求的开始与结束之间的某个时刻进行处理的，同样具体的读取必然是在对应请求的开始与结束之间的某个时刻进行处理。如果在写入结束后才开始读取，则读取的处理必然晚于写入，因此必须要读到已经写入的新值。</li><li>与写操作有时间重叠的读操作可能会返回0或1，因为我们不知道写操作在处理读操作时是否已经生效。读和写是并发的。</li></ul><p>但是，这还不足以完全描述线性一致性：如果与写操作并发的读操作可能会返回旧值或新值，那么在写操作进行过程中，读进程也可能会看到这个值在旧值和新值之间反复变动。这不是我们所期望的所谓等效于“单一数据副本”的系统。（脚注：与写操作并发读取时可能返回旧值或新值的寄存器称为 <strong>常规寄存器</strong> （regular register）[7, 25]。）</p><p>为了使系统可线性化，我们需要添加另一项约束，如图9-3所示。</p><p>&lt;图 9-3.&gt; 在任一次读取到新值后，任意客户端的后续所有读取也必须返回该新值。</p><p>在一个可线性化的系统中，我们可以想象，在写入操作开始与结束之间，必定存在某个时刻， <script type="math/tex">x</script> 的值原子的从 0 变成 1。因此，如果一个客户端的读取返回新值1，即使写入操作尚未结束（响应尚未返回到对应的客户端），所有后续的读取也必须返回新值。</p><p>图9-3中用箭头表示这种时序依赖。客户端A是第一个读到新值1的。在A的读取返回之后，B开始新的读取。由于B的读取严格在A读取之后发生，因此即使C的写入仍在进行中，数据库也必须返回1。（与图9-1中Alice和Bob的情况相同：在Alice读取新值之后，Bob也希望读取到新值 。）</p><p>我们可以进一步细化这个时序图，显示出每个操作在某个时刻以原子的方式生效。图9-4是一个更复杂的例子[10]。</p><p>在图9-4中，除了读写之外，我们还添加了第三种类型的操作：</p><ul><li><script type="math/tex">CAS(x，v_{old}，v_{new})⇒ r</script> 表示客户端请求原子的 <strong>比较并置位</strong> 操作（请参阅第7章“比较并置位”，第245页）。如果寄存器 <script type="math/tex">x</script> 的当前值等于 <script type="math/tex">v_{old}</script>，则原子地将其值置为 <script type="math/tex">v_{new}</script>。如果 <script type="math/tex">x ≠ v_{old}</script>，则不改变寄存器的值，并返回错误。 <script type="math/tex">r</script> 是数据库的响应（正常或错误）。</li></ul><p>图9-4中的每个操作都用横条内的竖线标记出来了，对应着我们认为操作发生的时刻。这些标记可以顺序排列起来，而且结果必须是一个有效的寄存器读写序列（即每次读取都必须返回最近写入的值）。</p><p>线性一致性的要求是，操作标记排成的队列总是向前移动（从左到右），从不后退。这一要求确保了我们前面提到的新近性的保证：一旦写入或读取了新值，后续都会读到写入的值，直到它再次被覆盖。</p><p>&lt;图 9-4.&gt; 标出读取和写入生效的时刻。B最后的那次读取的是非线性一致的。<br>…</p><h3 id="应用线性一致性-Relying-on-Linearizability"><a href="#应用线性一致性-Relying-on-Linearizability" class="headerlink" title="应用线性一致性 Relying on Linearizability"></a>应用线性一致性 Relying on Linearizability</h3><p>…</p><h4 id="分布式锁和主节点选举-Locking-and-leader-election"><a href="#分布式锁和主节点选举-Locking-and-leader-election" class="headerlink" title="分布式锁和主节点选举 Locking and leader election"></a>分布式锁和主节点选举 Locking and leader election</h4><p>…</p><h4 id="约束和唯一性保证-Constraints-and-uniqueness-guarantees"><a href="#约束和唯一性保证-Constraints-and-uniqueness-guarantees" class="headerlink" title="约束和唯一性保证 Constraints and uniqueness guarantees"></a>约束和唯一性保证 Constraints and uniqueness guarantees</h4><p>…</p><h4 id="跨信道的时序依赖-Cross-channel-timing-dependencies"><a href="#跨信道的时序依赖-Cross-channel-timing-dependencies" class="headerlink" title="跨信道的时序依赖 Cross-channel timing dependencies"></a>跨信道的时序依赖 Cross-channel timing dependencies</h4><p>…</p><h3 id="实现线性一致的系统-Implementing-Linearizable-Systems"><a href="#实现线性一致的系统-Implementing-Linearizable-Systems" class="headerlink" title="实现线性一致的系统 Implementing Linearizable Systems"></a>实现线性一致的系统 Implementing Linearizable Systems</h3><p>…</p><h4 id="线性一致性和-Quorums-Linearizability-and-quorums"><a href="#线性一致性和-Quorums-Linearizability-and-quorums" class="headerlink" title="线性一致性和 Quorums Linearizability and quorums"></a>线性一致性和 Quorums Linearizability and quorums</h4><p>…</p><h3 id="线性一致性的成本-The-Cost-of-Linearizability"><a href="#线性一致性的成本-The-Cost-of-Linearizability" class="headerlink" title="线性一致性的成本 The Cost of Linearizability"></a>线性一致性的成本 The Cost of Linearizability</h3><p>…</p><h4 id="CAP理论-The-CAP-theorem"><a href="#CAP理论-The-CAP-theorem" class="headerlink" title="CAP理论 The CAP theorem"></a>CAP理论 The CAP theorem</h4><p>…</p><blockquote><p>以下是 Google 翻译的内容（<a href="https://translate.google.cn/" target="_blank" rel="noopener">https://translate.google.cn/</a> 没有被墙，可以正常访问）</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">**无益的CAP定理** </span><br><span class="line"></span><br><span class="line">CAP有时表现为一致性，可用性，分区容差：从2中挑选2个。不幸的是，这样做是误导[32]因为网络分区是一种错误，所以它们不是你可以选择的东西：无论你喜欢与否，它们都会发生[38]。</span><br><span class="line">在网络正常工作时，系统可以提供一致性（线性化）和总体可用性。发生网络故障时，您必须在线性化或总可用性之间进行选择。因此，一种更好的表达CAP的方法是在分区时保持一致或可用[39]。一个更可靠的网络需要不经常做出这种选择，但在某些时候，选择是不可避免的。</span><br><span class="line">在CAP的讨论中，对可用性一词有几个相互矛盾的定义，而作为定理的形式化[30]与其通常的含义不相符[40]。许多所谓的“高可用性”（容错）系统实际上不符合CAP对可用性的特殊定义。总而言之，CAP周围存在很多误解和混淆，它无助于我们更好地理解系统，因此最好避免使用CAP。</span><br></pre></td></tr></table></figure><p>正式定义的CAP定理[30]范围非常狭窄：它只考虑一种一致性模型（即线性化）和一种故障（网络分区，或者活着但彼此断开的节点）。它没有说明网络延迟，死节点或其他权衡。因此，虽然CAP在历史上具有影响力，但它对设计系统几乎没有实际价值[9,40]。<br>在分布式系统中有更多有趣的不可能性结果[41]，CAP现在已被更精确的结果所取代[2,42]，因此它在今天主要是历史兴趣。</p><blockquote><p>原文</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">**The Unhelpful CAP Theorem**</span><br><span class="line"></span><br><span class="line">CAP is sometimes presented as Consistency, Availability, Partition tolerance: pick 2 out of 3. Unfortunately, putting it this way is misleading[32] because network partitions are a kind of fault, so they aren’t something about which you have a choice: they will happen whether you like it or not [38].</span><br><span class="line">At times when the network is working correctly, a system can provide both consistency (linearizability) and total availability. When a network fault occurs, you have to choose between either linearizability or total availability. Thus, a better way of phrasing CAP would be either Consistent or Available when Partitioned [39]. A more reliable network needs to make this choice less often, but at some point the choice is inevitable.</span><br><span class="line">In discussions of CAP there are several contradictory definitions of the term availability, and the formalization as a theorem [30] does not match its usual meaning [40]. Many so-called &quot;highly available&quot; (fault-tolerant) systems actually do not meet CAP’s idiosyncratic definition of availability. All in all, there is a lot of misunderstanding and confusion around CAP, and it does not help us understand systems better, so CAP is best avoided.</span><br></pre></td></tr></table></figure><p>The CAP theorem as formally defined [30] is of very narrow scope: it only considers one consistency model (namely linearizability) and one kind of fault (network partitions, or nodes that are alive but disconnected from each other). It doesn’t say anything about network delays, dead nodes, or other trade-offs. Thus, although CAP has been historically influential, it has little practical value for designing systems [9, 40].<br>There are many more interesting impossibility results in distributed systems [41], and CAP has now been superseded by more precise results [2, 42], so it is of mostly historical interest today.</p><h4 id="线性一致性和网络延迟-Linearizability-and-network-delays"><a href="#线性一致性和网络延迟-Linearizability-and-network-delays" class="headerlink" title="线性一致性和网络延迟 Linearizability and network delays"></a>线性一致性和网络延迟 Linearizability and network delays</h4><p>…<br><span>$$</span><!-- Has MathJax --> </p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1]. Peter Bailis and Ali Ghodsi: <strong><a href="http://queue.acm.org/detail.cfm?id=2462076" target="_blank" rel="noopener">“Eventual Consistency Today: Limitations, Extensions, and Beyond”</a></strong>, <em>ACM Queue</em>, vol. 11 no. 3, pp. 55-63 March 2013. <strong><a href="http://dx.doi.org/10.1145/2460276.2462076" target="_blank" rel="noopener">doi:10.1145/2460276.2462076</a></strong><br>[2]. Prince Mahajan, Lorenzo Alvisi, and Mike Dahlin: <strong><a href="http://apps.cs.utexas.edu/tech_reports/reports/tr/TR-2036.pdf" target="_blank" rel="noopener">“Consistency, Availability, and Convergence”</a></strong>, <em>University of Texas at Austin, Department of Computer Science</em>, Tech Report UTCS TR-11-22, May 2011.<br>[3]. Alex Scotti: <strong><a href="http://www.slideshare.net/AlexScotti1/allyourbase-55212398" target="_blank" rel="noopener">“Adventures in Building Your Own Database”</a></strong>, at <em>All Your Base</em>, November 2015.<br>[4]. Peter Bailis, Aaron Davidson, Alan Fekete, et al.: <strong><a href="www.vldb.org/pvldb/vol7/p181-bailis.pdf">“Highly Available Transactions: Virtues and Limitations”</a></strong>, at <em>40th International Conference on Very Large Data Bases (VLDB)</em>, September 2014. Extended version published as <strong><a href="http://arxiv.org/pdf/1302.0309.pdf" target="_blank" rel="noopener">arXiv:1302.0309 [cs.DB]</a></strong>.<br>[5]. Paolo Viotti and Marko Vukolić: <strong><a href="http://arxiv.org/abs/1512.00168" target="_blank" rel="noopener">“Consistency in Non-Transactional Distributed Storage Systems”</a></strong>, arXiv:1512.00168, 12 April 2016.<br>[6]. Maurice P. Herlihy and Jeannette M. Wing: <strong><a href="http://cs.brown.edu/%7Emph/HerlihyW90/p463-herlihy.pdf" target="_blank" rel="noopener">“Linearizability: A Correctness Condition for Concurrent Objects”</a></strong>, <em>ACM Transactions on Programming Languages and Systems (TOPLAS)</em>, vol. 12, no. 3, pp. 463–492, July 1990. <strong><a href="http://dx.doi.org/10.1145/78969.78972" target="_blank" rel="noopener">doi:10.1145/78969.78972</a></strong><br>[7]. Leslie Lamport: <strong><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/On-Interprocess-Communication.pdf" target="_blank" rel="noopener">“On interprocess communication”</a></strong>, <em>Distributed Computing</em>, vol. 1, no. 2, pp. 77–101, June 1986. <strong><a href="http://dx.doi.org/10.1007/BF01786228" target="_blank" rel="noopener">doi:10.1007/BF01786228</a></strong><br>[8]. David K. Gifford: <strong><a href="http://www.mirrorservice.org/sites/www.bitsavers.org/pdf/xerox/parc/techReports/CSL-81-8_Information_Storage_in_a_Decentralized_Computer_System.pdf" target="_blank" rel="noopener">“Information Storage in a Decentralized Computer System”</a></strong>, Xerox Palo Alto Research Centers, CSL-81-8, June 1981.<br>[9]. Martin Kleppmann: <strong><a href="http://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html" target="_blank" rel="noopener">“Please Stop Calling Databases CP or AP”</a></strong>, <em>martin.kleppmann.com</em>, May 11, 2015.<br>[10]. Kyle Kingsbury: <strong><a href="https://aphyr.com/posts/322-call-me-maybe-mongodb-stale-reads" target="_blank" rel="noopener">“Call Me Maybe: MongoDB Stale Reads”</a></strong>, <em>aphyr.com</em>, April 20, 2015.<br>[11]. Kyle Kingsbury: <strong><a href="https://aphyr.com/posts/314-computational-techniques-in-knossos" target="_blank" rel="noopener">“Computational Techniques in Knossos”</a></strong>, <em>aphyr.com</em>, May 17, 2014.<br>[12]. Peter Bailis: <strong><a href="www.bailis.org/blog/linearizability-versus-serializability/">“Linearizability Versus Serializability”</a></strong>, <em>bailis.org</em>, September 24, 2014.<br>[13]. Philip A. Bernstein, Vassos Hadzilacos, and Nathan Goodman: <strong><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/ccontrol.zip" target="_blank" rel="noopener">“Concurrency Control and Recovery in Database Systems”</a></strong>, Addison-Wesley, 1987. ISBN: 978-0-201-10715-9, available online at research.microsoft.com.<br>[14]. Mike Burrows: <strong><a href="http://research.google.com/archive/chubby.html" target="_blank" rel="noopener">“The Chubby Lock Service for Loosely-Coupled Distributed Systems”</a></strong>, at <em>7th USENIX Symposium on Operating System Design and Implementation (OSDI)</em>, November 2006.<br>[15]. Flavio P. Junqueira and Benjamin Reed: <em>“ZooKeeper: Distributed Process Coordination”</em>, O’Reilly Media, 2013. ISBN: 978-1-449-36130-3<br>[16]. <em>“etcd 2.0.12 Documentation”</em>, CoreOS, Inc., 2015.<br>[17]. <strong><a href="curator.apache.org">“Apache Curator”</a></strong>, Apache Software Foundation, <em>curator.apache.org</em>, 2015.<br>[18]. Morali Vallath: <em>“Oracle 10g RAC Grid, Services &amp; Clustering”</em>, Elsevier Digital Press, 2006. ISBN: 978-1-555-58321-7<br>[19]. Peter Bailis, Alan Fekete, Michael J Franklin et al.: <strong><a href="http://arxiv.org/pdf/1402.2237.pdf" target="_blank" rel="noopener">“Coordination-Avoiding Database Systems”</a></strong>, <em>Proceedings of the VLDB Endowment</em>, vol. 8, no. 3, pp. 185–196, November 2014 also at arxiv:1402.2237.<br>[20]. Kyle Kingsbury: <strong><a href="https://aphyr.com/posts/316-call-me-maybe-etcd-and-consul" target="_blank" rel="noopener">“Call Me Maybe: etcd and Consul”</a></strong>, <em>aphyr.com</em>, June 9, 2014.<br>[21]. Flavio P. Junqueira, Benjamin C. Reed, and Marco Serafini: <strong><a href="https://pdfs.semanticscholar.org/b02c/6b00bd5dbdbd951fddb00b906c82fa80f0b3.pdf" target="_blank" rel="noopener">“Zab: High- Performance Broadcast for Primary-Backup Systems”</a></strong>, at <em>41st IEEE International Conference on Dependable Systems and Networks (DSN)</em>, June 2011. <strong><a href="http://dx.doi.org/10.1109/DSN.2011.5958223" target="_blank" rel="noopener">doi:10.1109/DSN.2011.5958223</a></strong><br>[22]. Diego Ongaro and John K. Ousterhout: <strong><a href="http://ramcloud.stanford.edu/raft.pdf" target="_blank" rel="noopener">“In Search of an Understandable Consensus Algorithm (Extended Version)”</a></strong>, at <em>USENIX Annual Technical Conference (ATC)</em>, June 2014.<br>[23]. Hagit Attiya, Amotz Bar-Noy, and Danny Dolev: <strong><a href="http://www.cse.huji.ac.il/course/2004/dist/p124-attiya.pdf" target="_blank" rel="noopener">“Sharing Memory Robustly in Message-Passing Systems”</a></strong>, <em>Journal of the ACM</em>, vol. 42, no. 1, pp. 124 – 142, January 1995. <strong><a href="http://dx.doi.org/10.1145/200836.200869" target="_blank" rel="noopener">doi:10.1145/200836.200869</a></strong><br>[24]. Nancy Lynch and Alex Shvartsman: <strong><a href="http://groups.csail.mit.edu/tds/papers/Lynch/FTCS97.pdf" target="_blank" rel="noopener">“Robust Emulation of Shared Memory Using Dynamic Quorum-Acknowledged Broadcasts”</a></strong>, at <em>27th Annual International Symposium on Fault-Tolerant Computing (FTCS)</em>, June 1997. <strong><a href="http://dx.doi.org/10.1109/FTCS.1997.614100" target="_blank" rel="noopener">doi:10.1109/FTCS.1997.614100</a></strong><br>[25]. Christian Cachin, Rachid Guerraoui, and Luís Rodrigues: <em>“Introduction to Reliable and Secure Distributed Programming, 2nd edition”</em>, Springer, 2011. ISBN: 978-3-642-15259-7,  <strong><a href="http://dx.doi.org/10.1007/978-3-642-15260-3" target="_blank" rel="noopener">doi:10.1007/978-3-642-15260-3</a></strong><br>[26]. Sam Elliott, Mark Allen, and Martin Kleppmann: <strong><a href="https://twitter.com/lenary/status/654761711933648896" target="_blank" rel="noopener">“Personal Communication”</a></strong>, thread on <em>twitter.com</em>, October 15, 2015.<br>[27]. Niklas Ekström, Mikhail Panchenko, and Jonathan Ellis: <strong><a href="http://mail-archives.apache.org/mod_mbox/cassandra-dev/201210.mbox/%3CFA480D1DC3964E2C8B0A14E0880094C9%40Robotech%3E" target="_blank" rel="noopener">“Possible Issue with Read Repair?”</a></strong>, email thread on <em>cassandra-dev</em> mailing list, October 2012.<br>[28]. Maurice P. Herlihy: <strong><a href="https://cs.brown.edu/%7Emph/Herlihy91/p124-herlihy.pdf" target="_blank" rel="noopener">“Wait-Free Synchronization”</a></strong>, <em>ACM Transactions on Programming Languages and Systems (TOPLAS)</em>, vol. 13, no. 1, pp. 124–149, January 1991. <strong><a href="http://dx.doi.org/10.1145/114005.102808" target="_blank" rel="noopener">doi:10.1145/114005.102808</a></strong><br>[29]. Armando Fox and Eric A. Brewer: <strong><a href="http://radlab.cs.berkeley.edu/people/fox/static/pubs/pdf/c18.pdf" target="_blank" rel="noopener">“Harvest, Yield, and Scalable Tolerant Systems”</a></strong>, at <em>7th Workshop on Hot Topics in Operating Systems (HotOS)</em>, March 1999. <strong><a href="http://dx.doi.org/10.1109/HOTOS.1999.798396" target="_blank" rel="noopener">doi:10.1109/HOTOS.1999.798396</a></strong><br>[30]. Seth Gilbert and Nancy Lynch: <strong><a href="http://www.comp.nus.edu.sg/%7Egilbert/pubs/BrewersConjecture-SigAct.pdf" target="_blank" rel="noopener">“Brewer’s Conjecture and the Feasibility of Consistent, Available, Partition-Tolerant Web Services”</a></strong>, <em>ACM SIGACT News</em>, vol. 33, no. 2, pp. 51–59, June 2002. <strong><a href="http://dx.doi.org/10.1145/564585.564601" target="_blank" rel="noopener">doi:10.1145/564585.564601</a></strong><br>[31]. Seth Gilbert and Nancy Lynch: <em>“Perspectives on the CAP Theorem”</em>, <em>IEEE Computer Magazine</em>, vol. 45, no. 2, pp. 30–36, February 2012. <strong><a href="http://dx.doi.org/10.1109/MC.2011.389" target="_blank" rel="noopener">doi:10.1109/MC.2011.389</a></strong><br>[32]. Eric A. Brewer: <strong><a href="http://cs609.cs.ua.edu/CAP12.pdf" target="_blank" rel="noopener">“CAP Twelve Years Later: How the ‘Rules’ Have Changed”</a></strong>, <em>IEEE Computer Magazine</em>, vol. 45, no. 2, pp. 23–29, February 2012. <strong><a href="http://dx.doi.org/10.1109/MC.2012.37" target="_blank" rel="noopener">doi:10.1109/MC.2012.37</a></strong><br>[33]. Susan B. Davidson, Hector Garcia-Molina, and Dale Skeen: <strong><a href="http://delab.csd.auth.gr/%7Edimitris/courses/mpc_fall05/papers/invalidation/acm_csur85_partitioned_network_consistency.pdf" target="_blank" rel="noopener">“Consistency in Partitioned Networks”</a></strong>, <em>ACM Computing Surveys</em>, vol. 17, no. 3, pp. 341–370, September 1985. <strong><a href="http://dx.doi.org/10.1145/5505.5508" target="_blank" rel="noopener">doi:10.1145/5505.5508</a></strong><br>[34]. Paul R. Johnson and Robert H. Thomas: <strong><a href="https://tools.ietf.org/html/rfc677" target="_blank" rel="noopener">“RFC 677: The Maintenance of Duplicate Databases”</a></strong>, Network Working Group, January 27, 1975.<br>[35]. Bruce G. Lindsay, Patricia Griffiths Selinger, C. Galtieri, et al.: <strong><a href="http://domino.research.ibm.com/library/cyberdig.nsf/papers/A776EC17FC2FCE73852579F100578964/%24File/RJ2571.pdf" target="_blank" rel="noopener">“Notes on Distributed Databases”</a></strong>, IBM Research, Research Report RJ2571(33471), July 1979.<br>[36]. Michael J. Fischer and Alan Michael: <strong><a href="http://www.cs.ucsb.edu/%7Eagrawal/spring2011/ugrad/p70-fischer.pdf" target="_blank" rel="noopener">“Sacrificing Serializability to Attain High Availability of Data in an Unreliable Network”</a></strong>, at <em>1st ACM Symposium on Principles of Database Systems (PODS)</em>, March 1982. <strong><a href="http://dx.doi.org/10.1145/588111.588124" target="_blank" rel="noopener">doi:10.1145/588111.588124</a></strong><br>[37]. Eric A. Brewer: <strong><a href="https://www.infoq.com/presentations/NoSQL-History" target="_blank" rel="noopener">“NoSQL: Past, Present, Future”</a></strong>, at <em>QCon San Francisco</em>, November 2012.<br>[38]. Henry Robinson: <strong><a href="http://blog.cloudera.com/blog/2010/04/cap-confusion-problems-with-partition-tolerance/" target="_blank" rel="noopener">“CAP Confusion: Problems with ‘Partition Tolerance’”</a></strong>, <em>blog.cloudera.com</em>, April 26, 2010.<br>[39]. Adrian Cockcroft: <strong><a href="http://www.infoq.com/presentations/migration-cloud-native" target="_blank" rel="noopener">“Migrating to Microservices”</a></strong>, at <em>QCon London</em>, March 2014.<br>[40]. Martin Kleppmann: <strong><a href="http://arxiv.org/pdf/1509.05393.pdf" target="_blank" rel="noopener">“A Critique of the CAP Theorem”</a></strong>, arXiv:1509.05393, September 17, 2015.<br>[41]. Nancy A. Lynch: <strong><a href="http://groups.csail.mit.edu/tds/papers/Lynch/podc89.pdf" target="_blank" rel="noopener">“A Hundred Impossibility Proofs for Distributed Computing”</a></strong>, at <em>8th ACM Symposium on Principles of Distributed Computing (PODC)</em>, August 1989. <strong><a href="http://dx.doi.org/10.1145/72981.72982" target="_blank" rel="noopener">doi:10.1145/72981.72982</a></strong><br>[42]. Hagit Attiya, Faith Ellen, and Adam Morrison: <strong><a href="http://www.cs.technion.ac.il/people/mad/online-publications/podc2015-replds.pdf" target="_blank" rel="noopener">“Limitations of Highly-Available Eventually-Consistent Data Stores”</a></strong>, at <em>ACM Symposium on Principles of Distributed Computing (PODC)</em>, July 2015. <strong><a href="http://dx.doi.org/10.1145/2767386.2767419" target="_blank" rel="noopener">doi:10.1145/2767386.2767419</a></strong><br>[43]. Peter Sewell, Susmit Sarkar, Scott Owens, et al.: <strong><a href="http://www.cl.cam.ac.uk/%7Epes20/weakmemory/cacm.pdf" target="_blank" rel="noopener">“x86-TSO: A Rigorous and Usable Programmer’s Model for x86 Multiprocessors”</a></strong>, <em>Communications of the ACM</em>, vol. 53, no. 7, pp. 89–97, July 2010. <strong><a href="http://dx.doi.org/10.1145/1785414.1785443" target="_blank" rel="noopener">doi:10.1145/1785414.1785443</a></strong><br>[44]. Martin Thompson: <strong><a href="https://mechanical-sympathy.blogspot.com/2011/07/memory-barriersfences.html" target="_blank" rel="noopener">“Memory Barriers/Fences mechanical”</a></strong>, <em>sympathy.blogspot.co.uk</em>, July 24, 2011.<br>[45]. Ulrich Drepper: <strong><a href="http://www.akkadia.org/drepper/cpumemory.pdf" target="_blank" rel="noopener">“What Every Programmer Should Know About Memory”</a></strong>, <em>akkadia.org</em>, November 21, 2007.<br>[46]. Daniel J. Abadi: <strong><a href="http://cs-www.cs.yale.edu/homes/dna/papers/abadi-pacelc.pdf" target="_blank" rel="noopener">“Consistency Tradeoffs in Modern Distributed Database System Design”</a></strong>, <em>IEEE Computer Magazine</em>, vol. 45, no. 2, pp. 37–42, February 2012. <strong><a href="http://dx.doi.org/10.1109/MC.2012.33" target="_blank" rel="noopener">doi:10.1109/MC.2012.33</a></strong><br>[47]. Hagit Attiya and Jennifer L. Welch: <strong><a href="http://courses.csail.mit.edu/6.852/01/papers/p91-attiya.pdf" target="_blank" rel="noopener">“Sequential Consistency Versus Linearizability”</a></strong>, <em>ACM Transactions on Computer Systems (TOCS)</em>, vol. 12, no. 2, pp. 91–122, May 1994. <strong><a href="http://dx.doi.org/10.1145/176575.176576" target="_blank" rel="noopener">doi:10.1145/176575.176576</a></strong><br>[48]. Mustaque Ahamad, Gil Neiger, James E. Burns, et al.: <strong><a href="http://www-i2.informatik.rwth-aachen.de/i2/fileadmin/user_upload/documents/Seminar_MCMM11/Causal_memory_1996.pdf" target="_blank" rel="noopener">“Causal Memory: Definitions, Implementation, and Programming”</a></strong>, <em>Distributed Computing</em>, vol. 9, no. 1, pp. 37–49, March 1995. <strong><a href="http://dx.doi.org/10.1007/BF01784241" target="_blank" rel="noopener">doi:10.1007/BF01784241</a></strong><br>[49]. Wyatt Lloyd, Michael J. Freedman, Michael Kaminsky, and David G. Andersen: <strong><a href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final149.pdf" target="_blank" rel="noopener">“Stronger Semantics for Low-Latency Geo-Replicated Storage”</a></strong>, at <em>10th USENIX Symposium on Networked Systems Design and Implementation (NSDI)</em>, April 2013.<br>[50]. Marek Zawirski, Annette Bieniusa, Valter Balegas, et al.: <strong><a href="http://arxiv.org/abs/1310.3107" target="_blank" rel="noopener">“SwiftCloud: Fault- Tolerant Geo-Replication Integrated All the Way to the Client Machine”</a></strong>, INRIA Research Report 8347, August 2013.<br>[51]. Peter Bailis, Ali Ghodsi, Joseph M Hellerstein and Ion Stoica: <strong><a href="http://db.cs.berkeley.edu/papers/sigmod13-bolton.pdf" target="_blank" rel="noopener">“Bolt-on Causal Consistency”</a></strong>, at <em>ACM International Conference on Management of Data (SIGMOD)</em>, June 2013.<br>[52]. Philippe Ajoux, Nathan Bronson, Sanjeev Kumar, et al.: <strong><a href="https://www.usenix.org/system/files/conference/hotos15/hotos15-paper-ajoux.pdf" target="_blank" rel="noopener">“Challenges to Adopting Stronger Consistency at Scale”</a></strong>, at <em>15th USENIX Workshop on Hot Topics in Operating Systems (HotOS)</em>, May 2015.<br>[53]. Peter Bailis: <strong><a href="http://www.bailis.org/blog/causality-is-expensive-and-what-to-do-about-it/" target="_blank" rel="noopener">“Causality Is Expensive (and What to Do About It)”</a></strong>, <em>bailis.org</em>, February 5, 2014.<br>[54]. Ricardo Gonçalves, Paulo Sérgio Almeida, Carlos Baquero, and Victor Fonte: <strong><a href="http://haslab.uminho.pt/tome/files/global_logical_clocks.pdf" target="_blank" rel="noopener">“Concise Server-Wide Causality Management for Eventually Consistent Data Stores”</a></strong>, at <em>15th IFIP International Conference on Distributed Applications and Interoperable Systems (DAIS)</em>, June 2015. <strong><a href="http://dx.doi.org/10.1007/978-3-319-19129-4_6" target="_blank" rel="noopener">doi:10.1007/978-3-319-19129-4_6</a></strong><br>[55]. Rob Conery: <strong><a href="http://rob.conery.io/2014/05/29/a-better-id-generator-for-postgresql/" target="_blank" rel="noopener">“A Better ID Generator for PostgreSQL”</a></strong>, <em>rob.conery.io</em>, May 29, 2014.<br>[56]. Leslie Lamport: <strong><a href="http://research.microsoft.com/en-US/um/people/Lamport/pubs/time-clocks.pdf" target="_blank" rel="noopener">“Time, Clocks, and the Ordering of Events in a Distributed System”</a></strong>, <em>Communications of the ACM</em>, vol. 21, no. 7, pp. 558–565, July 1978. <strong><a href="http://dx.doi.org/10.1145/359545.359563" target="_blank" rel="noopener">doi:10.1145/359545.359563</a></strong><br>[57]. Xavier Défago, André Schiper, and Péter Urbán: <strong><a href="https://dspace.jaist.ac.jp/dspace/bitstream/10119/4883/1/defago_et_al.pdf" target="_blank" rel="noopener">“Total Order Broadcast and Multicast Algorithms: Taxonomy and Survey”</a></strong>, <em>ACM Computing Surveys</em>, vol. 36, no. 4, pp. 372–421, December 2004. <strong><a href="http://dx.doi.org/10.1145/1041680.1041682" target="_blank" rel="noopener">doi:10.1145/1041680.1041682</a></strong><br>[58]. Hagit Attiya and Jennifer Welch: <em>“Distributed Computing: Fundamentals, Simulations and Advanced Topics, 2nd edition”</em>, John Wiley &amp; Sons, 2004. ISBN: 978-0-471-45324-6,  <strong><a href="http://dx.doi.org/10.1002/0471478210" target="_blank" rel="noopener">doi:10.1002/0471478210</a></strong><br>[59]. Mahesh Balakrishnan, Dahlia Malkhi, Vijayan Prabhakaran, et al.: <strong><a href="https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final30.pdf" target="_blank" rel="noopener">“CORFU: A Shared Log Design for Flash Clusters”</a></strong>, at <em>9th USENIX Symposium on Networked Systems Design and Implementation (NSDI)</em>, April 2012.<br>[60]. Fred B. Schneider: <strong><a href="http://www.cs.cornell.edu/fbs/publications/smsurvey.pdf" target="_blank" rel="noopener">“Implementing Fault-Tolerant Services Using the State Machine Approach: A Tutorial”</a></strong>, <em>ACM Computing Surveys</em>, vol. 22, no. 4, pp. 299–319, December 1990.<br>[61]. Alexander Thomson, Thaddeus Diamond, Shu-Chun Weng, et al.: <strong><a href="http://cs.yale.edu/homes/thomson/publications/calvin-sigmod12.pdf" target="_blank" rel="noopener">“Calvin: Fast Distributed Transactions for Partitioned Database Systems”</a></strong>, at <em>ACM International Conference on Management of Data (SIGMOD)</em>, May 2012.<br>[62]. Mahesh Balakrishnan, Dahlia Malkhi, Ted Wobber, et al.: <strong><a href="http://research.microsoft.com/pubs/199947/Tango.pdf" target="_blank" rel="noopener">“Tango: Distributed Data Structures over a Shared Log”</a></strong>, at <em>24th ACM Symposium on Operating Systems Principles (SOSP)</em>, November 2013. <strong><a href="http://dx.doi.org/10.1145/2517349.2522732" target="_blank" rel="noopener">doi:10.1145/2517349.2522732</a></strong><br>[63]. Robbert van Renesse and Fred B. Schneider: <strong><a href="http://static.usenix.org/legacy/events/osdi04/tech/full_papers/renesse/renesse.pdf" target="_blank" rel="noopener">“Chain Replication for Supporting High Throughput and Availability”</a></strong>, at <em>6th USENIX Symposium on Operating System Design and Implementation (OSDI)</em>, December 2004.<br>[64]. Leslie Lamport: <strong><a href="http://research-srv.microsoft.com/en-us/um/people/lamport/pubs/multi.pdf" target="_blank" rel="noopener">“How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs”</a></strong>, <em>IEEE Transactions on Computers</em>, vol. 28, no. 9, pp. 690–691, September 1979. <strong><a href="http://dx.doi.org/10.1109/TC.1979.1675439" target="_blank" rel="noopener">doi:10.1109/TC.1979.1675439</a></strong><br>[65]. Enis Söztutar, Devaraj Das, and Carter Shanklin: <strong><a href="http://hortonworks.com/blog/apache-hbase-high-availability-next-level/" target="_blank" rel="noopener">“Apache HBase High Availability at the Next Level”</a></strong>, <em>hortonworks.com</em>, January 22, 2015.<br>[66]. Brian F Cooper, Raghu Ramakrishnan, Utkarsh Srivastava, et al.: <strong><a href="http://www.mpi-sws.org/%7Edruschel/courses/ds/papers/cooper-pnuts.pdf" target="_blank" rel="noopener">“PNUTS: Yahoo!’s Hosted Data Serving Platform”</a></strong>, at <em>34th International Conference on Very Large Data Bases (VLDB)</em>, August 2008. <strong><a href="http://dx.doi.org/10.14778/1454159.1454167" target="_blank" rel="noopener">doi:10.14778/1454159.1454167</a></strong><br>[67]. Tushar Deepak Chandra and Sam Toueg: <strong><a href="http://courses.csail.mit.edu/6.852/08/papers/CT96-JACM.pdf" target="_blank" rel="noopener">“Unreliable Failure Detectors for Reliable Distributed Systems”</a></strong>, <em>Journal of the ACM</em>, vol. 43, no. 2, pp. 225–267, March 1996. <strong><a href="http://dx.doi.org/10.1145/226643.226647" target="_blank" rel="noopener">doi:10.1145/226643.226647</a></strong><br>[68]. Michael J. Fischer, Nancy Lynch, and Michael S. Paterson: <strong><a href="https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf" target="_blank" rel="noopener">“Impossibility of Distributed Consensus with One Faulty Process”</a></strong>, <em>Journal of the ACM</em>, vol. 32, no. 2, pp. 374–382, April 1985. <strong><a href="http://dx.doi.org/10.1145/3149.214121" target="_blank" rel="noopener">doi:10.1145/3149.214121</a></strong><br>[69]. Michael Ben-Or: <strong>“Another Advantage of Free Choice: Completely Asynchronous Agreement Protocols”</strong>, at <em>2nd ACM Symposium on Principles of Distributed Computing (PODC)</em>, August 1983. <strong><a href="http://dl.acm.org/citation.cfm?id=806707" target="_blank" rel="noopener">doi:10.1145/800221.806707</a></strong><br>[70]. Jim N. Gray and Leslie Lamport: <strong>“Consensus on Transaction Commit”</strong>, <em>ACM Transactions on Database Systems (TODS)</em>, vol. 31, no. 1, pp. 133–160,March 2006. <strong><a href="http://dx.doi.org/10.1145/1132863.1132867" target="_blank" rel="noopener">doi:10.1145/1132863.1132867</a></strong><br>[71]. Rachid Guerraoui: <strong><a href="https://pdfs.semanticscholar.org/5d06/489503b6f791aa56d2d7942359c2592e44b0.pdf" target="_blank" rel="noopener">“Revisiting the Relationship Between Non-Blocking Atomic Commitment and Consensus”</a></strong>, at <em>9th International Workshop on Distributed Algorithms (WDAG)</em>, September 1995. <strong><a href="http://dx.doi.org/10.1007/BFb0022140" target="_blank" rel="noopener">doi:10.1007/BFb0022140</a></strong><br>[72]. Thanumalayan Sankaranarayana Pillai, Vijay Chidambaram, Ramnatthan Alagappan, et al.: <strong><a href="http://research.cs.wisc.edu/wind/Publications/alice-osdi14.pdf" target="_blank" rel="noopener">“All File Systems Are Not Created Equal: On the Complexity of Crafting Crash-Consistent Applications”</a></strong>, at <em>11th USENIX Symposium on Operating Systems Design and Implementation (OSDI)</em>, October 2014.<br>[73]. Jim Gray: <strong><a href="https://jimgray.azurewebsites.net/papers/theTransactionConcept.pdf" target="_blank" rel="noopener">“The Transaction Concept: Virtues and Limitations”</a></strong>, at <em>7th International Conference on Very Large Data Bases (VLDB)</em>, September 1981.<br>[74]. Hector Garcia-Molina and Kenneth Salem: <em>“Sagas”</em>, at <em>ACM International Conference on Management of Data (SIGMOD)</em>, May 1987. <strong><a href="http://dx.doi.org/10.1145/38713.38742" target="_blank" rel="noopener">doi:10.1145/38713.38742</a></strong><br>[75]. C. Mohan, Bruce G. Lindsay, and Ron Obermarck: <strong><a href="https://cs.brown.edu/courses/csci2270/archives/2012/papers/dtxn/p378-mohan.pdf" target="_blank" rel="noopener">“Transaction Management in the R&#42; Distributed Database Management System”</a></strong>, <em>ACM Transactions on Database Systems</em>, vol. 11, no. 4, pp. 378–396, December 1986. <strong><a href="http://dx.doi.org/10.1145/7239.7266" target="_blank" rel="noopener">doi:10.1145/7239.7266</a></strong><br>[76]. <strong><a href="pubs.opengroup.org/onlinepubs/009680699/toc.pdf">“Distributed Transaction Processing: The XA Specification”</a></strong>, X/Open Company Ltd., Technical Standard XO/CAE/91/300, December 1991. ISBN: 978-1-872-63024-3<br>[77]. Mike Spille: <strong><a href="http://www.jroller.com/pyrasun/entry/xa_exposed_part_ii_schwartz" target="_blank" rel="noopener">“XA Exposed, Part II”</a></strong>, <em>jroller.com</em>, April 3, 2004.<br>[78]. Ivan Silva Neto and Francisco Reverbel: <strong><a href="http://www.ime.usp.br/%7Ereverbel/papers/icis2008.pdf" target="_blank" rel="noopener">“Lessons Learned from Implementing WS-Coordination and WS-AtomicTransaction”</a></strong>, at <em>7th IEEE/ACIS International Conference on Computer and Information Science (ICIS)</em>, May 2008. <strong><a href="http://dx.doi.org/10.1109/ICIS.2008.75" target="_blank" rel="noopener">doi:10.1109/ICIS.2008.75</a></strong><br>[79]. James E. Johnson, David E. Langworthy, Leslie Lamport, and Friedrich H. Vogt: <strong>“Formal Specification of a Web Services Protocol”</strong>, at <em>1st International Workshop on Web Services and Formal Methods (WS-FM)</em>, February 2004. <strong><a href="http://dx.doi.org/10.1016/j.entcs.2004.02.022" target="_blank" rel="noopener">doi:10.1016/j.entcs.2004.02.022</a></strong><br>[80]. Dale Skeen: <strong><a href="http://www.cs.utexas.edu/%7Elorenzo/corsi/cs380d/papers/Ske81.pdf" target="_blank" rel="noopener">“Nonblocking Commit Protocols”</a></strong>, at <em>ACM International Conference on Management of Data (SIGMOD)</em>, April 1981. <strong><a href="http://dx.doi.org/10.1145/582318.582339" target="_blank" rel="noopener">doi:10.1145/582318.582339</a></strong><br>[81]. Gregor Hohpe: <strong><a href="http://www.martinfowler.com/ieeeSoftware/coffeeShop.pdf" target="_blank" rel="noopener">“Your Coffee Shop Doesn’t Use Two-Phase Commit”</a></strong>, <em>IEEE Software</em>, vol. 22, no. 2, pp. 64–66, March 2005. <strong><a href="http://dx.doi.org/10.1109/MS.2005.52" target="_blank" rel="noopener">doi:10.1109/MS.2005.52</a></strong><br>[82]. Pat Helland: <strong><a href="http://adrianmarriott.net/logosroot/papers/LifeBeyondTxns.pdf" target="_blank" rel="noopener">“Life Beyond Distributed Transactions: An Apostate’s Opinion”</a></strong>, at <em>3rd Biennial Conference on Innovative Data Systems Research (CIDR)</em>, January 2007.<br>[83]. Jonathan Oliver: <strong><a href="http://blog.jonathanoliver.com/my-beef-with-msdtc-and-two-phase-commits/" target="_blank" rel="noopener">“My Beef with MSDTC and Two-Phase Commits”</a></strong>, <em>blog.jonathanoliver.com</em>, April 4, 2011.<br>[84]. Oren Eini (Ahende Rahien): <strong><a href="http://ayende.com/blog/167362/the-fallacy-of-distributed-transactions" target="_blank" rel="noopener">“The Fallacy of Distributed Transactions”</a></strong>, <em>ayende.com</em>, July 17, 2014.<br>[85]. Clemens Vasters: <strong><a href="https://blogs.msdn.microsoft.com/clemensv/2012/07/30/transactions-in-windows-azure-with-service-bus-an-email-discussion/" target="_blank" rel="noopener">“Transactions in Windows Azure (with Service Bus) – An Email Discussion”</a></strong>, <em>vasters.com</em>, July 30, 2012.<br>[86]. <strong><a href="https://docs.particular.net/nservicebus/azure/understanding-transactionality-in-azure" target="_blank" rel="noopener">“Understanding Transactionality in Azure”</a></strong>, NServiceBus Documentation, Particular Software, 2015.<br>[87]. Randy Wigginton, Ryan Lowe, Marcos Albe, and Fernando Ipar: <strong><a href="https://www.percona.com/live/mysql-conference-2013/sites/default/files/slides/XA_final.pdf" target="_blank" rel="noopener">“Distributed Transactions in MySQL”</a></strong>, at <em>MySQL Conference and Expo</em>, April 2013.<br>[88]. Mike Spille: <strong><a href="http://www.jroller.com/pyrasun/entry/xa_exposed" target="_blank" rel="noopener">“XA Exposed, Part I”</a></strong>, <em>jroller.com</em>, April 3, 2004.<br>[89]. Ajmer Dhariwal: <strong><a href="http://www.eraofdata.com/orphaned-msdtc-transactions-2-spids/" target="_blank" rel="noopener">“Orphaned MSDTC Transactions (-2 spids)”</a></strong>, <em>eraofdata.com</em>, December 12, 2008.<br>[90]. Paul Randal: <strong><a href="http://www.sqlskills.com/blogs/paul/real-world-story-of-dbcc-page-saving-the-day/" target="_blank" rel="noopener">“Real World Story of DBCC PAGE Saving the Day”</a></strong>, <em>sqlskills.com</em>, June 19, 2013.<br>[91]. <strong><a href="https://technet.microsoft.com/en-us/library/ms179586(v=sql.110" target="_blank" rel="noopener">“in-doubt xact resolution Server Configuration Option”</a>.aspx)</strong>, SQL Server 2016 documentation, Microsoft, Inc., 2016.<br>[92]. Cynthia Dwork, Nancy Lynch, and Larry Stockmeyer: <strong><a href="http://www.net.t-labs.tu-berlin.de/%7Epetr/ADC-07/papers/DLS88.pdf" target="_blank" rel="noopener">“Consensus in the Presence of Partial Synchrony”</a></strong>, <em>Journal of the ACM</em>, vol. 35, no. 2, pp. 288– 323, April 1988. <strong><a href="http://dx.doi.org/10.1145/42282.42283" target="_blank" rel="noopener">doi:10.1145/42282.42283</a></strong><br>[93]. Miguel Castro and Barbara H. Liskov: <strong><a href="http://zoo.cs.yale.edu/classes/cs426/2012/bib/castro02practical.pdf" target="_blank" rel="noopener">“Practical Byzantine Fault Tolerance and Proactive Recovery”</a></strong>, <em>ACM Transactions on Computer Systems</em>, vol. 20, no. 4, pp. 396–461, November 2002. <strong><a href="http://dx.doi.org/10.1145/571637.571640" target="_blank" rel="noopener">doi:10.1145/571637.571640</a></strong><br>[94]. Brian M. Oki and Barbara H. Liskov: <strong><a href="http://www.cs.princeton.edu/courses/archive/fall11/cos518/papers/viewstamped.pdf" target="_blank" rel="noopener">“Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems”</a></strong>, at <em>7th ACM Symposium on Principles of Distributed Computing (PODC)</em>, August 1988. <strong><a href="http://dx.doi.org/10.1145/62546.62549" target="_blank" rel="noopener">doi:10.1145/62546.62549</a></strong><br>[95]. Barbara H. Liskov and James Cowling: <strong><a href="http://pmg.csail.mit.edu/papers/vr-revisited.pdf" target="_blank" rel="noopener">“Viewstamped Replication Revisited”</a></strong>, Massachusetts Institute of Technology, Tech Report MIT-CSAIL-TR-2012-021, July 2012.<br>[96]. Leslie Lamport: <strong><a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/lamport-paxos.pdf" target="_blank" rel="noopener">“The Part-Time Parliament”</a></strong>, <em>ACM Transactions on Computer Systems</em>, vol. 16, no. 2, pp. 133–169, May 1998. <strong><a href="http://dx.doi.org/10.1145/279227.279229" target="_blank" rel="noopener">doi:10.1145/279227.279229</a></strong><br>[97]. Leslie Lamport: <strong><a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf" target="_blank" rel="noopener">“Paxos Made Simple”</a></strong>, <em>ACM SIGACT News</em>, vol. 32, no. 4, pp. 51–58, December 2001.<br>[98]. Tushar Deepak Chandra, Robert Griesemer, and Joshua Redstone: <strong><a href="http://www.read.seas.harvard.edu/%7Ekohler/class/08w-dsi/chandra07paxos.pdf" target="_blank" rel="noopener">“Paxos Made Live – An Engineering Perspective”</a></strong>, at <em>26th ACM Symposium on Principles of Distributed Computing (PODC)</em>, June 2007.<br>[99]. Robbert van Renesse: <strong><a href="www.cs.cornell.edu/courses/cs7412/2011sp/paxos.pdf">“Paxos Made Moderately Complex”</a></strong>, <em>cs.cornell.edu</em>, March 2011.<br>[100]. Diego Ongaro: <strong><a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="noopener">“Consensus: Bridging Theory and Practice”</a></strong>, PhD Thesis, Stanford University, August 2014.<br>[101]. Heidi Howard, Malte Schwarzkopf, Anil Madhavapeddy, and Jon Crowcroft: <strong><a href="http://www.cl.cam.ac.uk/%7Ems705/pub/papers/2015-osr-raft.pdf" target="_blank" rel="noopener">“Raft Refloated: Do We Have Consensus?”</a></strong>, <em>ACM SIGOPS Operating Systems Review</em>, vol. 49, no. 1, pp. 12–21, January 2015. <strong><a href="http://dx.doi.org/10.1145/2723872.2723876" target="_blank" rel="noopener">doi:10.1145/2723872.2723876</a></strong><br>[102]. André Medeiros: <strong><a href="http://www.tcs.hut.fi/Studies/T-79.5001/reports/2012-deSouzaMedeiros.pdf" target="_blank" rel="noopener">“ZooKeeper’s Atomic Broadcast Protocol: Theory and Practice”</a></strong>, Aalto University School of Science, March 20, 2012.<br>[103]. Robbert van Renesse, Nicolas Schiper, and Fred B. Schneider: <strong><a href="http://arxiv.org/abs/1309.5671" target="_blank" rel="noopener">“Vive La Différence: Paxos vs. Viewstamped Replication vs. Zab”</a></strong>, <em>IEEE Transactions on Dependable and Secure Computing</em>, vol. 12, no. 4, pp. 472–484, September 2014. <strong><a href="http://dx.doi.org/10.1109/TDSC.2014.2355848" target="_blank" rel="noopener">doi:10.1109/TDSC.2014.2355848</a></strong><br>[104]. Will Portnoy: <strong><a href="http://blog.willportnoy.com/2012/06/lessons-learned-from-paxos.html" target="_blank" rel="noopener">“Lessons Learned from Implementing Paxos”</a></strong>, <em>blog.willportnoy.com</em>, June 14, 2012.<br>[105]. Heidi Howard, Dahlia Malkhi, and Alexander Spiegelman: <strong><a href="https://arxiv.org/abs/1608.06696.pdf" target="_blank" rel="noopener">“Flexible Paxos: Quorum Intersection Revisited”</a></strong>, <em>arXiv:1608.06696</em>, August 24, 2016.<br>[106]. Heidi Howard and Jon Crowcroft: <strong><a href="http://www.sigcomm.org/sites/default/files/ccr/papers/2015/August/2829988-2790010.pdf" target="_blank" rel="noopener">“Coracle: Evaluating Consensus at the Internet Edge”</a></strong>, at <em>Annual Conference of the ACM Special Interest Group on Data Communication (SIGCOMM)</em>, August 2015. <strong><a href="http://dx.doi.org/10.1145/2829988.2790010" target="_blank" rel="noopener">doi:10.1145/2829988.2790010</a></strong><br>[107]. Kyle Kingsbury: <strong><a href="https://aphyr.com/posts/323-call-me-maybe-elasticsearch-1-5-0" target="_blank" rel="noopener">“Call Me Maybe: Elasticsearch 1.5.0”</a></strong>, <em>aphyr.com</em>, April 27, 2015.<br>[108]. Ivan Kelly: <strong><a href="https://github.com/apache/bookkeeper" target="_blank" rel="noopener">“BookKeeper Tutorial”</a></strong>, <em>github.com</em>, October 2014.<br>[109]. Camille Fournier: <strong><a href="http://www.ustream.tv/recorded/61483409" target="_blank" rel="noopener">“Consensus Systems for the Skeptical Architect”</a></strong>, at <em>Craft Conference</em>, Budapest, Hungary, April 2015.<br>[110]. Kenneth P. Birman: <strong><a href="https://www.truststc.org/pubs/713.html" target="_blank" rel="noopener">“A History of the Virtual Synchrony Replication Model”</a></strong>, in <em>Replication: Theory and Practice</em>, Springer LNCS vol. 5959, ch. 6, pp. 91–120, 2010. ISBN: 978-3-642-11293-5, <strong><a href="http://dx.doi.org/10.1007/978-3-642-11294-2_6" target="_blank" rel="noopener">doi:10.1007/978-3-642-11294-2_6</a></strong> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;《设计数据密集型应用（影印版）Designing data-intensive applications》，中文版是《数据密集型应用系统设计》。&lt;br&gt;这本书9月份就由中国电力出版社出版了。因为我习惯在互动出版网浏览新书，而它没有跟中国电力出版社合作，所以最近才发现。&lt;/p&gt;
    
    </summary>
    
      <category term="yi" scheme="https://ying-zhang.github.io/categories/yi/"/>
    
    
  </entry>
  
  <entry>
    <title>阿里全球调度算法大赛 GSAC 2018 总结 - 1</title>
    <link href="https://ying-zhang.github.io/cloud/2018/gsac18a/"/>
    <id>https://ying-zhang.github.io/cloud/2018/gsac18a/</id>
    <published>2018-10-04T16:00:00.000Z</published>
    <updated>2018-10-16T20:55:38.574Z</updated>
    
    <content type="html"><![CDATA[<p>今年7月到9月，我以<code>master_deng</code>的队名和师弟一起参加了 <a href="https://tianchi.aliyun.com/competition/information.htm?raceId=231663" target="_blank" rel="noopener">阿里全球调度算法大赛 GSAC 2018</a> ，成绩分别为：初赛 12/2116，复赛 11/100。<br>比赛结束近一个月了，这里总结一下比赛过程。这是第 1 部分 - 比赛简介。</p><a id="more"></a><hr><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p><strong> <a href="https://tianchi.aliyun.com/competition/information.htm?raceId=231663" target="_blank" rel="noopener">阿里全球调度算法大赛 Alibaba Global Scheduling Algorithm Competition - GSAC2018</a> </strong> 分初赛、复赛、决赛三个阶段。<br>初赛和复赛在阿里云的天池平台线上进行。初赛前 100 名的团队进入复赛，复赛的前 10 名获得决赛资格，最终只有 6 支队伍进行决赛 —— 这 6 支队伍到杭州阿里巴巴总部 <a href="https://tianchi.aliyun.com/forum/videoStream.html?postsId=23470#postsId=23470" target="_blank" rel="noopener">进行现场答辩</a>。<br>我们以<code>master_deng</code>的队名三人组队，初赛排名是 12/2116；之后由于比赛规则，由两人继续参加复赛，排名是 11/100，止步于此。<br>从复赛的排行榜看，我们的成绩与前面的队伍的差距还是很大的。<br><img src="/img/gsac18_semi_final_board.png" width="560"></p><h2 id="1-1-初赛"><a href="#1-1-初赛" class="headerlink" title="1.1 初赛"></a>1.1 初赛</h2><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><p>初赛阶段从2018年6月初开始，到8月14日止，场景是 <strong>大规模集群中在线应用的部署</strong> 。<br>具体说，有 68k 多个 <a href="https://mp.weixin.qq.com/s/rR5lxfRBJ2Wn3ZMeAXbwFw" target="_blank" rel="noopener">Pouch容器</a> ，分属于 9k 多个持续运行的在线应用，需要部署到不超过 6k 台机器上，限制是不能超过集群总的资源容量，还要满足应用间的干扰约束规则，最终实现较好的资源利用率和机器间的负载均衡。<br>需要注意的是，</p><ul><li>这是阿里内部的集群环境，而且以 Pouch 容器作为资源管理单元，<strong>不是</strong> 阿里云的虚拟机环境</li><li>应用是持续运行的，<strong>不考虑时间因素</strong>，只为容器选择合适的机器，所以称为 <strong>部署（Deploy）</strong>，或者说 <strong>资源管理</strong>（虽然也常说成是 <strong>调度</strong>，而且中文的 <strong>调度</strong> 含义确实有此含义，但对应的英文单词 <strong>Schedule</strong> 通常指 <strong>时间相关的安排</strong>，必要时要区分开。）</li></ul><p>比赛以分时的曲线的形式给出了应用的资源使用模型（CPU，内存）。刚开始有些想法：在运行中的某个时刻，将某个应用迁移到其它机器，从而将高峰和低谷时段不同的应用的资源曲线错峰填谷搭配，提高资源利用效率。不过在<a href="https://tianchi.aliyun.com/forum/new_articleDetail.html?raceId=231663&amp;postsId=5492" target="_blank" rel="noopener">初赛解读（见附件PPT</a>，<a href="https://tianchi.aliyun.com/forum/videoStream.htm?spm=5176.9876270.0.0.33d1e44a2EM8gp&amp;postsId=5445#postsId=5445" target="_blank" rel="noopener">及视频</a>）中，比赛方 <strong>否定</strong> 了这个想法，虽然理论上看起来不错，但不符合实际，得不偿失。这样也让问题简化了不少。</p><p>比赛数据的初始状态中（集群的 <strong>初态</strong>），有些应用的容器实例已经部署到机器上了，还有一些等待部署，即机器不是完全空闲的状态。</p><ul><li>选手可以保留初始部署，在此基础上继续部署其它实例</li><li>也可以完全忽略初始部署，从所有机器都是空闲的状态开始实施自己的算法；显然这样才能贯彻选手的算法。</li></ul><p>最终选手提交的是一个<code>&lt;实例Id, 机器Id&gt;</code>的列表，即部署/迁移动作列表。但并 <strong>不是</strong> 简单地给出实例及其最终部署的目标机器（集群的 <strong>终态</strong>），而是从 <strong>初态</strong> 到选手得到的 <strong>终态</strong> 的全部过渡动作，而且每步动作都要满足资源容量约束和应用干扰约束。好在比赛不限制动作的总数。</p><p>虽然部署的是在线应用，但 <strong>部署过程</strong> 本身是 <strong>离线的</strong>，即所有应用的资源模型都已知，据此计算出优化的终态，实施部署，之后集群才算开始运行；而不是在集群运行期间响应用户提交的新应用（<strong>在线部署</strong>）。离线部署对计算时间不太敏感，可以长一些，所以比赛没有硬性限制计算时间。</p><p>实际的集群是持续运行的，而且会有新应用提交，也有旧应用下线，但集群中的大部分应用是较稳定的。可以根据资源监控的历史数据对这些已知的应用建模，并且定期（比如每天）重新计算并调整集群的最优部署。<a href="https://tianchi.aliyun.com/forum/new_articleDetail.html?raceId=231663&amp;postsId=5492" target="_blank" rel="noopener">初赛解读</a> 中提到比赛的场景来自阿里内部的集群资源管理系统 Sigma。</p><blockquote><p>因为 Sigma 兼容 Google 的 Kubernetes (k8s) API，之前我认为两者的资源管理方式也是差不多的，即 <strong>在线资源管理</strong> 。结合这次比赛，以及初赛解读中提到的 <strong>Sigma 是面向终态的架构设计</strong>，看来两者还是有很大差别的。<br>Sigma 补上了 k8s 缺失的 <strong>全局重调度</strong> 这个很有实践意义的重要功能。<br>k8s 有一个孵化项目 <strong><a href="https://github.com/kubernetes-incubator/descheduler" target="_blank" rel="noopener">descheduler</a></strong>，其设计目标也是重调度，可以参考 <a href="https://github.com/kubernetes/kubernetes/issues/12140" target="_blank" rel="noopener">相关讨论 #12140</a>。<br>离线部署功能也可以从 Sigma 中划分出来，作为单独的组件；但两者有不少功能是可以共用的（比如约束检查），所以我认为合在一起更合适些。</p></blockquote><p>机器<a href="https://en.wikipedia.org/wiki/Generalized_assignment_problem" target="_blank" rel="noopener">分配（Assignment）问题</a>是典型的 <strong><a href="https://en.wikipedia.org/wiki/Combinatorial_optimization" target="_blank" rel="noopener">组合优化问题</a></strong>，也可以表示为<a href="https://en.wikipedia.org/wiki/Bin_packing_problem" target="_blank" rel="noopener">装箱问题 Bin Packing，或直接说 Packing</a>。规模较小的问题可以使用 Gurobi 或 CPLEX 等商业求解器按 <a href="https://en.wikipedia.org/wiki/Integer_programming" target="_blank" rel="noopener">0-1整数规划</a> 求解。但比赛的数据规模超出了求解器的能力；另外，目标函数是指数函数，也难以直接使用求解器。</p><p>使用装箱的近似算法，比如首次适合算法（First fit，FF），肯定可以排在初赛的前 50 名，顺利进入复赛。<br>决赛的 6 支队伍仅有 <strong>4th - SuperUncle</strong> 只用 Best fit 算法，其它 5 支队伍都使用了某种 <a href="https://en.wikipedia.org/wiki/Local_search_(optimization)" target="_blank">局部搜索</a>，除了随机搜索（<strong>6th - 地球漫步</strong>，<strong>3rd - rivulet</strong>，<strong>2nd - greydog</strong>），还有 <a href="https://en.wikipedia.org/wiki/Simulated_annealing" target="_blank" rel="noopener">模拟退火 Simulated Annealing，SA</a> （<strong>5th - yxgy</strong>，<strong>1st - 我就看看不提交</strong>），不过 <strong>1st - 我就看看队</strong> 在答辩中提到，他们的 SA 并没有改变温度，实际上也是随机搜索；<strong>yxgy</strong> 的 SA 跟 <strong>我就看看队</strong> 的是不同的。</p><h3 id="机器"><a href="#机器" class="headerlink" title="机器"></a>机器</h3><p>集群共有 6000 台机器（Machine，不致混淆时，简记为 m），按资源容量（Capacity）分为 2 种，各 3000 台，Id 是连续的整数。<br>从机器数量来看，集群应该算是中等规模吧。<br><img src="/img/gsac18_machine_pre_a.png" width="500"></p><h3 id="应用和实例"><a href="#应用和实例" class="headerlink" title="应用和实例"></a>应用和实例</h3><p>所谓在线应用（App），主要就是 Web 应用。共有 <strong>9338</strong> 个应用。应用是匿名的，通过 App Id 来区分。App Id 也是连续的整数。<br>每个应用有不同数量的实例（Instance，简记为 inst）。每实例就是一个 Pouch 容器。共有 <strong>68219</strong> 个实例。Inst Id 也是整数，但 <strong>不是</strong> 连续的。<br>平均每个应用有 7 个实例，但实际上应用的实例个数是很不均衡的：</p><ul><li>最“大”的应用有 610 个实例，最小的只有 1 个实例</li><li>大部分（~62%）应用仅有 1~2 个实例；约 10% 的（1061个）应用有 &gt; 10 个实例，其中仅 104 个应用有 ≥ 100 个实例</li></ul><h3 id="应用干扰约束"><a href="#应用干扰约束" class="headerlink" title="应用干扰约束"></a>应用干扰约束</h3><p>应用之间有干扰（Interference，简记为 X）约束，表示为 <code>&lt;App_A, App_B, k&gt;</code> 这样的规则。其含义是：若某机器上已存在 App_A 的实例，那么允许存在的 App_B 的实例个数不能超过 k 个。</p><ul><li>若 k=0 ，就表示 App_A 不能与 App_B 共存在同一台机器；若机器上没有 App_A 的实例，这条规则就不影响 App_B 的部署了</li><li>若 App_A = App_B ，即两者是同一应用，由于规则生效的前提是机器上至少有一个 App_A 的实例，所以 <code>&lt;App_A, App_A, k&gt;</code> 这样的规则实际是限制同一机器上 App_A 的实例总数不超过 <strong>k+1</strong> 个；对这种规则，即便 k=0，机器上还是可以部署一个 App_A 的实例的，当然也可以不部署</li><li><code>&lt;App_A, App_B, k&gt;</code> 与 <code>&lt;App_B, App_A, m&gt;</code> ，即正，反向的约束 <strong>没有直接的关系</strong>。也就是说，每个应用都有自己的偏好，App_A 可能很嫌弃 App_B，但 App_B 却对 App_A 毫不在意，可以 <code>m ≠ k</code>，甚至可以不存在 <code>&lt;App_B, App_A, m&gt;</code> 这样的约束</li><li>向机器部署一个 App_B 的实例时，既要检查这台机器上 App_B 嫌弃的那些应用（可能是 App_C，App_D 等）已存在的实例个数不超过 App_B 的约束；也要检查若增加 App_B 的一个实例，是否会违反那些嫌弃 App_B 的应用（比如 App_A 等）的要求</li><li>共有 35k 多条约束规则，仅有少数应用有几百条规则，最多的一个有 600 多条，有约 2/3 的应用则没有规则</li></ul><p>初赛解读中提到了 <strong>亲和/反亲和</strong> 约束，实际上这里的规则是硬性的，适合表达 <strong>反亲和（干扰）</strong>。</p><h3 id="应用资源约束"><a href="#应用资源约束" class="headerlink" title="应用资源约束"></a>应用资源约束</h3><p><strong>属于同一个应用</strong> 的实例有相同的 <strong>资源使用模型</strong>，包括下面几种资源，共用 200 个数值（维度）来描述：</p><ul><li>98个 <strong>浮点数</strong> 表示 CPU 分时使用量，核数</li><li>98个浮点数表示 内存 分时使用量，GB</li><li>1 个整数表示 磁盘 使用量，GB</li><li>3 个整数表示 P，M，PM 三个阿里内部定义的虚拟资源，用来表示应用重要性，比赛中影响不大</li></ul><p>98 个点的<a href="https://tianchi.aliyun.com/forum/new_articleDetail.html?raceId=231663&amp;postsId=5338" target="_blank" rel="noopener">分时曲线</a>大致 ~15 min 记录一个点，描述了应用实例在一天 24 h （实际是 24.5 h）的资源使用变化情况。</p><p>下图是将所有应用的CPU和内存资源使用量分别乘以该应用的实例个数后，分时刻求和，再除以集群资源总容量得到的 <strong>整体分时波动曲线</strong>。</p><ul><li>可以看到内存的利用率比较平稳，~37%</li><li>CPU有明显的峰谷，最大 ~38%，最小 ~18%，平均 ~25%</li></ul><p>此外，整体的硬盘使用率 <strong>居然达到了 ~94 %， 比CPU和内存还紧张！</strong><br><img src="/img/gsac18_util_pre_a.png" width="450"></p><p>应用之间在资源使用量和分时波动上都存在显著的不均衡：大部分的应用使用的资源很少，而且一天内基本没有波动。少数关键应用使用了大部分资源，而且有明显的波动趋势。</p><ul><li>分时：对 CPU，标准差 StdVar &lt; 0.5 的 共有 46048 个（~68%）实例，分别属于 8613 个（~92%）应用； 对内存，StdVar &lt; 0.5 的 共有 50095 个（~73%）实例，涉及 7283 个（~78%）应用</li><li>总量：最紧张的硬盘资源用量，分为 40 GB 到 1024 GB 共 16 个离散值，大部分集中在 60 GB，占总实例个数的 78.5 %；超过 600 GB 的实例个数仅有 41 个，占 0.06 %</li></ul><p>很容易想到分时曲线是从资源监控的历史数据统计出来的。模型的准确性总是值得讨论的，但比赛中不考虑这个问题。另外，上面提到不少应用的资源使用量在一天内没有波动，可能没有对全部应用建模，而只对部分 <strong>关键应用</strong> 建模了吧。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>平均下来每台机器有11个实例。考虑到成本，要尽量 <strong>少占用</strong> 机器。比赛的问题就是 <strong>把 68k 多个实例部署到不超过 6000 台机器上</strong>，具体说，</p><ul><li>目标：所有实例都部署到了机器上，而且使用的机器数量越少越好</li><li>资源约束：每台机器上部署的应用实例使用资源之和不能超出机器资源容量</li><li>干扰约束：此外还要满足应用间的干扰约束规则</li></ul><p>每个实例部署时都不能违反这两个约束，最终整个机器的状态也不能违反。<br>若只考虑资源约束，可以认为是一个大规模的 <strong>多维向量装箱</strong> 问题，维度是200维，而且箱子（机器）是异构的。</p><h3 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h3><p>具体的 <strong>优化目标</strong> （Total cost score，简记为 score，越小越好） 是：</p><span>$$\begin{aligned}\mathrm{Total\_cost\_score} &amp; = \frac{1}{T} \sum_{t=1}^{T}\sum_{j=1}^{M}s^t_j \\                            &amp; = \sum_{j=1}^{M} (\frac{1}{T} \sum_{t=1}^{T}s^t_j) = \sum_{j=1}^{M} s_j\end{aligned}$$</span><!-- Has MathJax --><p>其中，<script type="math/tex">T=98</script>，是分时数据点的个数； <script type="math/tex">M=6000</script>，是机器总数；<script type="math/tex">s^t_j</script> 代表机器 <script type="math/tex">j</script> 在时刻 <script type="math/tex">t</script> 的成本分数。<br>交换两个求和的顺序后，说明可以先分别计算 <strong>各机器在 98 个时刻的成本分数平均值</strong> <script type="math/tex">s_j = \frac{1}{T} \sum_{t=1}^{T}s^t_j</script>，然后再合计集群中所有机器的成本。</p><p>如果机器 <script type="math/tex">j</script> 在时刻 <script type="math/tex">t</script> 没有实例部署，则 <script type="math/tex">s^t_j=0</script> ；（*注）<br>否则，</p><script type="math/tex; mode=display">s^t_j = 1 + \alpha(e^{\max(0,c-\beta)} - 1)</script><p>其中，<script type="math/tex">c</script> 是机器 <script type="math/tex">j</script> 在时刻 <script type="math/tex">t</script> 的 CPU 利用率；<script type="math/tex">\alpha, \beta</script>是惩罚系数，分别为 <script type="math/tex">\alpha=10, \beta=0.5</script>。<br>如果提交结果不符合规范，成本分数为 <script type="math/tex">10^9</script>。成本分数 <strong>越低</strong> 越好。</p><blockquote><p>*注：<strong>成本分数仅考虑 CPU 资源。</strong><br>若 CPU 利用率为 0，按公式计算出 <script type="math/tex">s^t_j=1</script>，即 <strong>没有部署任何实例的空闲机器</strong> 的成本分数是 1。另一方面，若一台机器的 CPU 使用率在所有时刻均不超过 50%，其成本也是 1。为了区分两者，所以 <strong>规定空闲机器的成本为 0</strong>。<br>上面提到，每台机器可以分别计算在 98 个时刻的成本分数平均值 <script type="math/tex">s_j</script> ：如果所有时刻的 CPU 利用率都不超过 50%，机器的成本分数 <script type="math/tex">s_j</script> 也是 1；只要有一个时刻的 CPU 利用率超过 50%， <script type="math/tex">s_j</script> 必然大于 1。</p></blockquote><p>若 CPU 利用率不超过 50% ，则成本分数就是 1；超过 50% 后，就呈指数增长了。下面是成本公式的反函数，<br><span>$$\begin{aligned}c&amp;= \ln(s^t_j + \alpha -1) - \ln \alpha + \beta\\ &amp;\approx \ln(s^t_j + 9) - 1.8026\end{aligned}$$</span><!-- Has MathJax --></p><p>若 <script type="math/tex">s = 2</script>，则 <script type="math/tex">c \approx 0.595</script>；即当 CPU 利用率从 50% 增加到 59.5%，成本分数就 <strong>翻倍</strong> 了。若 <script type="math/tex">s = 3</script>，则 <script type="math/tex">c \approx 0.682</script> 。</p><ul><li>对 92 个核的机器，从 50% 到 59.5%增加的 9.5% 利用率对应了 <strong>8.74</strong> 个核；反之，如果使用一台空闲机器 m，只要 m 的 CPU 利用率不超过 50%，也只增加 1 分，但相当于增加了 46 个核。</li><li>对 32 个核的机器，9.5% 的利用率对应 <strong>3.04</strong> 个核；50% 的利用率相当于 16 个核。</li></ul><p>因此，优化目标是希望：</p><ol><li>使用的机器尽量少</li><li>已经占用机器的 CPU 利用率尽量不超过 50%，且机器间的 CPU 利用率尽量均衡</li><li>由于只比较利用率，对相同的百分比，大型机器提供的资源数量更多，因此应充分使用大型机器</li></ol><h3 id="初始部署"><a href="#初始部署" class="headerlink" title="初始部署"></a>初始部署</h3><p>初始数据中，有约 30000 个（~ 44%）实例已经部署到 ~2500 台机器上了。初始部署的质量还是很高的：硬盘的利用率基本都在 90% 以上，甚至有的是 100%，而且都没有超出资源容量约束。<br>从成本分数上看，已部署的大型机器中，仅有一台的成本分数 &gt; 1.0，即有些时刻的 CPU 利用率超过了 50%；而小型机器则有 400 多台的成本分数 &gt; 1.0 。如果初始部署来自阿里的真实环境，那么看来算法对机器的异构性处理得不太好。</p><p>另外，有一百多个实例与所在机器上的其它应用的实例存在 <strong>违反干扰约束</strong> 的情况。看来发现了一个 Bug ;-)</p><h3 id="评分代码"><a href="#评分代码" class="headerlink" title="评分代码"></a>评分代码</h3><p>由于大家对赛题理解存在偏差，一开始很多队伍的提交不满足格式要求，好在比赛方在7月9日开源了评分代码。<br>对上面提到的一百多个实例违反干扰约束的实例，我们开始是直接 <strong>跳过</strong> 这样的实例，保证机器上部署的实例都是满足两个约束的。但评分代码则 <strong>忽略约束，强制</strong> 将实例部署到机器上。参考评分代码，我们修正了这个处理逻辑。</p><blockquote><p>数据和评分代码都公开了，比赛结束后，感兴趣的同学还可以尝试一下。</p></blockquote><h3 id="初赛数据集-B"><a href="#初赛数据集-B" class="headerlink" title="初赛数据集 B"></a>初赛数据集 B</h3><p>初赛数据中应用的 <strong>硬盘资源比 CPU 和内存要紧张得多</strong>，以至于仅考虑硬盘资源维度就可以得到比较好的部署结果。<br>7月5日，初赛刚开始排名，<strong>4th - SuperUncle</strong> 就给出了 5506 的最优解，随后 5506 分的队伍越来越多。<strong>月光鸣下</strong>（1st - 我就看看不提交） 在初赛结束后给出了 <a href="https://tianchi.aliyun.com/forum/new_articleDetail.html?raceId=231663&amp;postsId=6749" target="_blank" rel="noopener">通过硬盘资源构造初赛最优解</a>的思路，但还要在此基础上满足应用资源约束和干扰约束。<br>于是，比赛方在 7月26日 添加了初赛数据集 B。<br>相比最初的数据集 A，仍有 6000 台机器，大小各 3000 台；应用数仍为 9338 个；实例数增加了 5 个，为 68224 个。<br>发生变化的有：</p><ul><li>机器的 CPU 和内存等容量没有变化，但硬盘容量增加了</li><li>应用的 <strong>硬盘使用量不变</strong>，但因为机器硬盘容量增加了，导致硬盘利用率减小了（~39%）；应用的 CPU 和内存的使用量均 <strong>增加了</strong>，利用率也增加了（Max/Min/Avg：CPU ~55%/32%/45%，内存 ~60%/59%/60%）；分时上，内存使用率非常平稳，而 CPU 仍然是明显的峰谷趋势</li><li>所有应用都至少有 1 条干扰约束规则了，但仍然是不均衡的，大部分应用只有 1 条约束规则</li></ul><p><img src="/img/gsac18_machine_pre_b.png" width="500"></p><p>初始状态已经部署了 61k 多个实例，仅剩 6900 多个实例尚未部署。因为 CPU 用量增加了，大部分机器的成本分数都超过了 1.0。这次没有违反资源容量约束或干扰约束的情况。</p><h2 id="1-2-复赛"><a href="#1-2-复赛" class="headerlink" title="1.2 复赛"></a>1.2 复赛</h2><p>复赛从 8月15日 至 9月7日，比初赛时间短一些。这就要求选手初赛阶段的算法比较通用。复赛直接提供了 5 份数据集，除了初赛的在线应用，还增加了离线任务，场景也就变成了 <strong>在线应用（App）和离线作业（Job）混合部署（混部）</strong>。</p><h3 id="离线作业"><a href="#离线作业" class="headerlink" title="离线作业"></a>离线作业</h3><p>这里首先明确一下名称：比赛的介绍中称为离线 <strong>任务</strong>，但这里将其称为离线 <strong>作业（Job）</strong>。一个作业（Job，如一个完整的 MapReduce 程序）包含多个任务（Task，一个执行阶段，如 Map 任务、Reduce 任务等）。</p><p>每个任务对应数据文件 <code>job_info.x.csv</code> 中的一行，其中 x 是 a,b,c,d,e 之一（<code>job_info.e.csv</code> 是空文件）。下面是 <code>job_info.a.csv</code> 的前 5 行，每行的格式为 <strong><code>离线任务Id, CPU 用量, Mem 用量, 实例数, 执行时间, 前驱任务Id列表</code></strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">8886-18,0.50,0.25,111,98,</span><br><span class="line">8886-14,0.75,0.38,20,88,</span><br><span class="line">6801-2,0.50,0.50,3,128,</span><br><span class="line">6801-3,0.50,0.25,13,122,6801-1,6801-2</span><br><span class="line">6801-1,0.50,0.25,37,124,</span><br></pre></td></tr></table></figure><ul><li>其中 <strong>Task Id</strong> 如 <code>8886-18</code>，赛题介绍中没有明确（<strong>导致答辩时各队伍的叫法都不同</strong>），这里我们把短横前面的部分称为 Job Id，如 <code>8886</code>。同一作业的任务在数据文件中不一定是连续的，也不一定是顺序出现的，比如上面的例子。5 个数据集的 <strong>作业数/总任务数（行数）</strong> 分别为 <strong>a: 1085/5241, b: 1094/5637, c: 546/2840, d: 478/2250 和 e: 0</strong></li><li>一个任务的 <strong>CPU 和内存用量</strong> 在其执行期间是固定的数值。显然离线作业也受 <strong>资源容量的约束</strong>。数据集 a 和 c 中任务使用的资源 <strong>粒度较小</strong>，但实例数量多，而 b 和 d 中任务的 <strong>资源粒度较大</strong>，但实例数量少。总体而言，a 和 b 的资源总量基本相当，c 和 d 也基本相当，a/b 的资源总量约是 c/d 的 <strong>两倍</strong>。直觉上 <strong>小的实例可能比较容易部署</strong></li><li>一个任务有 <strong>多个实例</strong>，实例是资源管理的单元。作业的实例 <strong>不是</strong> Pouch 容器。实例一旦部署到某台机器，开始执行后，直到结束退出，期间不发生迁移。任务的实例总数要远大于在线应用的实例总数（数据集 a 最多，有 110 万多个实例）。可以单独为每个实例分配资源，但要使用一些缓存分数的优化技巧；也可以<strong>按批次处理</strong>。同时，为了与在线应用的 <strong>实例</strong> 区分，这里将离线任务的若干实例（可以是单个实例）称为一个 <strong>批次（Batch）</strong>，形式是一个四元组 <strong><code>&lt;Task, Machine, BeginTime, Size&gt;</code></strong>，表示部署到某机器（Machine），在某一时刻（BeginTime，分钟）开始执行的离线任务（Task）的若干实例（Size）。这也是离线作业提交文件的格式。<br>部署机器不同，或开始执行时间不同，都不是同一批次。</li><li>任务的 <strong>执行时间（Duration）</strong> 以分钟为单位。在线应用只使用了 98 个点，间隔 15 min 来描述应用的 CPU 和内存分时使用量，但复赛的一个周期要考虑 1470 个点，每分钟一个点（共 24.5 h）。任务的开始和结束时间都是整数分钟</li><li>任务的 <strong>前驱列表</strong> 直接在文件中给出来了，但要读入同一作业的所有任务后才能知道后继列表。前驱后继关系使作业的所有任务形成一个 <strong>有向无环图（DAG）</strong>。一个任务必须等待它的所有前驱都结束后才能开始执行。<br>如果一个任务没有前驱，就是 <strong>起始任务</strong>，可以有多个起始任务。没有后继的是 <strong>终止任务</strong>，同样需要读入同一作业的所有任务后才能知道，也可以有多个。<br>一个作业内任务之间存在 <strong>执行顺序约束</strong>。不同作业之间没有这个约束。</li></ul><p>作业的资源占用、任务/实例个数、DAG复杂程度、执行时间也都是不均衡的，大部分是较小的作业。</p><p>我们可以根据 DAG 计算出作业的 <strong>关键路径</strong>（Critical Path），以及 <strong>最短执行时间</strong>。一旦某个关键路径上的任务结束，其后继就可以执行了。同一时段可以有多个任务都在关键路径上。非关键路径上任务 <script type="math/tex">Task_{ncp}</script> 的 <strong>最早开始时间（<code>BeginEarliest</code>）</strong> 与同时段的关键路径任务 <script type="math/tex">Task_{cp}</script> 的相同，<strong>最晚开始时间（<code>BeginLatest</code>）</strong> 加上任务 <script type="math/tex">T_{ncp}</script> 的执行时间（<code>Duration</code>）后，应与对应关键路径任务 <script type="math/tex">T_{cp}</script> 的结束时间（<code>End</code>）相同。<br>上面计算的都是作业本身的相对时间。一旦确定了作业中某个任务在 1470 分钟周期内的具体开始时刻（绝对时间），其前驱和后继的浮动区间也就随之确定了。</p><p>不过，复赛的成本分数公式并 <strong>没有涉及</strong> 离线作业的等待时间，只要不违反上面提到的 <strong>资源约束</strong> 和 <strong>顺序约束</strong> 即可。为了防止过载，让就绪的任务多等一段时间也是可以的。决赛答辩中，有的队伍就只进行了 <a href="https://en.wikipedia.org/wiki/Topological_sorting" target="_blank" rel="noopener"><strong>拓扑排序</strong></a>，没有计算上面提到的关键路径参数。</p><p>上面提到，在线应用的 CPU 曲线有明显的峰谷。离线作业（Job）与在线应用（App）混部的主要目标就是 <strong>错峰填谷</strong>。通常后半夜在线应用的负载很低，这时候来执行离线作业，可以提高集群资源利用率。</p><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>复赛的 5 个数据集共用一个在线应用数据，跟 <strong>初赛数据集 B 的应用和干扰部分</strong> 是 <strong>一样的</strong>，共 9338 个应用，68224 个实例。<br>不同数据集的 <strong>实例 Id</strong> 稍有不同，但 <strong>每个应用的实例数量是相同的</strong>，因此实例 Id 不同并没有什么实质影响。</p><p>5 个数据集的机器配置和数量有所不同，具体如下表：a，b，e 共 8000 台机器；c 和 d 共 9000 台机器。a 和 b 都只有大型机器，资源总量最多；c，d 和 e 都有 6000 台小型机器，资源总量明显变少了，而且 e 的总量最少。</p><p><img src="/img/gsac18_machine_semi_final.png" width="540"></p><h3 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h3><p>初始状态，5 个数据集的所有实例都 <strong>已经部署到机器上了</strong>。前面提到，可以不考虑初始部署，从空的集群开始执行 <strong>装箱</strong> 算法，生成优化的 <strong>终态</strong>。<br>也可以从 <strong>初态</strong> 开始，逐步调整实例的部署，这时就不能用装箱了。其实这也是比赛方暗示应该用 <a herf="https://en.wikipedia.org/wiki/Local_search_(optimization)" target="_blank">局部搜索（Local Search，LS）</a> 算法。</p><p>有可能搜索过程很久，实例迁移的动作很多。要达到终态，可以输出搜索的 <strong>每一步实例迁移动作</strong>，但这可能存在不少冗余动作，即一个实例换了多个部署机器。<br>另一方面，可以比较 <strong>终态和初态的差异</strong> ，生成迁移动作，这需要有足够的空闲资源（机器）进行腾挪，否则可能无法在资源和干扰的约束下到达终态。</p><p>复赛对在线应用的迁移增加了限制，采取多轮并发执行。一个迁移动作分为两个阶段：若 <script type="math/tex">m_1</script> 机器上的实例 <script type="math/tex">inst</script> 要迁移到 <script type="math/tex">m_2</script>，先在目标机器 <script type="math/tex">m_2</script> 上新建一个实例 <script type="math/tex">inst'</script>，一轮结束后才删除 <script type="math/tex">m_1</script> 上的 <script type="math/tex">inst</script>；即过渡阶段 <script type="math/tex">inst</script> 占用了双份资源。可以在搜索的每步都保证这个限制，也可以仅在从终态差异生成迁移动作时考虑。<br>同一轮次的不同实例迁移可以并发执行。比赛限制的是迁移轮次不超过 3 次，一轮内能迁移的次数则没有限制。</p><blockquote><p>迁移时先新建再删除是合理的，但我认为分轮次迁移并不太合理。相反，限制总的迁移次数更直观。<br>若资源分配算法比较好，可以将集群保持在比较理想状态，期望重调度需要迁移的实例不太多。</p></blockquote><h3 id="成本公式"><a href="#成本公式" class="headerlink" title="成本公式"></a>成本公式</h3><p>复赛还修改了成本公式，将惩罚系数 <script type="math/tex">\alpha</script> 改为与机器上部署的实例个数 <script type="math/tex">N</script> 相关：</p><script type="math/tex; mode=display">s^t_j = 1 + (1 + N)(e^{\max(c-\beta,0)} - 1)</script><p>初赛阶段的成本公式规定如果机器 <script type="math/tex">j</script> 在时刻 <script type="math/tex">t</script> 没有实例部署，则 <script type="math/tex">s^t_j=0</script> 。因为所有应用实例的 CPU 使用量曲线都是＞0的，所以只要机器上部署了实例，就不会有 CPU 利用率为 0  的时刻。换句话说，只要机器上有一个时刻的 CPU 利用率为 0，整个机器必然没有实例部署，如果不为 0，必然部署了实例。<br>复赛中，一台机器可以没有部署任何实例，但部署了离线 Task ，不能按初赛的规定令机器的分数为 0 。<br><strong>没有 Task 执行的时刻，CPU 利用率为 0，对应的成本分数为 <script type="math/tex">s^t_j=1</script> 。如果有时刻 CPU 利用率超过了 50%，成本分数仍然是指数增加的。</strong></p><h2 id="1-3-链接"><a href="#1-3-链接" class="headerlink" title="1.3 链接"></a>1.3 链接</h2><ul><li><a href="https://tianchi.aliyun.com/competition/information.htm?raceId=231663" target="_blank" rel="noopener">阿里全球调度算法大赛官网 GSAC 2018</a>，包括赛制，赛题介绍，数据，评分代码，排行榜，答疑论坛</li><li><a href="https://tianchi.aliyun.com/forum/new_articleDetail.html?raceId=231663&amp;postsId=5492" target="_blank" rel="noopener">初赛解读：专家直播实录（附PPT下载）</a>，<a href="https://tianchi.aliyun.com/forum/videoStream.htm?spm=5176.9876270.0.0.33d1e44a2EM8gp&amp;postsId=5445#postsId=5445" target="_blank" rel="noopener">视频</a></li><li><a href="https://tianchi.aliyun.com/forum/videoStream.html?postsId=23470#postsId=23470" target="_blank" rel="noopener">视频：杭州阿里巴巴总部的决赛答辩</a></li><li><a href="https://mp.weixin.qq.com/s/nOru9ye2h0eredGneeV4TQ" target="_blank" rel="noopener">独家解密：阿里是如何应对超大规模集群资源管理挑战的</a></li><li><a href="https://mp.weixin.qq.com/s/8-FcbKGmfjeZPldyS_bUrw" target="_blank" rel="noopener">狮城新加坡完美收官！哪些能人异士参加了阿里全球调度算法大赛初赛？</a></li><li><a href="https://mp.weixin.qq.com/s/ov1tqa2siZlGq0z911Bwpw" target="_blank" rel="noopener">51个国家，2372名选手，20万奖金池，阿里全球调度算法大赛收官</a></li><li><a href="https://tianchi.aliyun.com/forum/new_articleDetail.html?raceId=231663&amp;postsId=6749" target="_blank" rel="noopener">月光鸣下：教大家算初赛两份数据的分数下界</a></li></ul><h3 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h3><ul><li><a href="https://gitlab.com/thyrix/tianchi_scheduling_2018" target="_blank" rel="noopener">1st - 我就看看不提交 - 代码 ThyrixYang / tianchi_scheduling_2018 · GitLab</a></li><li><a href="https://github.com/NeuronEmpire/aliyun_schedule_semi" target="_blank" rel="noopener">6th - 地球漫步 - 代码 NeuronEmpire/aliyun_schedule_semi · GitHub</a></li><li><a href="https://github.com/im2608/tianchi_dispatch/tree/dispatch_semifinal" target="_blank" rel="noopener">18th - im2608 - 代码 tianchi_dispatch · GitHub</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今年7月到9月，我以&lt;code&gt;master_deng&lt;/code&gt;的队名和师弟一起参加了 &lt;a href=&quot;https://tianchi.aliyun.com/competition/information.htm?raceId=231663&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;阿里全球调度算法大赛 GSAC 2018&lt;/a&gt; ，成绩分别为：初赛 12/2116，复赛 11/100。&lt;br&gt;比赛结束近一个月了，这里总结一下比赛过程。这是第 1 部分 - 比赛简介。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://ying-zhang.github.io/categories/cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>【译文】YARN资源管理器的研究进展，YARN-1011</title>
    <link href="https://ying-zhang.github.io/yi/2018/x-adv-yarn/"/>
    <id>https://ying-zhang.github.io/yi/2018/x-adv-yarn/</id>
    <published>2018-06-09T16:00:00.000Z</published>
    <updated>2018-06-10T02:50:25.206Z</updated>
    
    <content type="html"><![CDATA[<p>YARN资源管理器的研究进展（Advancements in YARN Resource Manager）是大数据技术百科（Encyclopedia of Big Data Technologies，这本书的其它条目质量较差）中的一个条目，是由微软的员工编写的对YARN进展比较全面的综述。<br>YARN-1011是YARN关于资源超售的一个JIRA项，是上面条目提到的一个参考文献，亦翻译后作为附录。</p><p>英文全文：<a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/02/yarn-big-data-encyclopedia-2018.pdf" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/uploads/prod/2018/02/yarn-big-data-encyclopedia-2018.pdf</a><br>译文全文：[<a href="https://ying-zhang.github.io/doc/Adv_in_YARN_CN_Ying_201806.pdf">https://ying-zhang.github.io/doc/Adv_in_YARN_CN_Ying_201806.pdf</a>]</p><a id="more"></a><hr><h1 id="Advancements-in-YARN-Resource-Manager"><a href="#Advancements-in-YARN-Resource-Manager" class="headerlink" title="Advancements in YARN Resource Manager"></a>Advancements in YARN Resource Manager</h1><h1 id="YARN资源管理器的研究进展"><a href="#YARN资源管理器的研究进展" class="headerlink" title="YARN资源管理器的研究进展"></a>YARN资源管理器的研究进展</h1><p>Konstantinos Karanasos，Arun Suresh, Chris Douglas， 微软<br>        译者：Ying 2018-06<br>Encyclopedia of Big Data Technologies， <a href="https://doi.org/10.1007/978-3-319-63962-8_207-1" target="_blank" rel="noopener">https://doi.org/10.1007/978-3-319-63962-8_207-1</a></p><h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p>YARN是目前流行的共享集群作业调度和资源管理框架之一。本条目将重点介绍自YARN初始版本推出之后增加的新功能。</p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Apache Hadoop [Apache Hadoop]是广泛采用的MapReduce实现之一 [Dean]。它改变了企业分析海量数据的方式。它可以在数千台机器组成的集群上并行处理数据，不必再让用户来实现复杂的通信模式和容错机制。</p><p>随着逐渐流行， 虽然Hadoop针对MapReduce设计的资源模型比较灵活，但仍无法适合所有的应用，特别是要求低延时或迭代计算的应用。这促使将集群资源管理基础模块从特定的编程模型中解耦出来，从而产生了YARN  [Vavilapalli] 。YARN负责管理集群资源，为应用提供请求资源的通用接口，从而允许将多个应用（包括MapReduce）部署在单个集群上，共享同一个资源管理层。</p><p>YARN是社区驱动的成果，于2011年11月作为Apache Hadoop 0.23版的一部分首次出现。之后，社区的兴趣一直不减。图1显示每月JIRA系统中有100多个涉及YARN的改进项（译注，因Apache Hadoop开发社区使用JIRA系统管理改进项，故也直接代称为JIRA） [YARN JIRA]。得益于社区的持续参与，相当比例的改进项都解决了。仅去年一年内，就有160多位开发者为YARN贡献了代码。</p><p>此外，YARN已经被作为生产系统广泛部署到数百家公司，其中包括雅虎（Oath）、微软、Twitter、LinkedIn、Hortonworks、Cloudera、eBay和阿里巴巴。</p><p>自YARN面世以来，我们观察到现代集群中的以下趋势：</p><p><strong>应用多样性</strong>：用户的兴趣已从批处理分析（如MapReduce）扩展到流式处理、迭代计算（例如机器学习）和交互式计算等。</p><p><strong>大型共享集群</strong>：不是将每个应用分别部署到专用的集群，而是将不同的工作负载整合（Consolidation）到数千乃至数以万计的机器上。整合避免了不必要的数据传输，提高了资源利用率，并支持将不同类型的应用连接（Pipeline）起来。</p><p><strong>高资源利用率</strong>：运行大型集群的成本是很高的。因此，集群管理员需要资源管理器实现高利用率，以改善投资收益。</p><p><strong>可预测的执行</strong>：生产任务通常都设有服务水平目标（SLO），如截止期限，为满足下游服务的数据输入需求，当前服务必须及时完成。对关键业务，运行的可预测性通常比单纯的应用性能更重要。</p><p>多样化的需求给资源管理层带来了新的挑战。为了满足这些新需求，YARN 已经从一个针对批处理分析工作负载的平台演化为一个生产级的通用资源管理器，可以支持大型共享集群中多样的应用和用户需求。下面，我们将首先概述YARN的架构，然后重点介绍近几年添加到YARN的新功能。</p><p><img src="/img/yarn-fig1.jpg" alt="图1. Apache Hadoop发布版本和每月YARN JIRA个数"></p><h1 id="YARN的架构"><a href="#YARN的架构" class="headerlink" title="YARN的架构"></a>YARN的架构</h1><p>YARN采用集中式架构，其中包括单一的资源管理器（RM）组件，负责为提交到集群的作业（Job）分配资源。RM被设计为处理通用的资源请求，而某应用特定的调度逻辑则需封装在应用主节点中（AM）。这使得YARN可以用相同的RM组件支持多种应用。YARN 的架构如图2所示。下面我们介绍它的主要组件。橙色标识出来的新功能将在随后的小节讨论。</p><p><strong>节点管理器（NM）</strong>：NM是在集群的每个工作节点上运行的守护进程。NM负责监控工作节点的可用资源，报告故障并管理容器的生命周期（例如启动、监控、暂停和杀死容器）。</p><p><strong>资源管理器（RM）</strong>：RM运行在一台指定的机器上，在彼此竞争的应用之间分配资源。可以启动多个RM以实现高可用性，但只有一个作为主RM。NM定期向RM汇报状态，RM将其存储为 <strong>集群状态</strong>。为实现扩展性，RM与NM之间的通信是基于心跳机制的。RM还维护着所有应用的资源请求（ <strong>应用状态</strong>）。基于集群的全局视角、应用需求、可用资源、调度优先级和共享策略（例如公平性）， <strong>调度器</strong>匹配应用请求和机器，将资源租约（称为 <strong>容器</strong>）提供给应用。容器是绑定到特定节点的逻辑上的资源组合（例如，2GB RAM，1个CPU）。</p><p>YARN有2个调度程序，即公平（Fair）调度器和容量（Capacity） 调度器。前者强调应用之间（资源份额）的公平性，后者为不同用户组分配特定份额的专有集群资源。</p><p>作业通过 <strong>YARN客户端</strong>协议提交给RM，并通过准入控制阶段，在此期间验证安全凭证并执行多种管理检查。</p><p><strong>应用主节点（AM）</strong>：AM是作业编排器（每个提交的作业有一个AM实例），管理其生命周期的各个方面，包括动态增加或减少资源，管理执行流程（例如，针对Mapper的输出启动对应的Reducer），并处理故障。AM可以运行任何用户代码，用任意编程语言编写。将这些功能划分给AM之后，YARN的架构实现了显著的可扩展性、编程模型的灵活性以及更好的升级/测试支持。</p><p>AM通常需要利用多个节点的资源来完成作业。为了获取容器，AM使用 <strong>AM服务接口</strong>，通过心跳向RM发出资源请求。调度器将资源分配给AM后，RM为该资源生成一个租约。然后，AM获得通知，并将容器租约发给NM，以在该节点启动容器。确认租约有效后，NM启动容器。</p><p>我们将在下文介绍YARN的主要进展，特别是关于资源利用率、扩展性、对服务的支持、运行的可预测性等方面。</p><p><img src="/img/yarn-fig2.jpg" alt="图2. YARN架构和新功能（橙色部分）"></p><h1 id="资源利用率"><a href="#资源利用率" class="headerlink" title="资源利用率"></a>资源利用率</h1><p>YARN的初始版本中，只有当某节点上有未分配的资源时，RM才会将容器分配给该节点。这种有 <strong>保证的（Guaranteed）</strong>分配方式确保了只要AM将容器分配给该节点，就会有足够的资源来立即启动容器。</p><p>尽管这个设计使资源获取是可预见的，但它存在以下缺陷，可能导致资源利用率不理想：</p><p><strong>反馈延迟</strong>：AM-RM和NM-RM之间基于心跳的通信机制会导致从容器结束到RM通知AM启动新容器的这段时间内节点资源闲置。</p><p><strong>低效的资源利用率</strong>：RM在每个节点基于分配的资源启动容器，这可能显著多于实际使用的资源（例如，为容器分配了4GB内存，但仅使用了2GB）。</p><p>在典型的YARN 集群，NM-RM的心跳间隔设置为3秒，AM-RM的心跳间隔随不同应用而变化，但典型值也是若干秒。因此，对于任务较短的工作负载，反馈延迟更为明显。</p><p>下面我们介绍在YARN中引入的提高集群资源利用率的新机制。这些想法首先出现在Mercury（译注：意为水银） [Karanasos]和Yaq系统 [Rasley]，并于Apache Hadoop 2.9版发布 [Distributed scheduling, Opportunistic Scheduling]。</p><p><strong>机会型（Opportunistic）容器</strong>：与保证型（Guaranteed）容器不同，即使在某节点上没有可用资源，机会型容器也会被分派到该NM。这种情况下，机会型容器将被放置到新引入的 <strong>NM队列</strong>中（见图2）。当资源可用时，NM将从队列中挑选一个机会型容器，并且立即开始执行，避免了反馈延迟。</p><p>机会型容器的运行优先级较低，发生资源竞争时，它们可能会被保证型容器抢占。因此，机会型容器可以改善集群资源利用率，而且不会影响保证型容器的执行。此外，初始版本的NM被动地执行从RM发来的无冲突的命令，新的NM使用2个优先级别作为输入进行本地调度决策。例如，低优先级的没有严格执行保证的作业，或者DAG中非关键路径的任务，就很适合使用机会型容器。</p><p>目前由AM确定各容器的执行类型，但系统可以使用自动化策略。AM也可以将机会型容器提升为保证型容器，以使其免于被抢占。</p><p><strong>混合调度</strong>：机会型容器可以由RM集中分配，也可以通过运行在每个NM的本地调度器分布式地分配，并可将容器放置到其它NM上而无需与RM联系（leases containers on other NMs without contacting the RM）。集中分配允许更高质量的放置决策和共享策略。分布式分配提供较低的分配延迟，这很适合较短的任务。为了防止冲突，保证型容器总是由RM分配。</p><p>为了确定放置机会型容器的负载最轻的节点，RM定期收集每个节点上运行和排队容器的信息，并将该信息传递到各本地调度器。为了解决节点间短时的负载不平衡问题，YARN动态地调整容器队列的平衡。</p><p><strong>资源超售（Overcommitment）</strong>：目前，机会型容器用来避免反馈延迟。进行中的开发还将为机会型容器使用 <strong>超售资源 [Utilization-Based Scheduling]</strong>。这种情况下，机会型容器用于回收过量申请的资源，而且不会影响不使用超售资源的那些作业的性能和可预测性。</p><h1 id="集群扩展性"><a href="#集群扩展性" class="headerlink" title="集群扩展性"></a>集群扩展性</h1><p>一个YARN RM可以管理几千个节点。然而，大型云计算公司的生产分析集群通常有几万台机器，超出了YARN 的能力 [Burd]。</p><p>YARN的扩展性受到资源管理器的限制，因为负载随集群节点数量和应用请求（例如运行容器，每秒资源请求）成比例地增加。增加心跳间隔可以提高节点数量方面的扩展性，但不利于利用率 [Vavilapalli]，并仍然存在应用数量增加的问题。</p><p>为此，Apache Hadoop 2.9版 [YARN Federation]引入了 <strong>基于联邦（Federation）</strong>的方法，可以将单个YARN集群扩展到几万个节点。这种方法将集群划分为更小的单元，称为 <strong>子集群</strong>，每个子集群都有自己的YARN RM和NM。联邦系统与子集群的RM协商，让应用仍然认为是在一个统一的大型集群中，允许应用将自己的任务调度到联邦集群的任意节点。</p><p>联邦集群通过 <strong>状态存储</strong>进行协调。状态存储是一个集中式的组件，它保存了（1）每个子集群RM通过心跳信号发送的子集群存活信息和可用资源；（2）部署了AM的所有YARN子集群；（3）用于保证全局集群不变量（Invariants）和执行负载再平衡的策略。</p><p>为了让作业无缝地分布在各子集群中，联邦集群依赖以下的组件：</p><p><strong>路由器</strong>：联邦YARN集群配备了一组路由器，从而对应用屏蔽多RM。每个应用都提交给路由器，路由器按策略确定执行该AM的子集群，从状态存储中获取子集群URL，并将应用提交请求重定向到合适的子集群RM。</p><p><strong>AMRM代理</strong>：该组件作为服务运行在集群的每个NM上，作为AM-RM通信的代理。系统强制要求应用访问其本地的AMRM代理，而不是直接与RM联系。通过动态路由AM-RM消息，AMRM代理为应用提供了对多个YARN RM的透明访问。需要注意的是，AMRM代理也被用于实现机会型容器的本地调度，还可用来以保护系统免受异常AM的干扰。</p><p>这种联邦设计是可扩展的，因为每个RM负责的节点数量是有限的。而且，通过适当的策略，大多数应用将在一个子集群范围之内运行；因此每个RM中的应用的数量也是有限的。由于子集群之间的协调较少，通过增加子集群，整个集群可以几乎线性地扩展。该架构可以在子集群内严格保证调度不变量，同时通过持续的子集群间负载再平衡来保证整个集群的不变量。</p><p>Apache Hadoop底层的HDFS也采用了类似的联邦设计来实现扩展性 [HDFS Federation]。</p><h1 id="长时间服务"><a href="#长时间服务" class="headerlink" title="长时间服务"></a>长时间服务</h1><p>正如前面提到的，YARN最初的目标应用是MapReduce这样的批处理分析作业。然而，如今集群中很大一部分机器专用于流处理、迭代计算、数据密集型交互作业和对延迟敏感的在线应用等负载。与批处理作业不同，这些应用更适合长生存期的容器（从数小时到数月），以分摊容器的初始化成本，减少调度负载或在计算过程中保持状态。这里我们称此类应用为 <strong>服务</strong>。鉴于其长期运行的特性，这些应用还有其它需求，例如支持重新启动、就地升级、监视和组件发现。为了避免使用YARN的低级API来实现这样的操作，用户目前使用了诸如Slider [Apache Slider]之类的AM库。不过，这些外部库只能部分地解决问题，例如，缺乏针对YARN的通用标准来优化跨库的资源需求，或库与YARN之间的版本不兼容。</p><p>为此，即将发布的Apache Hadoop 3.1版中的YARN增加了对长时间运行服务的重点支持，同时支持传统的进程容器和Docker容器。该服务架构允许用户在YARN上部署已有的服务，只需提供一个含有服务规范的JSON文件，而不需要在运行时将这些需求转化为低层次的资源请求（译注：即不需要用户实现AM）。</p><p>YARN服务框架的主要组件是 <strong>容器编排器</strong>，以简化服务部署。它实际是一个AM，基于服务规范，配置所需的RM请求，并启动相应的容器。它涉及各种服务操作，如在指定的依赖下启动组件、监测其健康状态、重启失败的容器、伸缩组件资源、升级组件、以及聚合日志。</p><p>新增的 <strong>REST API服务</strong>允许用户通过简单的命令（译注，如<code>curl</code>）使用与应用框架无关API管理YARN上服务的生命周期。此外，新增的 <strong>DNS服务</strong>允许通过标准的DNS查询来发现服务，通过使用服务的名字，大大简化了服务的故障转移。</p><p><strong>调度服务</strong>：除了上述对服务部署和管理的支持外，服务管理员还要求对容器放置进行精确控制，以优化应用的性能和弹性。例如，服务容器通常需要共同放置在同一节点（亲和性）以降低网络成本，或分散开（反亲和性）以最小化资源干扰和关联故障。为实现最优的服务性能，还可能有更强的约束，比如复杂的应用内或应用间共同放置服务的约束，或限制每个节点或机架上容器的个数。</p><p>放置服务容器时，集群管理员会有自定义的全局优化目标，而且可能存在潜在冲突。例如最小化违反放置约束、最小化资源碎片、最小化负载不平衡或最小化使用机器的个数。由于其长生存期，服务可以容忍比批处理作业调度长的调度等待时间，但不应影响批处理作业的调度延迟（译注：长时间服务调度可参考发表在EuroSys 2018的Medea论文）。</p><p>为了在YARN中实现高质量的服务放置，Apache Hadoop 3.1引入了丰富的放置约束支持 [Placement Constraints]。</p><h1 id="SLO作业"><a href="#SLO作业" class="headerlink" title="SLO作业"></a>SLO作业</h1><p>在生产集群中，通常大部分资源是由 <strong>生产作业</strong>消耗的。这些作业必须满足严格的服务水平目标（SLO），例如截止期限，以便下游服务及时使用计算结果。同时，集群中还提交了大量的较小的 <strong>尽力型（best-effort）作业</strong>，这些作业是探索性的，随机提交的，没有SLO要求，但对完成时间延迟比较敏感。</p><p>资源管理器通常基于 <strong>即时</strong>的作业优先级和份额不变量来为作业分配资源。尽管实现和实施起来比较简单，但即时的资源分配难以在满足其它作业的SLO同时不牺牲尽力型作业的低延迟性。</p><p>为了确保重要的生产作业将来有资源可用，YARN 引入了称为 <strong>预留</strong>的扩展，使用户可以事先预留资源。预留的想法首先出现在Rayon [Curino]（译注：rayon意为人造丝，yarn意为纱，而YARN则是Yet Another Resource Negotiator，即“又一个资源协调器”的缩写），并在Apache Hadoop 2.6版加入YARN。</p><p><strong>预留</strong>：用来确定资源数量和时间需求，并通过可预见的资源分配将作业的截止期限转换为SLO。这些计算在作业执行前就完成了，目的是确保可预见的、及时的执行。为此，YARN提出了预留定义语言（RDL）来表达多样的时间相关的资源需求，如截止期限、延展性（malleable）、整体并行（gang parallelism）以及作业间依赖关系。</p><p><strong>预留计划和调度</strong>：RDL提供了统一和抽象的作业需求表示。<strong>预留规划器</strong>在作业实际运行之前就收到预留请求了，它还执行在线的准入控制。它接受适合该集群一段时间安排内的作业，并拒绝那些无法满足的作业。一旦预留被规划器接受了，将由调度器为该作业动态分配集群资源。</p><p><strong>定期预留</strong>：鉴于大部分生产作业是定期执行的（例如，每小时、每天、或每月），从Apache Hadoop 2.9版开始，YARN 允许用户定义定期预留。定期预留的一个关键特性是，一旦定期作业被接受，其每个实例都将有可预见的资源分配。这使定期生产作业不受其它共享作业的干扰。</p><p><strong>可预测的执行</strong>：定期预留的想法首先在Morpheus（译注：意为睡眠）系统中提出 [Jyothi]。Morpheus分析作业间的数据依赖和传入/传出操作，以自动推测出SLO。它使用了一个资源估计工具，已经在Apache Hadoop 2.9版中实现，根据历史运行记录预测作业的资源需求。根据推测的SLO和资源需求，系统生成定期预留，将其提交，进行规划。这保证了定期生产作业对资源的获取是有保证的，从而其执行是可预测的。</p><h1 id="进一步的改进"><a href="#进一步的改进" class="headerlink" title="进一步的改进"></a>进一步的改进</h1><p>我们在本节将讨论YARN的其它一些改进。</p><p><strong>通用资源</strong>：由于越来越多的具有不同资源需求的异构应用部署到YARN集群，对CPU和内存之外其它类型资源的更细致的控制需求越来越多。例如磁盘带宽、网络I/O、GPU和FPGA等。</p><p>过去在YARN中添加新的资源类型很麻烦，需要修改大量的代码。即将推出的Apache Hadoop 3.1版 [Resource Profiles]使用更灵活的资源模型，允许用户轻松添加新的资源类型。事实上，用户可以在配置文件中定义资源，从而不需要修改代码或重新编译。RM中的主导资源公平调度算法 [Ghodsi]也针对通用资源类型进行了调整。<strong>资源组合（Resource Profile）</strong>可用于AM为容器申请预定义的资源集合。正在进行的工作关注于资源隔离机制，如磁盘、网络和GPU。</p><p><strong>节点标签</strong>：集群管理员可以对具有相似特征的节点进行分组，例如，有公网IP的节点，或用于开发/测试的节点。应用可以请求容器放置到有特定标签的节点上。Apache Hadoop 2.6版的YARN容量调度开始支持 [Node Labels]这个功能。每个节点最多只允许一个标签，这样就可以将集群划分为不重叠的分区。集群管理员可以指定调度队列能够使用的分区份额，以及使用特定分区的队列容量的比例。例如，<code>queue A</code>可能被限制访问有公网IP的节点的比例不可超过30％，并且<code>queue A</code> 的40％必须位于 <strong>dev机器</strong>上。</p><p><strong>更改队列配置</strong>：有几家公司使用YARN的容量调度器在彼此独立的用户之间共享集群。层次结构的队列将组织的各部门的作业隔离开。随着每个部门的资源需求、队列层次结构或集群条件的变化，管理员需要修改分配给每个部门队列以及该部门内部子队列的资源量。但是，重新配置队列有2个主要缺点：</p><p>（1）设置和更改配置是一个繁琐的过程，只能通过修改XML文件来执行;（2）队列所有者不能对其子队列进行修改；必须由集群管理员代他们进行操作。</p><p>为了解决这些缺点，Apache Hadoop 2.9版 [OrgQueue]允许将配置存储在内存数据库中而不是XML文件中。它添加了一个RESTful API，可以通过编程方式修改队列。这还有额外的好处，即可以根据集群条件或组织内部特定的标准，通过自动化工具动态地重新配置队列。队列ACL（译注：访问控制表）允许队列所有者有权限修改其队列结构。</p><p><strong>时间线（Timeline）服务器，TS</strong>：集群中当前和先前提交的作业信息对调试、容量规划和性能调优至关重要。最重要的是，观察历史数据能使我们更好地理解集群和作业的总体行为，从而全面改善系统运行。</p><p>这项工作的第一个实现是应用历史服务器（AHS），它只支持MapReduce作业。AHS被时间线服务器（TS）所取代，后者可以处理通用的YARN应用。在初始版本，TS只在RM部署了单个写入进程和单个读取进程。因此它仅适用于小型集群。</p><p>Apache Hadoop 2.9版对TS的设计做了重大修改 [YARN TS v2]，将数据收集（写入TS）与服务（从TS读取）分离开，并且2种操作都是分布执行的。这改进了扩展性和灵活性。</p><p>新的TS可以在各种粒度收集指标，包括从 <strong>流</strong>（flow, 指一组逻辑划分在一起的YARN应用）到作业、作业的重试、以及容器。它还收集集群范围的数据，例如用户和队列信息，以及配置数据。</p><p>在RM和各NM以服务方式运行的收集器将数据收集起来。每个作业的AM将数据发布到其节点上NM的收集器。同样，每个容器将数据推送到所在节点NM的收集器，而RM将数据发布到其专用收集器。TS读取服务是专用的独立实例，通过REST API提供查询。默认使用Apache HBase [Apache HBase]作为后端存储，它可以扩展到大量的数据和读/写操作。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>YARN于2011年底在Apache Hadoop中引入，旨在打破Hadoop和MapReduce之间的紧密关系，并允许在同一个资源管理器上部署通用应用。目前，YARN已经发展为一个完备的生产级资源管理器，该管理器已部署到数万台机器的共享集群上。它可处理从批处理分析、流式计算、机器学习工作负载、以及低延迟服务等应用，同时实现高资源利用率，并支持SLO和可预测的生产作业负载。每月进行数百个贡献的社区对YARN是至关重要的。</p><p>[Apache Hadoop] Apache Hadoop (2017) <strong>Apache Hadoop</strong>. <code>http://hadoop.apache.org</code><br>[Apache HBase] Apache HBase (2017) <strong>Apache HBase</strong>. <code>http://hbase.apache.org</code><br>[Apache Slider] Apache Slider (2017) <strong>Apache Slider (incubating)</strong>. <code>http://slider.incubator.apache.org</code><br>[Burd] Burd R, Sharma H, Sakalanaga S (2017) <strong>Lessons learned from scaling YARN to 40 K machines in a multitenancy environment</strong>. In: DataWorks Summit, San Jose<br>[Curino] Curino C, Difallah DE, Douglas C, Krishnan S, Ramakrishnan R, Rao S (2014) <strong>Reservation-based scheduling: if you’re late don’t blame us!</strong> In: SoCC<br>[Dean] Dean J, Ghemawat S (2004) <strong>MapReduce: simplified data processing on large clusters</strong>. In: USENIX OSDI<br>[Distributed scheduling] Distributed scheduling (2017) <strong>Extend YARN to support distributed scheduling</strong>. <code>https://issues.apache.org/jira/browse/YARN-2877</code><br>[Ghodsi] Ghodsi A, Zaharia M, Hindman B, Konwinski A, Shenker S, Stoica I (2011) <strong>Dominant resource fairness: fair allocation of multiple resource types</strong>. In: USENIX NSDI<br>[HDFS Federation] HDFS Federation (2017) <strong>Router-based HDFS federation</strong>. <code>https://issues.apache.org/jira/browse/HDFS-10467</code><br>[Jyothi] Jyothi SA, Curino C, Menache I, Narayanamurthy SM, Tumanov A, Yaniv J, Mavlyutov R, Goiri I, Krishnan S, Kulkarni J, Rao S (2016) <strong>Morpheus: towards automated slos for enterprise clusters</strong>. In: USENIX OSDI<br>[Karanasos] Karanasos K, Rao S, Curino C, Douglas C, Chaliparambil K, Fumarola GM, Heddaya S, Ramakrishnan R, Sakalanaga S (2015) <strong>Mercury: hybrid centralized and distributed scheduling in large shared clusters</strong>. In: USENIX ATC<br>[Node Labels] Node Labels (2017) <strong>Allow for (admin) labels on nodes and resource-requests</strong>. <code>https://issues.apache.org/jira/browse/YARN-796</code><br>[Opportunistic Scheduling] Opportunistic Scheduling (2017) <strong>Scheduling of opportunistic containers through YARN RM</strong>. <code>https://issues.apache.org/jira/browse/YARN-5220</code><br>[OrgQueue] OrgQueue (2017) <strong>OrgQueue for easy capacitysched uler queue configuration management</strong>. <code>https://issues.apache.org/jira/browse/YARN-5734</code><br>[Placement Constraints] Placement Constraints (2017) <strong>Rich placement constraints in YARN</strong>. <code>https://issues.apache.org/jira/browse/YARN-6592</code><br>[Rasley] Rasley J, Karanasos K, Kandula S, Fonseca R, Vojnovic M, Rao S (2016) <strong>Efficient queue management for cluster scheduling</strong>. In: EuroSys<br>[Resource Profiles] Resource Profiles (2017) <strong>Extend the YARN resource model for easier resource-type management and profiles</strong>. <code>https://issues.apache.org/jira/browse/YARN-3926</code><br>[Utilization-Based Scheduling] Utilization-Based Scheduling (2017) <strong>Schedule containers based on utilization of currently allocated containers</strong>. <code>https://issues.apache.org/jira/browse/YARN-1011</code><br>[Vavilapalli] Vavilapalli VK, Murthy AC, Douglas C, Agarwal S, Konar M, Evans R, Graves T, Lowe J, Shah H, Seth S, Saha B, Curino C, O’Malley O, Radia S, Reed B, Baldeschwieler E (2013) <strong>Apache Hadoop YARN: yet another resource negotiator</strong>. In: SoCC<br>[YARN Federation] YARN Federation (2017) <strong>Enable YARN RM scale out via federation using multiple RMs</strong>. <code>https://issues.apache.org/jira/browse/YARN-2915</code><br>[YARN JIRA] YARN JIRA (2017) <strong>Apache JIRA issue tracker for YARN</strong>. <code>https://issues.apache.org/jira/browse/YARN</code><br>[YARN TS v2] YARN TS v2 (2017) <strong>YARN timeline service v2</strong>. <code>https://issues.apache.org/jira/browse/YARN-5355</code></p><h1 id="附录：资源超售YARN-1011"><a href="#附录：资源超售YARN-1011" class="headerlink" title="附录：资源超售YARN-1011"></a>附录：资源超售YARN-1011</h1><p>Karthik Kambatla, Haibo Chen，2017-05-30<br><a href="https://issues.apache.org/jira/browse/YARN-1011" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/YARN-1011</a><br><a href="https://issues.apache.org/jira/secure/attachment/12874299/yarn-1011-design-v3.pdf" target="_blank" rel="noopener">https://issues.apache.org/jira/secure/attachment/12874299/yarn-1011-design-v3.pdf</a></p><h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>Yarn根据群集节点的可用资源来为作业分配资源。目前，节点可用资源的计算方法为其“容量”（由<code>yarn.nodemanager.resource.*</code> 配置项确定）减去当前节点上已经分配给容器的资源。容器的资源配额是该容器可以使用的资源额度的上限，其大小是应用请求的。</p><p>在实践中，用户对资源的估计是保守的，原因有：（1）避免任务失败;（2）因为使用了更高级别的抽象（例如Hive），不关注生成的MR / Tez / Spark作业的资源需求。</p><h1 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h1><p>通过使用机会型容器（见YARN-2882，<code>https://issues.apache.org/jira/browse/YARN-2882</code>），将已分配但未使用的资源投机地分配给等待中的请求。这会导致节点资源超售：即节点容纳的容器总额超过了节点的容量。超售的程度应该是可配置的。</p><p>在严重超售的节点上，当容器同时增加资源使用量时，这些容器中的任务可能会严重变慢甚至失败。为了避免这种情况，如果节点利用率超过了配置的阈值，我们建议抢占（译注：杀死）机会型容器。</p><h1 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h1><p>尽管超售有助于提高群集利用率，但我们需要考虑以下约束/目标：</p><ol><li>工作节点不应该因超售而崩溃；</li><li>对保证型容器运行产生的影响应尽可能小。这意味着：（1）立即启动已分配的保证型容器；（2）合理地隔离容器的资源（CPU和内存）；</li><li>集群管理员应该在无需修改应用的情况下启用超售。例如，MR的AM不需要修改；</li><li>应用应该能够选择是否使用机会型容器；</li><li>可选功能：超售的资源应按照与保证型资源相同的比例分配给应用。</li></ol><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h2 id="识别机会"><a href="#识别机会" class="headerlink" title="识别机会"></a>识别机会</h2><p>机会型容器将在节点资源已完全分配但资源利用率低于配置阈值（YARN-4512）时分配 。我们将这个阈值称为超额分配阈值（$T_{alloc}$），它是一个各维度介于0和1之间的向量，其中每个维度表示一种类型的资源。我们建议将此阈值连同容器使用信息一起通过心跳发送到RM。</p><p>需增加的配置项（YANR-6670）：</p><ul><li><code>yarn.nodemanager.overallocation.memory.allocation-threshold</code>：调度器向节点分配机会型容器的节点内存利用率阈值。</li><li><code>yarn.nodemanager.overallocation.cpu.allocation-threshold</code>：调度器向节点分配机会型容器的节点CPU使用率阈值。</li></ul><h2 id="调度机会型容器"><a href="#调度机会型容器" class="headerlink" title="调度机会型容器"></a>调度机会型容器</h2><p>我们建议按队列为机会型容器分配超售资源。也就是说，按与容量/公平性相同比例的队列（YARN-1013 和 YARN-1015）分配容器 。</p><p>目前，在每轮心跳，调度器按优先级依次处理等待中的容器，并尽可能地分配保证型容器。我们建议用另一个迭代来分配机会型容器作为补充。这样，只有在完全分配了节点资源（译注：或保证型容器）后才会触发机会型分配。</p><p>节点上的机会型份额不超过 $T_{alloc}$ 的限值。</p><h2 id="启动机会型容器"><a href="#启动机会型容器" class="headerlink" title="启动机会型容器"></a>启动机会型容器</h2><p>目前，如果节点上存在未分配的资源，我们可以在上面启动机会型容器。启用超售后，如果有已分配但未使用的资源（YARN-6675），我们也建议允许启动机会型容器。因此，启动一个机会型容器的条件是（1）存在未分配的资源，或（2）使用量$&lt;$抢占阈值（稍后详细介绍此阈值）。</p><p>机会型容器的队列应该可以继续运作。</p><h2 id="避免超售的不利影响"><a href="#避免超售的不利影响" class="headerlink" title="避免超售的不利影响"></a>避免超售的不利影响</h2><p>在超售时，机会型容器使用已经分配给保证型容器的资源。调度器根据汇报的资源使用情况分配机会型资源。</p><p>然而，容器的资源使用量，包括保证型和机会型，都随时间而变化。如果不加限制，机会型容器会干扰保证型容器的执行。根据资源的类型，这可能导致容器变慢（CPU，网络等）甚至失败（内存）。在严重超售的情况下，节点本身可能会崩溃。</p><p>为避免这种情况，我们建议在多个层次进行检查：</p><p><strong>抢占</strong></p><p>引入抢占阈值（$T_{preempt}$），也是一个不同维度表示不同资源类型的向量。节点会抢占足够的机会型容器，以保持利用率低于此阈值（YARN-6672）。对于像CPU这样的可延展资源，节点利用率暂时超过抢占阈值是可以的。我们可以考虑引入第二个配置，以确定检查失败的次数，以作为触发抢占的信号。这与我们目前基于<code>procfs</code>的内存限额机制类似。</p><p>请注意，当资源使用超过阈值时抢占容器是一种被动方法。这种方法的有效性取决于我们能多快发现利用率超过了阈值。在我们的原型中，我们发现通过遍历每个容器的利用率（通过解析<code>procfs</code>确定）来计算容器合计的利用率可能需要大约10秒。</p><p>$T<em>{alloc}$与$T</em>{preempt}$之间的较大差距将降低无法超售的可能性，从而减少需要抢占的机会型容器。</p><p><strong>Cgroups（使用Linux容器执行器时，LCE指Linux Container Executor）</strong></p><p>使用LCE时，cgroups提供了一种更加主动的方法来限制资源。</p><p>• <strong>CPU（YARN-6673）</strong>：除了为每个容器设置<code>cpu.cfs_period_us</code>，我们还可以将机会型容器的<code>cpu.shares</code>设置为2，以降低其优先级。</p><p>• <strong>内存：</strong></p><ul><li>软上限（YARN-6674）：当节点内存紧张时，系统会尝试将进程使用的内存限制为不超过软上限。我们可以将机会型和保证型容器的软上限分别设置为`0’和分配额度。</li><li>交换内存上限（YARN-6674）：我们可以将机会型容器的交换内存比例设置为100，这样进程使用的内存就可以完全交换到硬盘。</li><li>低内存（OOM）控制（YARN-6677）：将YARN cgroup资源组的内存额度限制为NM的内存容量。如果合计用量超过了此容量，则所有容器都被暂停并通知NM。NM可以杀死足够的机会型容器。另一个限制内存使用量的方案是对每个容器实施内存限额，以防止瞬间超出限值，这在JVM的容器中很常见。</li></ul><p>除了执行限制之外，我们还可以使用cgroups而不是procfs来监视容器资源使用情况（YARN-6668），如<code>memory.usage</code>。</p><p><strong>低内存清理（OOM Killer）（YARN-1014）：</strong> 在Linux，当触发OOM Killer后，可以配置为先抢占机会型容器。</p><h1 id="未来的工作"><a href="#未来的工作" class="headerlink" title="未来的工作"></a>未来的工作</h1><p>为了尽早整合可用版本，本JIRA旨在实施最简单的超售版本。以下的项作为未来的工作（按优先顺序排列）：</p><ol><li>同一节点内提升机会型容器的优先级：当节点上有可用资源时，考虑在分配新容器之前提升机会型容器的优先级；</li><li>支持非Linux操作系统；</li><li>复杂的和启发式的策略：（1）选择更适合机会型容器的应用，（2）超售的动态阈值；</li><li>跨节点提升机会型容器的优先级；</li><li>使用cgroups进行磁盘和网络隔离：作为磁盘和网络支持功能的一部分（YARN-2139和YARN-2140）。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;YARN资源管理器的研究进展（Advancements in YARN Resource Manager）是大数据技术百科（Encyclopedia of Big Data Technologies，这本书的其它条目质量较差）中的一个条目，是由微软的员工编写的对YARN进展比较全面的综述。&lt;br&gt;YARN-1011是YARN关于资源超售的一个JIRA项，是上面条目提到的一个参考文献，亦翻译后作为附录。&lt;/p&gt;
&lt;p&gt;英文全文：&lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2018/02/yarn-big-data-encyclopedia-2018.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.microsoft.com/en-us/research/uploads/prod/2018/02/yarn-big-data-encyclopedia-2018.pdf&lt;/a&gt;&lt;br&gt;译文全文：[&lt;a href=&quot;https://ying-zhang.github.io/doc/Adv_in_YARN_CN_Ying_201806.pdf&quot;&gt;https://ying-zhang.github.io/doc/Adv_in_YARN_CN_Ying_201806.pdf&lt;/a&gt;]&lt;/p&gt;
    
    </summary>
    
      <category term="yi" scheme="https://ying-zhang.github.io/categories/yi/"/>
    
    
  </entry>
  
  <entry>
    <title>书单</title>
    <link href="https://ying-zhang.github.io/misc/2018/book-list/"/>
    <id>https://ying-zhang.github.io/misc/2018/book-list/</id>
    <published>2018-01-11T16:00:00.000Z</published>
    <updated>2018-12-01T13:51:35.905Z</updated>
    
    <content type="html"><![CDATA[<p>入职半年的Y让我推荐一些书。说来惭愧，自己的水平本来就不怎么样，一年多来浑浑噩噩，难说有资格推荐；再者，怕推荐的书单跟网上搜到的结果也不会有太大区别，还怕不合适的书耽误了他的时间，毕竟他的 <strong>时薪</strong> 比市面上绝大部分书的定价都多得多;-)<br>于是拖着过了元旦，Y的饭都吃过一周多了，不能老是拖着了……</p><a id="more"></a><hr><h1 id="闲言：少读书"><a href="#闲言：少读书" class="headerlink" title="闲言：少读书"></a>闲言：少读书</h1><p>每周二学校图书馆新书上架，我都跑过去看，一般都会有一两本感兴趣的，借来翻翻，大部分下周二就还了，那时又有一批新书上架了。<br>浏览了一下自己的借阅记录，还有向图书馆荐购的记录，加起来两百多条，然而感觉并没有学到什么东西，没有什么印象。值得推荐的倒是有几本书，自己也买了，但内容与目前的学习关联不大，只是作为收藏。</p><p>反思我现在的状态，读书只是习惯为之，或者说是贪小便宜，总想去图书馆看看有没有什么新书，而不是因为学习科研需要找某个方面的资料，才去找书看。结果就是每周至少有两天左右的时间来看这些借来的新书，然而并没有什么收获：</p><ul><li>大部分的书与学术关联不大；</li><li>有些实践入门类的书，又没有动手敲一敲里面的代码，跑一下例子，只是走马观花，抓不住重点；</li><li>难得有一两本好书，比如周老师的西瓜书《机器学习》，还是与自己的方向直接关联不大，而且需要花时间精读才行，往往是买了收藏，就一直放在书架上不动了。</li></ul><p>我这种状态很明显就是在逃避问题，让自己看起来在努力，实际上只是在边缘兜圈子，浪费时间。<br>所以，我觉得追求所谓“读万卷书”是没有必要的，<strong>要有明确的目标再去读一本书</strong> 。</p><hr><h1 id="软件工程，组织管理"><a href="#软件工程，组织管理" class="headerlink" title="软件工程，组织管理"></a>软件工程，组织管理</h1><p>相比于少得可怜的动手写代码的经历，在IT公司实习或工作的实际体验对于我则完全等于〇。<br>以我之前近5年传统行业的工作体验，很希望了解IT公司里是如何分工合作的，如何保证进度和质量，如何培养新人的。前几天老板教育我，看一个人靠不靠谱，要看三点 “<strong>凡事有交代，件件有着落，事事有回音</strong>” 。我听了附和着点头，其实心里马上就想到了四个凡事： “<strong>凡事有章可循；凡事有据可查；凡事有人负责；凡事有人监督</strong>”。显然不是三和四的区别，而是个人和组织的层次之差。<br>初入职场，我觉得学习组织管理方面的知识比单纯提升业务技能更重要一些。</p><ul><li>《构建之法（第3版）》：作者是微软的邹欣，比较新的一本书，网上评价不错。刚买来了，还没看过；</li><li>《观止：微软创建NT和未来的夺命狂奔》：这本书已经绝版了，但个人感觉不输《人月神话》。《人月》取材于OS 360的，而这本书是微软NT的开发记录，类似小说的叙事，读起来很轻松</li><li>《梦断代码》：这是另一个失败项目的故事</li><li>《人月神话》，《代码大全》，《人件》：从亚马逊搜其中任一本，另外两本肯定也会出现在列表里。我本科时读过前面两本。《代码大全》虽然比较厚，但读起来更流畅一些，其中变量命名的一章印象最深。虽说是经典，毕竟是好多年前的作品了，其中有价值观点的可能现在看来已经习以为常了</li><li>《持续交付:发布可靠软件的系统方法》，《高效团队开发:工具与方法》：两本是比较具体的书。流程和工具，其实比什么所谓的“本质”更实在些。质量保障（QA）有所谓六字诀“人，机，料，法，环，测”，法指流程，机指工具，虽然传统软件工程比较关注流程、工具，似乎git/github/gitlab的普及才真正让软件工程落地；料对IT行业可以解释为输入数据，环（境）可能对IT关联不大，至于测，IT定量的东西还不够</li><li>《性能之巅： 洞悉系统、企业与云计算 》：这就是一本关于性能测量的书，作者Gregg是行业专家，比较厚，可以当做参考书</li></ul><p>下面几本是偏管理的，读起来应该比较轻松，我只读过《杜拉拉》。当然，看书学管理是枯燥且低效的，最终还是要在实践中不断学习前人，自己总结摸索。</p><ul><li>《代码整洁之道》</li><li>《IT项目经理成长手记》</li><li>《漫画中国式项目管理(第2版)》</li><li>《从技术走向管理:李元芳履职记》</li><li>《杜拉拉升职记 I》</li><li>《成为技术领导者:掌握全面解决问题的方法》</li></ul><p>《重构》也是一本经典书，但相比《修改软件的艺术》和《遗留系统重建实战》，《重构》更偏代码细节，建议从前两本比较新的书读起。</p><ul><li>《修改软件的艺术》</li><li>《遗留系统重建实战》</li><li>《重构：改善既有代码的设计》</li></ul><h1 id="语言"><a href="#语言" class="headerlink" title="语言"></a>语言</h1><p>Java</p><ul><li>《阿里巴巴Java开发手册》</li><li>《Effective Java, 3rd Edition》：中文版应该快上市了。</li><li>《Java 8实战》</li><li>《Java程序员修炼之道》</li><li>《深入理解Java虚拟机（第2版）》</li><li>《Java并发编程实战》</li></ul><p>其它</p><ul><li>《深入理解C#（第3版）》：C#，可以跟Java做对照</li><li>《C++语言的设计与演化》：C++之父解释对C++设计决策的考虑</li><li>《程序员的自我修养：链接、装载与库》：补上《操作系统》和《编译原理》中间缺失的一环</li></ul><blockquote><p>参考：</p><ul><li><a href="http://www.vaikan.com/books-programmers-dont-really-read/" target="_blank" rel="noopener">最常被程序员们谎称读过的计算机书籍</a></li><li><a href="http://lucida.me/blog/developer-reading-list/" target="_blank" rel="noopener">程序员必读书单 1.0</a></li></ul></blockquote><h1 id="2017年买的书"><a href="#2017年买的书" class="headerlink" title="2017年买的书"></a>2017年买的书</h1><ul><li>《机器学习》（周志华老师的西瓜书，实际是2016年买的，小组经费）</li><li>《深度学习》</li><li>《深度学习：优化与识别》</li><li>《Netty实战》</li><li>《R语言实战（第2版）》</li><li>《Kotlin实战》</li><li>《Scala程序设计（第2版）》</li><li>《Go并发编程实战（第2版）》</li><li>《Linux多线程服务端编程：使用muduo C++网络库》</li><li>《图解Spark： 核心技术与案例实战》</li><li>《性能之巅： 洞悉系统、企业与云计算》（小组经费）    </li><li>《深入理解计算机系统（第3版）》（小组经费）</li><li>《SRE:Google运维解密》 （小组经费）</li><li>《ZooKeeper:分布式过程协同技术详解》 （小组经费）</li><li>《垃圾回收算法手册：自动内存管理的艺术》</li><li>《现代操作系统（原书第4版）》</li><li>《大型汽轮发电机设计、制造与运行》</li></ul><p>虽然买了好几本“实战”，但都没实践过……</p><h1 id="2018年买的书"><a href="#2018年买的书" class="headerlink" title="2018年买的书"></a>2018年买的书</h1><ul><li>《构建之法（第3版）》</li><li>《设计数据密集型应用（影印版）Designing data-intensive applications》，中文版是《数据密集型应用系统设计》</li><li>《深入理解并行编程》：英文原书： <a href="(https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html">Is Parallel Programming Hard, And, If So, What Can You Do About It?</a>)</li><li>《深入浅出强化学习》</li><li>《人工智能简史》作者：尼克</li><li>《深入浅出Rust》</li><li>《毛泽东选集》 第1-4卷</li><li>《面向计算机科学的数理逻辑 - 系统建模与推理》</li><li>《云系统管理：大规模分布式系统设计与运营 - 卷 2》</li><li>《软件工程：实践者的研究方法（原书第8版）》</li><li>《Julia数据科学应用》</li><li>《etcd技术内幕》</li><li>《图解性能优化》</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;入职半年的Y让我推荐一些书。说来惭愧，自己的水平本来就不怎么样，一年多来浑浑噩噩，难说有资格推荐；再者，怕推荐的书单跟网上搜到的结果也不会有太大区别，还怕不合适的书耽误了他的时间，毕竟他的 &lt;strong&gt;时薪&lt;/strong&gt; 比市面上绝大部分书的定价都多得多;-)&lt;br&gt;于是拖着过了元旦，Y的饭都吃过一周多了，不能老是拖着了……&lt;/p&gt;
    
    </summary>
    
      <category term="misc" scheme="https://ying-zhang.github.io/categories/misc/"/>
    
    
  </entry>
  
  <entry>
    <title>CentOS 7 安装TensorFlow GPU深度学习环境</title>
    <link href="https://ying-zhang.github.io/setup/2017/setup-tensorflow-gpu-centos7/"/>
    <id>https://ying-zhang.github.io/setup/2017/setup-tensorflow-gpu-centos7/</id>
    <published>2017-12-03T16:00:00.000Z</published>
    <updated>2018-06-10T02:57:29.277Z</updated>
    
    <content type="html"><![CDATA[<p>在CentOS 7上安装Nvidia GTX 1080 Ti显卡的驱动，以及TensorFlow GPU等深度学习开发环境。</p><a id="more"></a><hr><p>上周老板突然说要给机房的Dell服务器分别装两个显卡，让我去看一下，然后把支持GPU的深度学习开发环境搭起来。装显卡是供应商的一个小哥动手的，基本顺利，遇到的小问题是电源供电不足，需要改一下iDrac中的电源设置，将服务器的两路电源互为备用模式改为两路同时供电，这样功率才够跑两个显卡。</p><p>网上一搜，就有不少CentOS上搭环境的文章了，但 1）相关开源项目发展太快，2）不同需求的用户可以有针对性的简化配置过程，所以我把集群上实测过的步骤记录下来。因为自己完全是门外汉，所以还没有涉及具体的深度学习知识。</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>网上相关文章的步骤大多是先安装驱动，再安装CUDA，还需要安装C++编译器（g++或msvc），再安装cuDNN库，最后通过<code>pip</code>或<code>conda</code>再安装Tensorflow。<a href="https://www.tensorflow.org/install/install_linux" target="_blank" rel="noopener">TensorFlow官网上的安装说明</a>以及 <a href="https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/tensorflow/" target="_blank" rel="noopener">Nvidia官网上的安装说明</a>亦是如此。</p><p>CUDA（Compute Unified Device Architecture，统一计算架构）是针对GPU计算加速的开发工具包，就像Windows SDK，或者JDK一样，一些深度学习库（比如TensorFlow）的底层是C++调用的CUDA库，它们提供给深度学习开发者的多是 Python 包装过的接口。一般的开发者直接用这些Python库就可以设计出多种多样的深度学习模型，不再需要跟CUDA打交道。</p><p>如果<strong>不需要从源码编译TensorFlow</strong>，就没必要安装NVIDIA官网上的那个一个多GB的CUDA包和cuDNN库。直接通过<del><code>pip</code>或</del><code>conda</code>安装的<code>tensorflow-gpu</code>库就自带了对应版本的cuda动态链接库，包括 <strong>libnvrtc-builtins.so，libnvrtc.so，libnvToolsExt.so，libnvvm.so，libcudart.so，libcublas.so，libcudnn.so，libcurand.so，libcufft.so，libcusolver.so，libcusparse.so</strong> 等，还有<strong>Intel MKL库</strong>。</p><p>最近（2017-12-4）Nvidia官网上的CUDA版本已经是9.0，而TensorFlow 1.4 使用的是cuda 8.0，cuDNN则是6.0，python又有2.7、3.5、3.6版。各种版本组合起来还有点麻烦呢。</p><p>我们先从显卡驱动开始。</p><h1 id="安装显卡驱动"><a href="#安装显卡驱动" class="headerlink" title="安装显卡驱动"></a>安装显卡驱动</h1><p>先安装一下<code>pciutils</code>，以使用<code>lspci</code>： <code>yum install -y pciutils</code>。<br>看看显卡硬件是不是插好了，执行<code>lspci | grep NVIDIA</code>，可见已经安装了两个GeForce GTX 1080 Ti显卡：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@n170 ~]# lspci | grep NVIDIA</span><br><span class="line">03:00.0 VGA compatible controller: NVIDIA Corporation GP102 [GeForce GTX 1080 Ti] (rev a1)</span><br><span class="line">03:00.1 Audio device: NVIDIA Corporation GP102 HDMI Audio Controller (rev a1)</span><br><span class="line">82:00.0 VGA compatible controller: NVIDIA Corporation GP102 [GeForce GTX 1080 Ti] (rev a1)</span><br><span class="line">82:00.1 Audio device: NVIDIA Corporation GP102 HDMI Audio Controller (rev a1)</span><br></pre></td></tr></table></figure><p>然后安装内核驱动（这里无需禁用<code>nouveau</code>，在下面的安装过程中会自动禁用）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 参考：https://www.dedoimedo.com/computers/centos-7-nvidia-second.html</span><br><span class="line"># 及 https://www.youtube.com/watch?v=C9Yf71qh0i4</span><br><span class="line"></span><br><span class="line">sudo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org </span><br><span class="line"># sudo rpm -Uvh  http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span><br><span class="line">sudo yum install http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span><br><span class="line">sudo yum install   nvidia-detect  # 这个 nvidia-detect 的输出就是字符串 kmod-nvidia，所以不安装也可以。。。</span><br><span class="line">sudo yum install $(nvida-detect)  # 这个命令跟下面的是等效的</span><br><span class="line">sudo yum install   kmod-nvidia</span><br><span class="line">sudo reboot # 必须重启才能加载显卡内核模块 nvidia.ko 等</span><br></pre></td></tr></table></figure></p><p>重启后可通过 <code>lsmod | grep nvidia</code>，或在 <code>/lib/modules/`uname -r`/modules.dep</code> 查看。<br>还可以执行<code>cat /proc/driver/nvidia/version</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@n170 ~]# cat /proc/driver/nvidia/version </span><br><span class="line">NVRM version: NVIDIA UNIX x86_64 Kernel Module  384.98  Thu Oct 26 15:16:01 PDT 2017</span><br><span class="line">GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)</span><br></pre></td></tr></table></figure></p><blockquote><p>Ubuntu系统上的命令是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 参考：https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/tensorflow/</span><br><span class="line"></span><br><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa </span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install nvidia- # 敲到 nvidia- 之后，按一下Tab键，稍等一会，会列出补全项，显示目前最新的是387，</span><br><span class="line"># 就是说完整的命令是</span><br><span class="line"></span><br><span class="line">sudo apt install nvidia-387</span><br><span class="line"></span><br><span class="line"># 注意，不要选择 378 版，据说会造成无限重试登录</span><br><span class="line"># 安装后也要重启系统</span><br></pre></td></tr></table></figure></p></blockquote><p>重启后查看驱动是否安装正确，执行<code>nvidia-smi</code>（还可以执行<code>watch -n 1 nvidia-smi</code>持续监控）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@n170 ~]# nvidia-smi</span><br><span class="line">Mon Dec  4 16:03:57 2017       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 384.98                 Driver Version: 384.98                    |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |</span><br><span class="line">|  0%   29C    P8     8W / 250W |      0MiB / 11172MiB |      0%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   1  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |</span><br><span class="line">|  0%   30C    P8     9W / 250W |      0MiB / 11172MiB |      0%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure></p><p><code>gpustat</code>是一个输出格式比较简单的工具，通过<code>pip install gpustat</code>安装后，输出格式如下（其中n170是机器名）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@n170 ~]# gpustat</span><br><span class="line">n170  Mon Dec  4 16:07:10 2017</span><br><span class="line">[0] GeForce GTX 1080 Ti | 28&apos;C,   0 % |     0 / 11172 MB |</span><br><span class="line">[1] GeForce GTX 1080 Ti | 31&apos;C,   0 % |     0 / 11172 MB |</span><br></pre></td></tr></table></figure></p><h1 id="安装-Anaconda-和-Python-3-6"><a href="#安装-Anaconda-和-Python-3-6" class="headerlink" title="安装 Anaconda 和 Python 3.6"></a>安装 Anaconda 和 Python 3.6</h1><p>这里选择的Python版本是3.6，但不是从Python官网或yum安装的，而是Anaconda集成环境内置的版本，这个集成环境还有<code>conda</code>包管理器，<code>jupyter notebook</code>和<code>numpy</code>，<code>pandas</code>等一些常用的包。</p><p>Anaconda官网下载页是[<a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">https://www.anaconda.com/download/</a>] ，不过我们从清华的镜像站下载，这样下载速度快一点[<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.0.1-Linux-x86_64.sh" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.0.1-Linux-x86_64.sh</a>] 。虽然这个安装文件后缀是<code>.sh</code>，但实际的二进制安装文件都打包在里面了，有525MB。</p><p>安装过程需要用到<code>bzip2</code>，先安装一下<code>sudo yum install -y bzip2</code><br>执行 <code>bash Anaconda3-5.0.1-Linux-x86_64.sh</code> 开始安装，敲回车显示 license agreement ，敲几次空格翻到底，然后输入<code>yes</code>接受协议，再敲回车，安装到默认的路径<code>$HOME/anaconda3</code>，如果这个路径已经存在，就会安装失败，需要删掉或另选路径。<br>安装脚本还会在<code>.bashrc</code>的<code>PATH</code>环境变量加上安装路径。安装结束后，执行<code>source .bashrc</code>，更新<code>PATH</code>环境变量，这时系统的<code>python</code>命令已经变成Anaconda安装的Python 3.6了（因为安装程序把<code>$HOME/anaconda3/bin</code>加在了<code>PATH</code>最前面）。</p><blockquote><p>为了让其他用户也能使用Anaconda，可将其安装到系统目录，如<code>/opt/anaconda3</code>，并修改系统的<code>PATH</code><br>静默模式安装Anaconda：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">curl -kO https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.0.1-Linux-x86_64.sh</span><br><span class="line">bash ~/Anaconda3-5.0.1-Linux-x86_64.sh -b -p   /opt/anaconda3</span><br><span class="line">echo &apos;export PATH=/opt/anaconda3/bin:$PATH&apos; &gt;&gt; /etc/profile</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><p>更改<code>conda</code>源：执行<br><code>conda config --add channels &#39;https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/&#39;</code><br><code>conda config --set show_channel_urls yes</code><br>这两个命令其实是把配置项写到了<code>~/.condarc</code>文件，还可以在这里设置http代理：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">show_channel_urls: true</span><br><span class="line"></span><br><span class="line">proxy_servers:</span><br><span class="line">    http:  http://127.0.0.1:1080</span><br><span class="line">    https: http://127.0.0.1:1080</span><br><span class="line"></span><br><span class="line">ssl_verify: False</span><br></pre></td></tr></table></figure></p></blockquote><h1 id="安装-TensorFlow"><a href="#安装-TensorFlow" class="headerlink" title="安装 TensorFlow"></a>安装 TensorFlow</h1><p>执行 <code>conda install tensorflow-gpu</code>，注意，安装的版本是 <code>1.3.0-py36cuda8.0cudnn6.0_1</code> ，不是最新的<code>1.4.0</code>版，不过好处是开箱即用，就这句命令就搞定了。cuda相关的动态库都已经安装在了<code>$HOME/anaconda3/lib</code>。</p><p>执行一下官网的测试例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@n170 ~]# python</span><br><span class="line">Python 3.6.2 |Anaconda custom (64-bit)| (default, Sep 22 2017, 02:03:08) </span><br><span class="line">[GCC 7.2.0] on linux</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">&gt;&gt;&gt; import tensorflow as tf</span><br><span class="line">&gt;&gt;&gt; hello = tf.constant(&apos;Hello, TensorFlow!&apos;)</span><br><span class="line">&gt;&gt;&gt; sess = tf.Session()</span><br><span class="line">&gt;&gt;&gt; print(sess.run(hello))</span><br><span class="line">b&apos;Hello, TensorFlow!&apos;</span><br><span class="line">&gt;&gt;&gt; with tf.Session():</span><br><span class="line">...     a=tf.constant([1.0, 1.0, 1.0, 1.0])</span><br><span class="line">...     b=tf.constant(2.0, shape=[4])</span><br><span class="line">...     out=tf.add(a,b)</span><br><span class="line">...     print(&quot;result:&quot;,out.eval())</span><br><span class="line">... </span><br><span class="line">result: [ 3.  3.  3.  3.]</span><br></pre></td></tr></table></figure></p><h2 id="TensorFlow-CPU版"><a href="#TensorFlow-CPU版" class="headerlink" title="TensorFlow CPU版"></a>TensorFlow CPU版</h2><p>TensorFlow 使用<strong>CPU</strong>的官方版本没有使用SSE等向量化指令，执行时有Warning<br><code>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.</code> 。</p><p>禁用该Warning可添加环境变量 <code>export TF_CPP_MIN_LOG_LEVEL=2</code>。<br>当然最好的解决方案是 <strong>重新构建</strong>TensorFlow，开启SSE，AVX的编译选项。</p><blockquote><p>参考：</p><ul><li><a href="https://www.tensorflow.org/install/install_sources" target="_blank" rel="noopener">https://www.tensorflow.org/install/install_sources</a></li><li><a href="https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture" target="_blank" rel="noopener">https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture</a></li><li><a href="https://github.com/tensorflow/tensorflow/issues/8037" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/issues/8037</a> </li><li><a href="https://stackoverflow.com/questions/41293077/how-to-compile-tensorflow-with-sse4-2-and-avx-instructions" target="_blank" rel="noopener">https://stackoverflow.com/questions/41293077/how-to-compile-tensorflow-with-sse4-2-and-avx-instructions</a></li></ul></blockquote><p>下面的构建过程是在Ubuntu 16.04的容器中完成的。涉及到机器的指令集，CPU型号是 i7-6700 CPU @ 3.40GHz。</p><h3 id="安装bazel"><a href="#安装bazel" class="headerlink" title="安装bazel"></a>安装bazel</h3><p>安装必要的软件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt install git wget</span><br><span class="line">apt install openjdk-8-jdk pkg-config zip g++ zlib1g-dev unzip python</span><br></pre></td></tr></table></figure></p><p>修改系统默认的python为上面安装的python3.5<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /usr/bin/python3.5 /usr/local/bin/python</span><br></pre></td></tr></table></figure></p><p>下载bazel的安装包，<br><a href="https://github.com/bazelbuild/bazel/releases/download/0.9.0/bazel-0.9.0-without-jdk-installer-linux-x86_64.sh" target="_blank" rel="noopener">https://github.com/bazelbuild/bazel/releases/download/0.9.0/bazel-0.9.0-without-jdk-installer-linux-x86_64.sh</a></p><p>然后执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash bazel-0.9.0-without-jdk-installer-linux-x86_64.sh</span><br></pre></td></tr></table></figure></p><h3 id="构建TensorFlow-CPU版"><a href="#构建TensorFlow-CPU版" class="headerlink" title="构建TensorFlow CPU版"></a>构建TensorFlow CPU版</h3><p>下载1.4版的源码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone -b r1.4 --depth=1 https://github.com/tensorflow/tensorflow</span><br></pre></td></tr></table></figure></p><p>安装必要的python包。<br>注意，<strong>不要用pip3安装numpy</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt install python3-numpy python3-dev python3-pip python3-wheel</span><br></pre></td></tr></table></figure></p><p>配置构建参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd tensorflow</span><br><span class="line">./configure</span><br></pre></td></tr></table></figure></p><p>敲回车接受默认的bazel和python3.5路径，后面的其它选项均选择 n，最后提示使用本机的CPU架构作为编译选项，因为现在的CPU都是支持SSE，AVX等指令的，所以也就会在构建选项中加入了相应的选项。</p><p>开始构建，约二十多分钟<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bazel build --incompatible_load_argument_is_label=false \</span><br><span class="line"> -c opt --copt=-march=native //tensorflow/tools/pip_package:build_pip_package</span><br></pre></td></tr></table></figure></p><p>构建完成后，将其打包为whl<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bazel-bin/tensorflow/tools/pip_package/build_pip_package /root/</span><br><span class="line">ls /root</span><br><span class="line"></span><br><span class="line"># tensorflow-1.4.1-cp35-cp35m-linux_x86_64.whl</span><br></pre></td></tr></table></figure></p><p>保存上面打包好的whl，可以安装到其它Linux系统上。</p><hr><h1 id="在docker容器中的TensorFlow环境"><a href="#在docker容器中的TensorFlow环境" class="headerlink" title="在docker容器中的TensorFlow环境"></a>在docker容器中的TensorFlow环境</h1><p>需要安装<code>nvidia-container-runtime</code>插件，才能正确运行支持GPU的容器。参考：[<a href="https://github.com/NVIDIA/nvidia-docker]。" target="_blank" rel="noopener">https://github.com/NVIDIA/nvidia-docker]。</a></p><blockquote><p>注意，安装过程会 <strong>覆盖</strong> <code>/etc/docker/daemon.json</code> 配置文件！需要提前备份。</p></blockquote><p>安装步骤是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/centos7/x86_64/nvidia-docker.repo | tee /etc/yum.repos.d/nvidia-docker.repo</span><br><span class="line"></span><br><span class="line">yum install -y nvidia-docker2</span><br><span class="line">pkill -SIGHUP dockerd</span><br></pre></td></tr></table></figure></p><p>安装后的<code>/etc/docker/daemon.json</code> 如下（阿里云的仓库镜像是后来添加的）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@n170 ~]# cat /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;registry-mirrors&quot;: [&quot;https://lmigye0h.mirror.aliyuncs.com&quot;],</span><br><span class="line">    &quot;runtimes&quot;: &#123;</span><br><span class="line">        &quot;nvidia&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;,</span><br><span class="line">            &quot;runtimeArgs&quot;: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中增加了<code>nvidia-container-runtime</code>这个运行时插件，这是<code>nvidia-docker</code> v2 的实现方式了，运行一个容器验证一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvidia-docker run --rm nvidia/cuda nvidia-smi</span><br><span class="line">nvidia-docker run --rm -e NVIDIA_VISIBLE_DEVICES=1 nvidia/cuda nvidia-smi</span><br></pre></td></tr></table></figure></p><p>其中环境变量<code>NVIDIA_VISIBLE_DEVICES</code>是指定GPU设备的可见性，可以是 0,1,… 这样逗号分隔的一个或多个GPU id，也可以是all或none。<br>参考：<a href="https://github.com/nvidia/nvidia-container-runtime#nvidia_visible_devices" target="_blank" rel="noopener">https://github.com/nvidia/nvidia-container-runtime#nvidia_visible_devices</a></p><p>其实<code>nvidia-docker</code>只是一个包装脚本，实际执行的命令是<code>docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi</code> 。</p><p>至于TensorFlow的容器，执行<br><code>docker run --runtime=nvidia -ti --rm -p 8000:8888 -p 6006:6006 tensorflow/tensorflow:latest-gpu</code></p><p>这个镜像有3.36GB。8888端口是jupyter notebook的，6006是tensorboard的端口，因为我的这台机器的8888端口被占用了，所以映射到了8000。<br>容器启动后，会输出jupyter notebook的访问token，在浏览器输入主机的IP（假设为2.2.2.170）和映射端口号（这里是8000，不是默认的8888），即<br><a href="http://2.2.2.170:8000/?token=79f542ddc22fb567f3c2900c9310f1ce30847d5c5f927cba" target="_blank" rel="noopener">http://2.2.2.170:8000/?token=79f542ddc22fb567f3c2900c9310f1ce30847d5c5f927cba</a><br>就会打开jupyter notebook，里面有三个TensorFlow入门介绍的ipynb文件，这样就可以编辑运行Python代码了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@n170 ~]# docker run --runtime=nvidia -ti --rm -p 8000:8888 -p 6006:6006 tensorflow/tensorflow:latest-gpu</span><br><span class="line">[I 03:08:12.136 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret</span><br><span class="line">[W 03:08:12.159 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.</span><br><span class="line">[I 03:08:12.165 NotebookApp] Serving notebooks from local directory: /notebooks</span><br><span class="line">[I 03:08:12.165 NotebookApp] 0 active kernels</span><br><span class="line">[I 03:08:12.165 NotebookApp] The Jupyter Notebook is running at:</span><br><span class="line">[I 03:08:12.165 NotebookApp] http://[all ip addresses on your system]:8888/?token=79f542ddc22fb567f3c2900c9310f1ce30847d5c5f927cba</span><br><span class="line">[I 03:08:12.165 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).</span><br><span class="line">[C 03:08:12.166 NotebookApp] </span><br><span class="line">    </span><br><span class="line">    Copy/paste this URL into your browser when you connect for the first time,</span><br><span class="line">    to login with a token:</span><br><span class="line">        http://localhost:8888/?token=79f542ddc22fb567f3c2900c9310f1ce30847d5c5f927cba</span><br><span class="line"></span><br><span class="line">[root@n170 ~]# # 按 Ctrl + p, q 键退出容器交互终端，容器仍在后台运行</span><br></pre></td></tr></table></figure><blockquote><p>Anaconda 中也有jupyter notebook，在主机执行命令<code>jupyter notebook</code>就会运行后台服务，并启动浏览器打开页面。<br>默认只能允许localhost访问，如果需要设置别的机器也可以通过主机的IP地址访问notebook，可以参考 [<a href="http://jupyter-notebook.readthedocs.io/en/stable/public_server.html" target="_blank" rel="noopener">http://jupyter-notebook.readthedocs.io/en/stable/public_server.html</a>] 。</p><p>notebook中用matplotlib画图，如果不想写<code>plt.show()</code>，可以在代码前加上<code>%matplotlib inline</code>指令，这样执行<code>plt.plot(...)</code>就会输出图形。</p></blockquote><h1 id="pip-和-cuda"><a href="#pip-和-cuda" class="headerlink" title="pip 和 cuda"></a>pip 和 cuda</h1><p>如果不是按上面小节的步骤使用<code>conda</code>，就要按照教程的步骤，先安装cuda了。</p><blockquote><p>pip换源，在文件<code>$HOME/.pip/pip.conf</code> 或 <code>/etc/pip.conf</code> 中添加<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">trusted-host = mirrors.tuna.tsinghua.edu.cn</span><br><span class="line">index-url = https://mirrors.tuna.tsinghua.edu.cn/pypi/simple</span><br></pre></td></tr></table></figure></p></blockquote><p>没有安装cuda，直接执行<code>pip install tensorflow-gpu</code>，取决于系统的Python版本，不论2.7，3.5或3.6版，都可以安装对应1.4.0版本，但执行上面的测试例子，就会报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">... ...</span><br><span class="line">ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure></p><p>就是说找不到cuda的动态库。</p><blockquote><p>前面也提到了，其实cuda类似JDK，但Nvidia没有把cuda的动态库打包单独提供（类似JRE）。<br><code>conda</code>自己打包了需要的动态库（cudatoolkit，cudnn），可以一键安装，但<code>pip</code>就没有这么贴心了，需要安装完整版的cuda SDK。</p></blockquote><p>需要下载的文件和具体安装步骤可见[<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads</a>] ，目前Nvidia官网提供的是cuda 9.0（不知向前兼容性如何），旧版cuda的下载链接是[<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit-archive</a>] ，还要注册一下，然后下载并安装cuDNN的库。</p><p>如果之前没有安装显卡驱动的话，按上面官网的介绍，以为上面的步骤会把cuda 9.0和内核驱动一起安装上，而且确实安装了名为<code>nvidia-kmod</code>的包，但重启后执行<code>nvidia-smi</code>，发现并没有安装成功，不知是什么问题。<br>所以还是要按照更前面小节的步骤从elrepo安装<code>kmod-nvidia</code>包，不过安装过程会有包冲突，需要根据提示信息卸载：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo yum erase 1:nvidia-kmod-384.81-2.el7.x86_64</span><br><span class="line">sudo yum erase 1:xorg-x11-drv-nvidia-384.81-1.el7.x86_64</span><br><span class="line">sudo yum-config-manager --disable cuda-9-0-local</span><br></pre></td></tr></table></figure></p><p>之后再重新执行安装<code>kmod-nvidia</code>的命令，重启后验证安装是否正确。再增加环境变量<br><code>export LD_LIBRARY_PATH=/usr/local/cuda/lib64/:$LD_LIBRARY_PATH</code><br>TensorFlow应该就可以找到需要的动态库了。</p><h1 id="深度学习框架"><a href="#深度学习框架" class="headerlink" title="深度学习框架"></a>深度学习框架</h1><p>参考：[<a href="https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software</a>]</p><p>比较常见的几个框架有：</p><ul><li>Tensorflow : Google的项目，参考TensorFlow OSDI`2016的论文，设计目标是在大规模集群和异构硬件（GPU，TPU，ASIC等）上支持深度学习网络的训练和应用</li><li>MXNet：由<a href="https://www.cs.cmu.edu/~muli/" target="_blank" rel="noopener">CMU的李沐博士</a> ，<a href="https://homes.cs.washington.edu/~tqchen/" target="_blank" rel="noopener">华盛顿大学的陈天齐博士</a> 等开发的项目，他还有一篇博客介绍了<a href="http://mli.github.io/2015/12/03/mxnet-overview/" target="_blank" rel="noopener">MXNet设计和实现</a> 。目前是Apache的孵化项目，Amazon也在推广MXNet（李沐博士在Amazon工作）。在MXNet的基础上，他们还发布了<a href="http://mp.weixin.qq.com/s/_9aY-7aTZDOjeWFKntLnXA" target="_blank" rel="noopener">更灵活的前端Gluon（胶子）</a> 和<a href="https://zhuanlan.zhihu.com/p/29914989" target="_blank" rel="noopener">更可拓展的后端NNVM compiler</a></li><li>Cognitive Toolkit（CNTK）：这是微软的深度学习项目</li><li>Theano：蒙特利尔大学MILA实验室开发的项目，2017年11月15日发布1.0版后就不再继续开发</li><li>PyTorch：是基于Lua的Torch项目的Python版本，由Facebook开发</li><li>Caffe2，Caffe：是由<a href="http://daggerfs.com" target="_blank" rel="noopener">UC Berkeley的贾扬清博士</a> 开发的，他已经在Facebook工作，所以Caffe2也是Facebook的一个项目</li><li>Keras：这个项目是对一些深度学习项目的更高层抽象和统一包装，官方支持的后端有TensorFlow，CNTK和Theano，有些深度学习项目也会提供对Keras的支持。当然，有的项目，像PyTorch，本身的抽象就比较高层，与Keras相当，另外像MXNet自己也有类似的前端Gluon。</li></ul><p>从Wiki上的比较列表来看，对深度学习框架的关注点主要有：是否支持GPU加速，支持分布式集群，自动推导梯度，支持的网络类型（CNN，RNN等），是否有预先训练的模型等。<br>问了两位搞机器学习方向的同学，他们觉得TensorFlow偏底层，工程化，不如PyTorch写代码直观，Keras虽然理念很好，但性能上还差一点。他们目前还是用单机的GPU来训练模型，跑一次也要不少时间，但还没有准备搞TensorFlow那种分布式计算集群。</p><p>对DNN的了解太少了，要抓紧时间啊！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在CentOS 7上安装Nvidia GTX 1080 Ti显卡的驱动，以及TensorFlow GPU等深度学习开发环境。&lt;/p&gt;
    
    </summary>
    
      <category term="setup" scheme="https://ying-zhang.github.io/categories/setup/"/>
    
    
  </entry>
  
  <entry>
    <title>【译文修订】使用Borg在Google管理大规模集群</title>
    <link href="https://ying-zhang.github.io/yi/2017/x-eurosys15-borg-cn/"/>
    <id>https://ying-zhang.github.io/yi/2017/x-eurosys15-borg-cn/</id>
    <published>2017-10-30T16:00:00.000Z</published>
    <updated>2018-06-10T02:47:26.788Z</updated>
    
    <content type="html"><![CDATA[<p>发表于EuroSys 2015的 <strong><em>Large-scale cluster management at Google with Borg</em></strong> 详细介绍了Google的Borg资源管理器。已经有网友“难易（HardySimpson）” 翻译了此文，这里对其稍作修订。之前读过两三遍此文，每遍都感觉有新的体会，这次修订就是为了更仔细地读一遍。</p><a id="more"></a><hr><h1 id="Large-scale-cluster-management-at-Google-with-Borg"><a href="#Large-scale-cluster-management-at-Google-with-Borg" class="headerlink" title="Large-scale cluster management at Google with Borg"></a>Large-scale cluster management at Google with Borg</h1><h1 id="使用Borg在Google管理大规模集群"><a href="#使用Borg在Google管理大规模集群" class="headerlink" title="使用Borg在Google管理大规模集群"></a>使用Borg在Google管理大规模集群</h1><p>作者：Abhishek Vermay, Luis Pedrosaz, Madhukar Korupolu, David Oppenheimer, Eric Tune, John Wilkes</p><p>英文原文PDF下载地址 </p><ul><li>EuroSys 15 @ ACM DL [<a href="https://dl.acm.org/citation.cfm?doid=2741948.2741964" target="_blank" rel="noopener">https://dl.acm.org/citation.cfm?doid=2741948.2741964</a>] </li><li>Google Research [<a href="http://ai.google.com/pubs/pub43438" target="_blank" rel="noopener">http://ai.google.com/pubs/pub43438</a>]</li><li>MIT 6.824 课程页 [<a href="https://pdos.csail.mit.edu/6.824/papers/borg.pdf" target="_blank" rel="noopener">https://pdos.csail.mit.edu/6.824/papers/borg.pdf</a>]</li><li>转存到GitHub的PDF [<a href="https://ying-zhang.github.io/doc/EuroSys15_Borg.pdf">https://ying-zhang.github.io/doc/EuroSys15_Borg.pdf</a>]</li></ul><p><strong>中文译文全文PDF</strong> [<a href="https://ying-zhang.github.io/doc/EuroSys15_Borg_CN_Ying_201806.pdf">https://ying-zhang.github.io/doc/EuroSys15_Borg_CN_Ying_201806.pdf</a>]</p><hr><blockquote><p>因为改动太多，就不列举了。可以对比一下摘要。</p></blockquote><p><a href="https://my.oschina.net/HardySimpson/blog/515398" target="_blank" rel="noopener">原译者：难易</a></p><blockquote><p><strong>修订：Ying 2017-11,2018-06</strong></p></blockquote><p>最近又看到一版译文<a href="http://geek.csdn.net/news/detail/189597" target="_blank" rel="noopener">深度译文｜Google的大规模集群管理系统Borg - 王勇桥</a> 。</p><blockquote><p>原文：<br>Google’s Borg system is a cluster manager that runs hundreds of thousands of jobs, from many thousands of different applications, across a number of clusters each with up to tens of thousands of machines.<br>It achieves high utilization by combining admission control, efficient task-packing, over-commitment, and machine sharing with process-level performance isolation. <strong>It supports high-availability applications with runtime features that minimize fault-recovery time, and scheduling policies that reduce the probability of correlated failures.</strong> Borg simplifies life for its users by offering a declarative job specification language, name service integration, real-time job monitoring, and tools to analyze and simulate system behavior.<br>We present a summary of the Borg system architecture and features, important design decisions, a quantitative analysis of some of its policy decisions, and a qualitative examination of lessons learned from a decade of operational experience with it.</p></blockquote><hr><blockquote><p>难易：<br>谷歌的Borg系统群集管理器运行几十万个以上的jobs，来自几千个不同的应用，跨多个集群，每个集群有上万个机器。<br>它通过管理控制、高效的任务包装、超售、和进程级别性能隔离实现了高利用率。<u>它支持高可用性应用程序与运行时功能，最大限度地减少故障恢复时间，减少相关故障概率的调度策略</u>。Borg简化了用户生活，通过提供一个声明性的工作规范语言，名称服务集成，实时作业监控，和分析和模拟系统行为的工具。<br>我们将会展现Borg系统架构和特点，重要的设计决策，定量分析它的一些策略，和十年以来的运维经验和学到的东西。</p></blockquote><hr><blockquote><p>王：<br>Google的Borg系统是一个运行着成千上万项作业的集群管理器，它同时管理着很多个应用集群，每个集群都有成千上万台机器，这些集群之上运行着Google的很多不同的应用。<br>Borg通过准入控制，高效的任务打包，超额的资源分配和进程级隔离的机器共享，来实现超高的资源利用率。<u>它通过最小化故障恢复时间的运行时特性和减少相关运行时故障的调度策略来支持高可用的应用程序</u>。Borg通过提供一个作业声明的标准语言，命名服务的集成机制，实时的作业监控，以及一套分析和模拟系统行为的工具来简化用户的使用。<br>我们将通过此论文对Borg系统的架构和主要特性进行总结，包括重要的设计决定，一些调度管理策略的定量分析，以及对十年的使用经验中汲取的教训的定性分析。</p></blockquote><hr><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>Google的Borg系统是一个集群管理器。它在多个万台机器规模的集群上运行着来自几千个不同应用的几十万个作业。<br>Borg通过准入控制、高效的任务装箱、超售、机器共享、以及进程级别的性能隔离，实现了高利用率。<u>它为高可用应用提供了可以减少故障恢复时间的运行时特性，以及降低关联故障概率的调度策略</u>。Borg提供了声明式的作业描述语言、域名服务集成、实时作业监控、分析和模拟系统行为的工具。这些简化了用户的使用。<br>本文介绍了Borg系统架构和特性，重要的设计决策，对某些策略选择的定量分析，以及十年来的运营经验和教训。</p><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>我们内部称为Borg的集群管理系统，负责接收、调度、启动、重启和监控Google所有的应用。本文介绍它是如何实现的。</p><p>Borg提供了三个主要的好处：（1）隐藏资源管理和故障处理细节，使用户可以专注于应用开发；（2）高可靠和高可用的运维，并支持应用程序也能够如此；（3）让我们可以在几万台机器上高效地运行负载。Borg不是第一个涉及这些问题的系统，但它是少有的运行在如此大规模，具有弹性且完整的系统之一。</p><p>本文围绕这些主题来编写，总结了十多年来我们在生产环境运行Borg的一些定性观察。</p><p><img width="600" src="/img/borg-fig-01.png" alt="图1. Borg的架构。图中只画出了数千个工作节点的很小一部分"></p><h1 id="2-用户视角"><a href="#2-用户视角" class="headerlink" title="2. 用户视角"></a>2. 用户视角</h1><p>Borg的用户是Google的开发人员以及运行Google应用和服务的系统管理员（站点可靠性工程师，SRE）。用户以作业（Job）的方式将他们的工作提交给Borg。作业由一个或多个任务（Task）组成，每个任务执行相同的二进制程序。每个作业只运行在一个Borg单元（Cell）里。Cell是一组机器的管理单元。下面的小节将介绍用户视角看到的Borg系统的主要特性。</p><blockquote><p>SRE的职责比系统管理员多得多：他们是负责Google生产服务的工程师。他们也设计和实现包括自动化系统等软件，管理应用、服务基础设施和平台，以保证在Google如此大的规模下的高性能和高可靠性。</p></blockquote><h2 id="2-1-工作负载"><a href="#2-1-工作负载" class="headerlink" title="2.1 工作负载"></a>2.1 工作负载</h2><p>Borg Cell主要运行2种异构的工作负载。第一种是应该“永不”停止的长期运行的服务，处理持续时间较短但对延迟敏感的请求（从几微秒到几百毫秒）。这些服务用于面向最终用户的产品，如Gmail、Google Docs、网页搜索，以及内部基础设施服务（例如Bigtable）。第二种是批处理作业，执行时间从几秒到几天，对短期性能波动不敏感。这2种负载在不同Cell中的比例不同，取决于其主要租户（例如，有些Cell就以批处理作业为主）。工作负载也随时间变化：批处理作业不断提交或结束，而很多面向终端用户的服务表现出昼夜周期性的使用模式。Borg需要都处理好这些情况。</p><p>Borg的代表性负载是一个公开的2011年5月整月的记录数据集[80]。这个数据集已经得到了广泛的分析[1, 26, 27, 57, 68]。</p><p>最近几年，以Borg为基础构建了很多应用框架，包括我们内部的MapReduce系统[23]、FlumeJava[18]、Millwheel[3]和Pregel[59]。这些框架大多有一个控制器来提交Master Job，还有多个Worker Job。前两个框架类似于YARN的应用管理器[76]。我们的分布式存储系统，例如GFS[34]和它的后继者CFS、Bigtable[19]、以及Megastore[8]，都是运行在Borg上的。</p><p>本文中，我们把高优先级的Borg作业称为为生产作业（prod），其它的则是非生产的（non-prod）。大多数长期服务是prod的，大部分批处理作业是non-prod的。一个典型Cell里，prod作业分配了约70%的总CPU资源，占总CPU使用量约60%；分配了约55%的总内存资源，占总内存使用量约85%。§5.5节表明分配量和使用量的差异是值得注意的。</p><h2 id="2-2-集群（Cluster）和单元（Cell）"><a href="#2-2-集群（Cluster）和单元（Cell）" class="headerlink" title="2.2 集群（Cluster）和单元（Cell）"></a>2.2 集群（Cluster）和单元（Cell）</h2><p>一个Cell里的机器属于同一个集群。集群由数据中心级的高性能光纤的组网来定义。一个集群位于数据中心的一栋建筑内，而一个数据中心有多栋建筑（注：这些关系会有少数例外情况）。一个集群通常包括一个大的Cell，还可能有一些小规模的测试用或其它特殊用途的Cell。我们尽力避免任何单点故障。（译注：即不搞大型Cell）</p><p>不计测试用的Cell，中等规模的Cell约有一万台机器；有些Cell还要大得多。Cell中的机器从多个维度看都是异构的：大小（CPU、内存，硬盘，网络）、处理器类型、性能、以及是否有外网IP地址或SSD等。Borg负责决定任务在Cell中的哪些机器上执行、为其分配资源、安装程序及依赖、监控健康状态并在失败后重启，从而使用户几乎不必关心机器异构性。</p><h2 id="2-3-作业（Job）和任务（Task）"><a href="#2-3-作业（Job）和任务（Task）" class="headerlink" title="2.3 作业（Job）和任务（Task）"></a>2.3 作业（Job）和任务（Task）</h2><p>一个Borg 作业的属性有：名称、拥有者和任务个数。作业可以有一些约束来强制其任务运行在有特定属性的机器上，比如处理器架构、操作系统版本、是否有外网IP地址等。约束可以是硬性的或者柔性的，柔性约束表示偏好，而非需求。一个作业可以推迟到前一个作业结束后再开始（译注：即作业间的依赖顺序）。一个作业只在一个Cell中运行。</p><p>每个任务对应着一组Linux进程，运行在一台机器上的一个容器内 [62]。绝大部分Borg的工作负载没有运行在虚拟机里，因为我们不想付出虚拟化的开销。而且，在Borg设计的时候，我们有很多处理器还没有硬件虚拟化功能呢。</p><p>任务也有一些属性，如资源需求量，在作业中的序号等。一个作业中的任务大多有相同的属性，但也可以被覆盖 —— 例如特定任务的命令行参数。各维度的资源（CPU核、内存、硬盘空间、硬盘访问速度、TCP端口（注：Borg负责管理一台机器上的可用端口并将其分配给任务）等）。可以互相独立的以细粒度指定。我们不强制使用固定大小的资源桶或槽（见§5.4）。Borg运行的程序都是静态链接的，以减少对运行环境的依赖，这些程序组织成由二进制文件和数据文件构成的包，由Borg负责安装。</p><p>用户通过向Borg发送RPC来控制作业。RPC大多是从命令行工具、其它作业、或我们的监控系统（§2.6）发出的。大多作业描述文件使用一种声明式配置语言BCL。BCL是GCL[12]的一个变种，即增加了一些Borg专有的关键字，而GCL会生成若干protobuf文件[67]。GCL还提供了匿名函数以支持计算，这样就能让应用根据环境调整自己的配置。有上万个超过一千行的BCL配置文件，系统中累计了千万行BCL。Aurora的配置文件与Borg的作业配置 [6]相似。</p><p>图2展示了作业和任务整个生命周期的状态变化。</p><p><img width="600" src="/img/borg-fig-02.png" alt="图2. 作业和任务的状态图。用户可以触发提交，杀死和更新操作"></p><p>要想在运行时改变一个作业中若干或全部任务的属性，用户可以向Borg提交一个新的作业配置，并命令Borg将任务更新到新的配置。更新是轻量的，非原子性的事务，在事务结束（提交）之前可以很容易地撤销。更新通常是滚动执行的，而且可以限制由更新导致的任务中断（被重新调度或抢占）的数量；超过限值后，变更将会被跳过。</p><p>一些任务更新（如更新二进制程序）需要重启任务；另外一些更新（如增加资源需求或修改约束）可能使该任务不适合运行在当前机器上，导致停止并重新调度该任务；还有一些更新（如修改优先级）总是可以进行的，不需要重启或者移动任务。</p><p>任务可以要求在被Unix的<code>SIGKILL</code>信号立即杀死之前获得<code>SIGTERM</code>信号通知，这样它们还有时间清理资源、保存状态、结束当前请求、拒绝新请求。但如果抢占者设置了延迟限值，就可能来不及发通知。实践中，80%的情况下能发出通知信号。</p><h2 id="2-4-分配（Allocs）"><a href="#2-4-分配（Allocs）" class="headerlink" title="2.4 分配（Allocs）"></a>2.4 分配（Allocs）</h2><p>Borg的alloc（allocation的缩写）是一台机器上的预留资源，可以用来执行一个或多个任务；不管有没有被使用，这些资源都算分配出去了。Allocs可以给将来的任务预留资源，或在任务暂停和重启的间隔保持资源，以及将不同作业的多个任务绑定在同一台机器上 —— 例如一个Web服务器实例和附加的将其URL日志从本机硬盘拷贝到分布式文件系统的日志转存任务。Alloc像一台机器那样来管理；运行在同一个Alloc内的多个任务共享其资源。如果一个Alloc需要迁移到其它机器上，那么它的任务也要跟着重新调度。</p><p>一个Alloc集，即一组在多台机器上预留了资源的Alloc，类似于一个作业。一旦创建了一个Alloc集，就可以向其提交若干作业。简便起见，我们用 <strong>任务</strong>表示一个Alloc或者一个顶层任务（即运行在Alloc之外的任务），用 <strong>作业</strong>表示一个普通作业或者Alloc集。</p><h2 id="2-5-优先级、配额和准入控制"><a href="#2-5-优先级、配额和准入控制" class="headerlink" title="2.5 优先级、配额和准入控制"></a>2.5 优先级、配额和准入控制</h2><p>当出现超过系统容量的工作负载会产生什么情况？我们对此的解决方案是优先级和配额。</p><p>每个作业都有一个小的正整数表示的优先级。高优先级的任务可以优先获得资源，甚至抢占（杀死）低优先级的任务。Borg为不同用途定义了不重叠的优先级区间，包括（优先级降序）：<strong>监控、生产、批处理、尽力（即测试的或免费的）</strong>。本文中，prod作业的优先级包括监控和生产两个区间。</p><p>虽然一个被抢占的任务通常会被重新调度到Cell的其它机器上，但级联抢占也可能发生：如果某个任务抢占了一个优先级稍低的任务，而后者又抢占了另一个优先级稍低的，如此往复。为避免这种情况，我们禁止<code>生产</code>区间的任务互相抢占。细粒度（译注：相比于区间的粗粒度）的优先级在其它场景下也很有用 —— 如MapReduce的Master 任务的优先级比其管理的Worker高一点，以提高其可靠性。</p><p>优先级表示了Cell中运行或等待的作业之间的相对重要性。配额（Quota）则用来决定准许哪个作业可以被调度。配额是特定优先级和时间段（典型是几个月）的一个资源向量（CPU，内存，硬盘等）。配额限制了用户的作业一次可以申请资源的最大数量（如：20TB内存，prod优先级，从现在到7月末，在xx Cell内）。配额检查是准入控制的一部分，而不是调度的：配额不足的作业提交时当即就会被拒绝。</p><p>高优先级的配额比低优先级的成本要高。生产级的配额限定于一个Cell的物理资源量。因此，用户提交了不超过配额的生产级作业时，不考虑资源碎片和约束，可以预期这个作业一定会运行。尽管我们鼓励用户不要购买超过其需求的配额，但很多用户仍然超买了，这样他们就不用担心由于将来应用用户量增长可能导致的配额短缺。我们的应对方案是对低优先级资源配额的超售：所有用户的0优先级配额是无限的，尽管这无法实现。低优先级的作业虽然被接收了，但可能由于资源不足而一直等待。</p><p>配额分配是Borg之外的系统处理的，与我们的物理容量规划紧密相关。容量规划的结果反映在各数据中心的价格和可用配额上。只有在其要求的优先级有足够的配额，用户的作业才能被接收。采用配额使得主导资源公平性（DRF）[29, 35, 36, 66]这样的策略不是那么必要了。</p><p>Borg的容量系统可以给某些用户一些特殊权限。例如，允许管理员删除或修改Cell里的任意作业，或者允许某个用户操作特定的内核特性或Borg行为（如对其作业禁用资源估计。§5.5）。</p><h2 id="2-6-命名和监控"><a href="#2-6-命名和监控" class="headerlink" title="2.6 命名和监控"></a>2.6 命名和监控</h2><p>仅仅创建和部署任务是不够的：一个服务的客户端和其它系统需要能找到它们，即使该服务被重新部署到另一台机器之后。为实现该需求，Borg为每个任务创建了一个固定的BNS域名（BNS，Borg name Service），这个域名包括了Cell名，作业名称和任务序号。Borg把任务的主机名和端口写入Chubby [14]的一个持久化高可用文件里，以BNS域名为文件名。这个文件被RPC用来发现任务的实际地址。BNS域名也是任务的DNS域名的一部分，例如，cc Cell的ubar用户的jfoo 作业的第50个任务可以通过<code>50.jfoo.ubar.cc.borg.google.com</code>来访问。每当状态改变时，Borg还会把作业的大小和任务的健康信息写入到Chubby，这样负载均衡器就知道如何路由请求了。</p><p>几乎每个任务都有一个内置的HTTP服务器，用来发布任务的健康信息和几千个性能指标（如RPC延时）。Borg监控这些健康检查的URL，重启那些没有立刻响应或返回HTTP错误码的任务。监控工具跟踪其它数据并显示在仪表盘上，当违反服务水平目标（SLO）时报警。</p><p>用户可以使用一个称为Sigma的Web界面来检查他的所有作业的状态，针对某个Cell，或者深入某个作业及任务，检查其资源使用行为、详细日志、执行历史和最终结果。我们的应用产生大量的日志，它们都会被自动的滚动以避免耗尽硬盘空间。任务退出后，日志会保留一小段时间以帮助调试。如果一个作业没有运行起来，Borg会提供一个挂起原因的标注，以及建议如何修改作业的资源请求，以使其更适合Cell。我们发布了如何使资源请求更容易被调度的指南。</p><p>Borg将所有的作业提交、任务事件、以及每个任务的详细资源使用都记录在Infrastore里。Infrastore是一个可扩展的只读数据存储，通过Dremel[61]提供了类似SQL的交互式接口。这些数据用以支持基于使用量的收费，调试作业和系统故障，以及长期容量规划。公开的Google集群负载数据集[80]也来自于这些数据。</p><p>所有这些特性帮助用户理解和调试Borg及其作业的行为，并帮助我们的SRE实现每人管理超过上万台机器。</p><h1 id="3-Borg架构"><a href="#3-Borg架构" class="headerlink" title="3. Borg架构"></a>3. Borg架构</h1><p>一个Borg的Cell包括一组机器，一个逻辑上集中的控制器，称为Borgmaster，以及运行在每台机器上的称为Borglet的代理进程（见图1）。Borg的组件都是用C++实现的。</p><h2 id="3-1-Borgmaster"><a href="#3-1-Borgmaster" class="headerlink" title="3.1 Borgmaster"></a>3.1 Borgmaster</h2><p>Cell的Borgmaster由两个进程组成：Borgmaster主进程和一个单独的调度进程（§3.2）。Borgmaster主进程处理客户端的RPC，包括修改状态（如创建作业），或提供只读数据（如查找作业）。它还管理着系统中所有对象（机器、任务、Allocs等）的状态，与Borglet通信，并提供一个Web UI（作为Sigma的备份）。</p><p>Borgmaster在逻辑上是单个进程，但实际上有5个副本。每个副本在内存维护着Cell状态的拷贝，该状态同时保存在由这些副本的本地硬盘组成的一个基于Paxos[55]的高可用、分布式存储上。每个Cell中仅有一个选举出来的Master，它同时作为Paxos的Leader和状态修改者，处理所有变更Cell状态的请求，例如提交作业或者结束某台机器上的一个任务。当Cell启动或者上一个Master故障时，新的Master会通过Paxos算法选举出来；新Master会获取一个Chubby锁，这样其它的系统就可以找到它。选举并转移到新的Master通常需要10秒，但在大的Cell里可能需要长达1分钟，因为需要重构一些内存状态。当一个副本从宕机恢复后，它会动态地从其它最新的Paxos副本中重新同步自己的状态。</p><p>某个时刻的Borgmaster状态被称为检查点（Checkpoint），以定期快照加变更日志的形式保存在Paxos存储里。检查点有很多用途：如重建过去任意时刻的Borgmaster状态（例如，在接收一个触发了Borg故障的请求之前的时刻，这样就可以用来调试）；特别情况下可以手工修复检查点；构建一个持久的事件日志供日后查询；或用于离线仿真。</p><p>一个高保真的Borgmaster模拟器，称为Fauxmaster，可以读取检查点文件。Fauxmaster的代码拷贝自线上的Borgmaster，还有对Borglet的存根接口。它接收RPC来改变状态，执行操作，例如“调度所有等待的任务”。我们用它来调试故障，像跟在线的Borgmaster那样与模拟器交互，用模拟的Borglet重放检查点文件里的真实交互。用户可以单步执行并观察系统过去确实发生了的状态变化。Fauxmaster也用于容量规划（可以接收多少个此类型的作业？），以及在实际更改Cell配置前做可行性检查（这个变更会导致关键作业异常退出吗？）</p><h2 id="3-2-调度"><a href="#3-2-调度" class="headerlink" title="3.2 调度"></a>3.2 调度</h2><p>当提交一个作业后，Borgmaster会把它保存在持久的Paxos存储上，并将这个作业的所有任务加入等待队列中。调度器异步地扫描等待队列，将任务分配到满足作业约束且有足够资源的机器上（调度是针对任务的，而非作业）。队列扫描从高优先级到低优先级，同优先级则以轮转的方式处理，以保证用户间的公平，并避免队首的大型作业阻塞队列。调度算法有两个部分：<strong>可行性检查</strong>，找到一组可以运行任务的机器；<strong>评分</strong>，从中选择一个合适的机器。</p><p>在可行性检查阶段，调度器会找到一组满足任务约束且有足够可用资源的机器 —— 可用资源包括已经分配给低优先级任务但可以抢占的资源。在评分阶段，调度器确定每台可行机器的适宜性。评分考虑了用户特定的偏好，但主要取决于内建的标准：例如最小化被抢占任务的个数和优先级，选择已经有该任务安装包的机器，尽可能使任务分散在不同的供电和故障域，以及装箱（Packing）质量（在单台机器上混合高、低优先级的任务，以允许高优先级任务在负载尖峰扩容）等。</p><p>Borg早期使用修改过的E-PVM[4]算法来评分。这个算法对异构的资源生成等效的成本值，放置任务的目标是使成本的变化量最小。在实践中，E-PVM会把负载分散到所有机器，为负载尖峰预留出资源 —— 这样的代价是增加了碎片，特别是对需要大部分机器的大型任务而言；我们有时称其为“最差匹配”。</p><p>与之相反的是“最佳匹配”，把机器上的任务塞的越满越好。这就“空”出一些没有用户作业的机器（它们仍运行存储服务），这样放置大型任务就比较直接了。但是，如果用户或Borg错误估计了资源需求，紧实的装箱会对此造成（性能上的）惩罚。这种策略不利于有突发负载的应用，而且对申请少量CPU的批处理作业特别不友好，这些作业申请少量CPU本来是为了更容易被调度执行，并抓住机会使用空闲资源：20%的non-prod 任务申请少于0.1个CPU核。</p><p>我们目前的评分模型是混合的，试图减少搁浅（Stranded）的资源（指一台机器因某些类型资源全部分配了，导致未能分配的其它类型资源）。对我们的负载而言，这个模型比“最佳匹配”提升了3%-5%的装箱效率（以[78]定义的方式评价）。</p><p>如果评分后选中的一台机器仍没有足够的资源来运行新任务，Borg会抢占低优先级的任务，从最低优先级向上逐级抢占，直到资源足够运行该任务。被抢占的任务放回到调度器的等待队列里，而不是被迁移或休眠（注：例外情况是，为Google Compute Engine提供虚拟机的任务会被迁移）。</p><p>任务的启动延迟（从提交作业到任务开始运行之间的时间段）是我们持续重点关注的。这个时间差别很大，中位数约25秒。安装软件包耗费了其中80%的时间：一个已知的瓶颈就是软件包写入时对本地硬盘的竞争。为了减少任务启动时间，调度器偏好将任务分配到已经有必需的软件包（程序及数据）的机器：大部分包是只读的，所以可以被共享和缓存（这是Borg调度器唯一的一种数据局部性支持）。另外，Borg通过树形和类似BT的协议并发地将软件包分发到多个机器上。</p><p>此外，调度器采用多种技术使其能够扩展到数万台机器的Cell（§3.4）。</p><h2 id="3-3-Borglet"><a href="#3-3-Borglet" class="headerlink" title="3.3 Borglet"></a>3.3 Borglet</h2><p>Borglet是部署在Cell每台机器上的本机Borg代理。它负责启动和停止任务；重启失败的任务；通过OS内核设置来管理本地资源；滚动调试日志；把本机的状态上报给Borgmaster和其它监控系统。</p><p>Borgmaster每过几秒就会轮询每个Borglet来获取机器的当前状态，并向其发送请求。这让Borgmaster能控制通信频率，省去了显式的流量控制机制，而且防止了恢复风暴[9]。</p><p>选举出来的Master负责准备发送给Borglet的消息，并根据Borglet的响应更新Cell的状态。为使性能可扩展，每个Borgmaster副本会负责一个无状态的链接分片（Link Shard）来处理部分Borglet的通信；Borgmaster选举后重新计算链接的分片。为了保证容错（Resiliency），Borglet总是汇报全部状态，但是Link Shard只汇报变化值，从而聚合、压缩这些信息，减少Master更新的负担。</p><p>如果某个Borglet几次没有响应轮询请求，该机器会被标记为宕机，其上运行的所有任务会被重新调度到其它机器。如果通讯恢复了，Borgmaster会让这个Borglet杀掉已经被重新调度出去的任务，以避免重复。即便无法与Borgmaster通信，Borglet仍会继续正常运行。所以即使所有的Borgmaster都出故障了，正在运行的任务和服务还会保持运行。</p><h2 id="3-4-扩展性"><a href="#3-4-扩展性" class="headerlink" title="3.4 扩展性"></a>3.4 扩展性</h2><p>我们还没有遇到Borg这种集中式架构的终极扩展上限。我们顺利地突破了遇到的每个限制。一个单独的Borgmaster可以管理有数千台机器的Cell，有些Cell每分钟有10000多个任务到达。一个繁忙的Borgmaster使用10~14个CPU核以及50GB内存。我们用了几项技术来实现这种扩展性。</p><p>早期版本的Borgmaster使用一个简单的，同步的循环来处理请求、调度任务，并与Borglet通信。为了处理更大的Cell，我们把调度器分离为一个单独的进程，这样它就可以与其它的Borgmaster功能并行执行，而这些其它的功能有多副本以便容错。调度器使用一份缓存的Cell状态拷贝，重复执行下面的操作：从选举出来的Master获取状态变更（包括已分配的和等待中的工作）；更新自己的本地拷贝；执行一轮调度来分配任务；将分配信息发送给Master。Master会接受并应用这些分配，但如果分配不适合（例如，是基于过时的状态做出的），就会等待调度器的下一轮调度。这与Omega [69]使用的乐观并发控制思路很相似，而且我们最近还给Borg添加了对 <strong>不同负载类型使用不同调度器</strong>的功能。</p><p>为了改进响应时间，Borglet使用独立的线程分别进行通信和响应只读RPC。为了更好的性能，我们将这些请求划分给5个Borgmaster副本（§3.3）。总的效果是，UI响应时间的99%分位数小于1秒，而Borglet轮询间隔的95%分位数小于10秒。</p><p>一些提高Borg调度器扩展性的方法如下：</p><p><strong>缓存评分</strong>：计算一台机器的可行性和评分是比较昂贵的，所以Borg会一直缓存评分，直到这台机器或者任务的属性发生了变化 —— 例如，这台机器上的某个任务结束了，一些属性修改了，或者任务的需求改变了。忽略小额的资源变化可以减少缓存失效。</p><p><strong>任务等效类（Equivalence classes）</strong>：一般来说，同一个Borg 作业的任务有相同的请求和约束。任务等效类即一组有相同需求的任务。Borg只对等效类中的一个任务进行可行性检查和评分，而不是对等待的每个任务去检查一遍所有机器的可行性并对可行的机器评分。</p><p><strong>适度随机</strong>：在一个大的Cell中，对所有机器都去计算一遍可行性和评分是很浪费的。调度器会随机地检查机器，直到找到足够多的可用机器来评分，然后从中挑选出最好的一个。这减少了任务启动和退出所需的评分次数及导致的缓存失效，加快了任务分配过程。适度随机有点类似Sparrow[65]的批量采样技术（译注：Sparrow的批量采样考虑的是机器上的任务队列长度），但Borg还处理了优先级、抢占、异构性和安装软件包的成本。</p><p>在我们的实验中（§5），从零开始调度整个Cell的工作负载只要几百秒，但禁用上面几项技术的话，3天都不够。正常情况下，半秒之内就能完成一遍等待队列的在线调度。</p><h1 id="4-可用性"><a href="#4-可用性" class="headerlink" title="4. 可用性"></a>4. 可用性</h1><p><img width="600" src="/img/borg-fig-03.png" alt="图3. 不同类型任务的异常退出率及原因（包括抢占、资源不足、机器故障、机器关机、其它）。数据从2013-08-01开始。"></p><p>大型系统里故障是很常见的[10, 11, 12]。图3展示了在15个样本Cell里任务异常退出的原因分类。在Borg上运行的应用需要能处理这种事件，可采用的技术有多副本、保存持久状态到分布式存储，或定期快照（如果可行的话）等。当然，我们也尽可能的缓解异常事件的影响。例如，Borg提供了：</p><ul><li>自动重新调度异常退出的任务，如果必要，可以放置到另一台机器上去运行</li><li>把一个作业的任务分散到不同的可用域，例如机器、机架、供电域层次，以减少关联失效</li><li>在机器/OS升级等维护活动期间，限制任务受影响的速率，以及同一作业中同时中止的任务的个数</li><li>使用声明式的预期状态表示，及幂等的变更操作，这样故障的客户端可以无损地重复提交故障期间漏掉的请求</li><li>对于失联的机器上的任务，限制重新调度的速率，因为大规模的机器故障和网络分区是很难区分的</li><li>回避造成崩溃的 &lt;任务，机器&gt; 组合</li><li>通过不断重新执行日志保存任务（§2.4），恢复已写入本地硬盘的关键中间数据，就算这个日志关联的Alloc已经终止或调度到其它机器上了。用户可以设置系统持续重复尝试多久，通常是几天时间。</li></ul><p>Borg的一个关键设计特性是：就算Borgmaster或者Borglet退出了，已经运行的任务还会继续运行下去。不过，保持Master正常运行仍然重要，因为在它退出后就无法提交新的作业，无法更新运行作业的状态，也不能重新调度故障机器上的任务。</p><p>Borgmaster使用多项的技术支持其获得99.99%的实际可用性：多副本应对机器故障；准入控制应对过载；使用简单、底层的工具部署实例，以减少外部依赖。Cell彼此是独立的，减少了关联误操作和故障传播的机会。同时这也是我们不扩大Cell规模的主要考虑，而并非是受限于扩展性。</p><h1 id="5-利用率"><a href="#5-利用率" class="headerlink" title="5. 利用率"></a>5. 利用率</h1><p>Borg的一个主要目标就是有效地利用Google的大量机器（这是一大笔财务投资）：让效率提升几个百分点就能省下几百万美元。这一节讨论和评估了一些Borg使用的策略和技术。</p><h2 id="5-1-评估方法"><a href="#5-1-评估方法" class="headerlink" title="5.1 评估方法"></a>5.1 评估方法</h2><p>作业有部署约束，而且需要处理负载尖峰（尽管比较少见）；机器是异构的；我们回收服务型作业的资源来运行批处理作业。因此，我们需要一个比“平均利用率”更高级的指标来评估我们的策略选择。大量实验后，我们选择了Cell压缩量（Compaction）：给定一个负载，我们不断地移除机器，直到无法容纳该负载，从而得知所需最小的Cell规模。从空集群开始部署该负载并重复多次，以减少特殊情况的影响。终止条件是明确的，对比可以自动化，避免了生成和建模合成负载的陷阱[31]。[78]提供了评估技术的定量比较，其中的细节非常微妙。</p><p>我们不可能在线上Cell进行实验，但是我们用了Fauxmaster来获得高保真的模拟效果，它使用了真实生产Cell和负载的数据，包括所有约束、实际限制、预留和使用量数据（§5.5）。实验数据提取自2014-10-01 14:00 PDT的Borg快照（其它快照也有类似的结论）。我们首先排除了特殊用途的、测试用的、小型的（少于5000台机器）的Cell，然后从剩下的Cell中选取了15个样本，抽样尽量关于Cell的大小均匀分布。</p><p>为了保持机器异构性，在Cell压缩实验中，我们随机地移除机器。为了保持工作负载的异构性，我们保留了所有负载（除了那些绑定到特定机器的服务和存储任务，如Borglet）。我们把那些需要超过原Cell大小一半的作业的硬性限制改成柔性的，允许不超过0.2%的任务一直等待，这是针对一些特别“挑剔”的，只能放置在很少的特定机器上的任务；充分的实验表明结果是可复现的，波动很小。如果需要一个大型的Cell，就把原Cell复制几倍；如果需要更多的Cell，也是复制原Cell。</p><p>每个实验都用不同的随机数种子对每个Cell重复了11次。图中，我们用误差线线来表示所需机器数量的最大和最小值，选择90%分位数作为结果 —— 平均值或中位数不能反映系统管理员所期望的充分把握。我们认为Cell压缩率是一个公平一致的比较调度策略的方法，而且可以直接转化为成本/收益的结果：更好的策略只需要更少的机器来运行相同的负载。</p><p>我们的实验关注于即时的调度（装箱），而不是重放一段长时间的负载记录。部分原因是避免处理开放或闭合的队列模型[71, 79]的困难；部分是传统的完成时间不适用于长时间运行的服务；部分是这样可以提供明确的比较结果；部分是因为我们认为不会对结果产生显著影响；还有部分现实原因，我们发现一次实验使用了20万个Borg CPU核 —— 即便对Google而言，这个成本也不是个小数目。</p><p><img width="600" src="/img/borg-fig-04.png" alt="图4. 压缩的效果。15个Cell在压缩后相比原规模的百分比累积分布（CDF）"></p><p>生产环境中，我们特意保留了一些裕度（Headroom），以应对负载增长、偶然的“黑天鹅”事件、负载尖峰、机器故障、硬件升级、以及大范围的局部故障（如供电母线短路）。图4显示了如果应用Cell压缩，实际的Cell可以压缩到多小。下文的图使用这些压缩后的大小作为基准值。</p><h2 id="5-2-Cell共享"><a href="#5-2-Cell共享" class="headerlink" title="5.2 Cell共享"></a>5.2 Cell共享</h2><p>几乎所有的机器都同时运行prod和non-prod的任务：在共享的Cell里是98%的机器，在所有Borg管理的机器里是83%（有一些是Cell专用的）。</p><p><img src="/img/borg-fig-05.png" alt="图5. 将prod和non-prod工作划分到不同的集群将需要更多的机器。两幅图中的百分比都是相对于单个集群所需机器的最少数量而言的"></p><p>鉴于很多外部组织将面向用户的作业和批处理作业分别运行在不同的集群上，我们检查一下如果我们也这么做会怎样。图5表明，在一个中等大小的Cell上，分开运行prod和non-prod的工作负载将需要增加20-30%的机器。这是因为prod的作业通常会保留一些资源来应对极少发生的负载尖峰，但大多情况下用不到这些资源。Borg回收了这些用不到的资源（§5.5），来运行non-prod的工作，所以总体我们只需要更少的机器。</p><p><img width="600" src="/img/borg-fig-06.png" alt="图6. 将用户分开到不同的集群也会需要更多的机器"></p><p>大部分Borg Cell被数千个用户共享使用。图6展示了为什么要共享。测试中，如果一个用户消费了超过10TiB（或100TiB）的内存，我们就把这个用户的工作负载分离到另一个Cell中。我们目前的共享策略是有效的：即使100TiB的阈值，也需要2-16倍的Cell，增加20-150%的机器。将资源池化再次显著地节省了成本。</p><p>但是，把很多不相关的用户和作业类型放置到同一台机器上可能会造成CPU冲突，我们是否需要更多的机器来补偿？为评估这一点，我们看一下固定机器类型和时钟频率，任务的CPI（Cycles per Instruction，执行每条指令平均所需时钟数，越大则程序执行越慢）在其它环境条件不同的影响下是如何变化的。在这种实验条件下，CPI是一个可比较的指标，而且可以表征性能冲突，因为2倍的CPI意味着一个CPU密集型程序需要2倍的执行时间。数据是在一周内从约12000个随机选择的prod任务获取的，使用了[83]中介绍的硬件剖析工具记录5分钟内的时钟数和指令数，并调整了采样的权重，使CPU时间的每秒都均等处理。结果并非直截了当的：</p><p>（1）我们发现CPI在同一个时间段内和下面两个量正相关：这台机器上总的CPU使用量，以及这个机器上同时运行的任务个数（基本上独立）；每向一台机器上增加一个任务，就会使其它任务的CPI增加0.3%（从数据拟合的线性模型给出的预测值）；将一台机器的CPU使用量增加10%，就会增加2%弱的CPI。尽管相关性在统计意义上是显著的，也只是解释了CPI变化的5%。还有其它的因素，支配着CPI的变化，例如，应用程序固有的差别，以及特殊的干扰模式[24, 83]。</p><p>（2）比较从共享Cell和只运行几种应用的少数专用Cell获取的CPI采样，我们看到共享Cell里的CPI平均值为1.58（σ=0.35，标准差），专用Cell的CPI平均值是1.53（σ=0.32） —— 也就是说，共享Cell的性能差3%。</p><p>（3）为了搞定不同Cell的应用会有不同的工作负载，或者会有幸存者偏差（或许对冲突更敏感的程序会被挪到专用Cell里面去），我们观察了Borglet的CPI。所有Cell的所有机器上都运行着Borglet。我们发现专用Cell里Borlet的CPI平均值是1.20（σ=0.29），而共享Cell里的CPI平均值为1.43（σ=0.45），表明在专用Cell上比在共享Cell上快1.19倍，不过这个结果忽略了专用Cell中的机器负载较轻的因素，即稍偏向专用Cell。</p><p>这些实验表明了仓库级别的性能比较是复杂的，强化了[51]中的观察，但也说明共享并没有显著增加运行程序的开销。</p><p>不过，就算从结果中最差的数据来看，共享还是有益的：比起CPU的降速，共享比各个划分方案都减少了机器，这一点更重要，而且共享的收益适用于包括内存和硬盘等各种资源，不仅仅是CPU。</p><h2 id="5-3-大型Cell"><a href="#5-3-大型Cell" class="headerlink" title="5.3 大型Cell"></a>5.3 大型Cell</h2><p><img src="/img/borg-fig-07.png" alt="图7. 将Cell分成更小的规模将需要更多的机器"></p><p>Google建立了大型Cell，一是为了允许运行大型任务，二是为了减少资源碎片。为测试减少碎片的效果，我们把负载从一个Cell分散多个较小的Cell中 —— 首先将作业随机排列，然后轮流分配到各小的Cell中。图7确认了使用小型Cell需要增加相当多的机器。</p><h2 id="5-4-细粒度资源请求"><a href="#5-4-细粒度资源请求" class="headerlink" title="5.4 细粒度资源请求"></a>5.4 细粒度资源请求</h2><p>Borg用户请求的CPU单位是0.001个核，内存和硬盘的单位是字节。（一个核实际上是一个CPU的超线程，对不同机器类型的性能进行了标准化）。图8表明用户充分利用了细粒度：请求的CPU核和内存数量的“特别偏好值”是很少的，这些资源也没有明显的相关性。这与[68]里的分布非常相似，除了我们在90%分位数及以上的内存请求多一点之外。</p><p>尽管IaaS普遍只提供一组固定尺寸的容器或虚拟机[7, 33]，但不符合我们的需求。为说明这一点，我们对prod的作业和Alloc（§2.4）申请的CPU核和内存分别向上取整到最接近的2的幂，形成固定大小的“桶”，最小的桶有0.5个核和1GiB内存。图9显示一般情况下这样需要增加30-50%的资源。上限的情形是，有的大型任务即便将Cell扩大为未压缩尺寸的四倍也无法容纳，只好为其分配一整台机器。下限是允许这些任务一直等待。（这比[37]给出的将近100%的额外开销要小一些，因为我们支持不止4种尺寸的桶，而且允许CPU和内存分别改变）。</p><h2 id="5-5-资源回收"><a href="#5-5-资源回收" class="headerlink" title="5.5 资源回收"></a>5.5 资源回收</h2><p>作业可以声明一个资源<strong>限额（Limit）</strong>，是每个任务能获得的资源上限。Borg会用它来检查用户是否有足够的配额来接受该作业，并检查某个机器是否有足够的可用资源来运行任务。因为Borg通常会杀死那些试图使用超出内存和硬盘申请值的任务，或者限制其CPU使用量不超过申请值，所以有的用户会为任务申请超过实际需要的资源，就像有的用户会购买超过实际需要的配额一样。另外，一些任务只是偶尔需要使用它们申请的所有资源（例如，在一天中的高峰期或者受到了拒绝服务攻击），但大多时候用不了。</p><p>与其把那些分配出来但暂时没有被用到的资源浪费掉，我们估计了一个任务会用多少资源，然后把剩余的资源回收给那些可以忍受低质量资源的任务，例如批处理作业。这整个过程称为<strong>资源再利用</strong>。这个估值称为任务的资源<strong>预留（Reservation）</strong>。Borgmaster每隔几秒就会根据Borglet获取的细粒度资源使用量信息来计算一次预留值。最初的预留资源被设置为资源限额；在300秒之后，也就过了启动阶段，预留资源会缓慢的下降到实际使用量加上一个安全值。在实际使用量超过它时，预留值会迅速增加。</p><p>Borg调度器使用资源限额来计算prod级任务（注：准确的说，是高优先级的、延迟敏感的任务，见§6.2）是否可以执行（§3.2），所以这些任务不依赖于回收的资源，也与资源超售无关；对于non-prod的任务，运行任务使用的资源在预留值之内，这样新任务就可以使用回收的资源。</p><p>一台机器有可能因为预留（预测）错误而导致运行时资源不足 —— 即使所有的任务都在资源限额之内。如果这种情况发生了，我们会杀掉或者限制non-prod任务，但从来不对prod任务下手。</p><p>图10表明，如果没有资源回收，将需要更多的机器。在一个中等规模的Cell中大概有20%的工作负载（§6.2）使用了回收的资源。</p><p>图11可以看到更多的细节，其中有预留值、使用量与限额的比例。当资源紧张时，超出内存限额的任务首先会被抢占，不论优先级有多高，所以很少有任务超过内存限额。另一方面，CPU使用量是可以被轻易限制住的，所以短时的毛刺虽然会导致使用量超过预留值，但这没什么损害。</p><p>图11表明了资源回收可能还过于保守：在预留值和实际使用量中间还有一大段差距。为了测试这一点，我们选择了一个线上Cell，（第一周作为参照基准，）第二周将其估计算法的参数调整为比较<strong>激进</strong>的设置，即把安全裕度留小一点；第三周采取的是介于激进和基准之间的<strong>适度</strong>策略，最后一周恢复到基准策略。</p><p><img src="/img/borg-fig-08-09-10-11.png" alt=""></p><p>图12展示了结果。第二周的预留值明显更接近实际使用量，第三周稍大一点，最大的是第一周和第四周。和预期的一样，第二周和第三周的OOM比率轻微地增加了（注：第3周后期的异常情况与本次实验无关）。在评估了这个结果后，我们认为利大于弊，于是在其它Cell上也采用了<strong>适度</strong>策略的资源回收参数。</p><p><img src="/img/borg-fig-12.png" alt="图12. 更激进的资源估计可以回收更多资源，但会稍增加OOM事件"></p><h1 id="6-隔离"><a href="#6-隔离" class="headerlink" title="6. 隔离"></a>6. 隔离</h1><p>50%的机器运行了9个以上的任务；处于90%分位数的机器则有大约25个任务，4500个线程[83]。虽然在应用之间共享机器会增加利用率，但也需要一个比较好的机制来保证任务之间不产生干扰。这同时适用于安全和性能两个方面。</p><h2 id="6-1-安全隔离"><a href="#6-1-安全隔离" class="headerlink" title="6.1 安全隔离"></a>6.1 安全隔离</h2><p>我们使用Linux的chroot作为同一台机器上不同任务之间的主要安全隔离机制。仅当某台机器有用户运行的任务时，为了允许远程调试，我们以前会自动分发（或废除）SSH秘钥，使用户可以访问这台机器。对大多数用户来说，现在被替换为<code>borgssh</code>命令，这个程序和Borglet协同构建一个SSH通道，连接到与任务运行在同一个chroot和cgroup下的Shell，这样限制就更加严格了。</p><p>Google的AppEngine（GAE）[38]和Google Compute Engine（GCE）使用VM和安全沙箱技术运行外部的软件。我们把每个运行在KVM进程中的VM作为一个Borg任务来运行。</p><h2 id="6-2-性能隔离"><a href="#6-2-性能隔离" class="headerlink" title="6.2 性能隔离"></a>6.2 性能隔离</h2><p>早期的Borglet使用了一种相对原始的资源隔离措施：事后检查内存、硬盘和CPU使用量，终止使用过多内存和硬盘的任务，或者降低使用过多CPU的任务的Linux CPU优先级。不过，一些粗暴的任务还是能很容易地影响到同台机器上其它任务的性能，于是有的用户就会多申请资源来让Borg减少与其共存的任务数量，降低了资源利用率。资源回收可以弥补一些损失，但不是全部，因为涉及到安全裕度。在极端情况下，用户会要求使用专属的机器或者Cell。</p><p>目前，所有Borg任务都运行在基于Linux cgroup的资源容器[17, 58, 62]里。Borglet控制着这些容器的设置。有了OS内核的帮助，控制能力得到了改善。即使这样，偶尔还是有底层的资源发生冲突（例如内存带宽或L3缓存污染），见[60, 83]。</p><p>为了应对过载和超售，Borg任务有一个应用类别（appclass）属性。最重要的区分是延迟敏感（LS）的应用和本文中称为批处理（batch）的其它类别。LS任务包括面向用户的应用和需要快速响应的共享基础设施。高优先级的LS任务得到最高优待，可以暂时让批处理任务等待几秒种。</p><p>第二个区分是：<strong>可压缩</strong>资源（例如CPU，硬盘I/O带宽），都是基于速率的，可以通过降低一个任务的服务质量而不是杀死它来回收；<strong>不可压缩</strong>资源（例如内存、硬盘空间），这些一般来说不杀掉任务是没办法回收的。如果一个机器用光了不可压缩资源，Borglet马上就会开始杀死任务，从低优先级开始，直到能满足剩下的资源预留。如果机器用完了可压缩资源，Borglet会限制使用量（偏好LS任务），这样不用杀死任何任务也能处理短期负载尖峰。如果情况没有改善，Borgmaster会从这个机器上移除一个或多个任务。</p><p>Borglet有一个用户态的控制循环，负责以下操作：为容器确定内存量，prod任务基于预测值，而non-prod任务则基于内存压力；处理来自内核的OOM事件；当任务试图分配超过其自身限额的内存时，或者超售的机器上确实耗尽内存时，都会杀死任务。Linux激进的文件缓存让我们的实现复杂得多，因为需要精确计算内存使用量。</p><p>为了增强性能隔离，LS任务可以预留整个物理CPU核，以阻止别的LS任务来使用它们。批处理任务被允许运行在任何核上，但是相比LS任务，批处理任务只分配了很少的调度份额。Borglet动态地调整贪婪的LS任务的资源上限，以保证它们不会把批处理任务饿上几分钟，必要时有选择的使用CFS带宽控制[75]；仅用份额来表示是不够的，因为我们有多个优先级。</p><p><img width="600" src="/img/borg-fig-13.png" alt="图13. 调度延迟与负载的关系。即一个就绪线程需要等待超过1 ms才能运行的比率，与机器繁忙程度的关系。每组数据条中，左侧是延迟敏感的任务，右侧是批处理任务。只有很少的比率需要等5 ms以上，超过10 ms就极少了。这是2013年12月从一个代表性的Cell中获取的一个月的数据；误差线是每天的波动"></p><p>同Leverich[56]一样，我们发现标准的Linux CPU调度器（CFS）需要大幅调整才能同时支持低延迟和高利用率。为了减少调度延迟：我们内部版本的CFS对每个<code>cgroup</code>都有单独的负载历史 [16]；允许LS任务抢占批处理任务；当一个CPU有多个就绪的LS任务时，会减少其调度量（Quantum）。幸运的是，我们的大多应用使用一个线程处理一个请求的模型，这样就缓解了持续的负载失衡。我们节俭地使用 <code>cpusets</code>为有特别严格的延迟需求的应用分配CPU核。这些努力的一些效果展示在图13中。我们持续在这方面投入，增加感知NUMA、超线程、能耗（如 [81]）的线程放置和CPU管理，改进Borglet的控制精确度。</p><p>任务被允许在其上限之内消费资源。大部分任务还允许去使用超出上限的可压缩资源，例如CPU，以利用空闲资源。只有5%的LS任务禁止这么做，主要是为了改善可预测性；小于1%的批处理任务也禁止了。使用超量内存默认是被禁止的，因为这会增加任务被杀掉的概率，不过即使这样，10%的LS任务解除了这个限制，79%的批处理任务也解除了，因为这是MapReduce框架的默认设置。这补偿了资源回收（§5.5）的后果。批处理任务很乐意使用空闲的或回收的内存：大多情况下这样运作得很好，即使偶尔批处理任务会被急需资源的LS任务杀掉。</p><h1 id="7-相关工作"><a href="#7-相关工作" class="headerlink" title="7. 相关工作"></a>7. 相关工作</h1><p>数十年来，资源调度已经在多种场景得到了研究，如广域高性能计算网格、工作站网络、和大规模服务器集群等。我们这里只关注最相关的大规模服务器集群这个场景。</p><p>最近的一些研究分析了来自于Yahoo!、Google和Facebook的集群记录数据[20, 52, 63, 68, 70, 80, 82]，展现了这些现代的数据中心和工作负载固有的异构性和大规模带来的挑战。[69]包含了对集群管理器架构的分类。</p><p>Apache Mesos[45]将资源管理和任务放置功能拆分到一个集中资源管理器（类似于去掉调度器的Bormaster）和多种“框架”（比如Hadoop[41]和Spark[73]）之间，两者基于供应（Offer）机制交互。Borg则把这些功能集中在一起，使用基于请求的机制，而且扩展性相当好。DRF[29, 35, 36, 66]最初是为Mesos开发的；Borg则使用优先级和准入配额来替代。Mesos开发者已经宣布了他们扩展Mesos的雄心壮志：预测性资源分配和回收，以及解决[69]中发现的一些问题。</p><p>YARN[76]是一个针对Hadoop的集群管理器。每个应用都有一个另外的管理器，与中央资源管理器谈判所需资源；这跟大约2008年开始Google的MapReduce作业已经使用的向Borg获取资源的模式如出一辙。YARN的资源管理器最近才支持容错。一个相关的开源项目是Hadoop Capacity Scheduler（基于容量的调度器）[42]，提供了多租户下的容量保证、多层队列、弹性共享和公平调度。YARN最近扩展支持了多种资源类型、优先级、抢占和高级准入控制[21]。Tetris（俄罗斯方块）研究原型[40]支持完成时间感知的作业装箱。</p><p>Facebook的Tupperware[64]，是一个在集群中调度<code>cgroup</code>容器的类Borg系统；只有少量细节披露出来了，看起来它也提供了某种形式的资源回收功能。Twitter开源的Aurora[5]是一个类似Borg的，用于长期运行服务的调度器，运行与Mesos之上，其配置语言和状态迁移与Borg类似。</p><p>微软的Autopilot[48]为其集群提供了“自动化的软件供应和部署；系统监控；以及采取修复行为处理软硬件故障”的功能。Borg生态系统提供了相似的特性，不过篇幅所限，不再深入讨论；作者Isaard概括了很多我们也赞成的最佳实践。</p><p>Quincy[49]使用了一个网络流模型来提供公平性和数据局部性感知的调度，应用在几百个节点的集群的数据处理DAG上。Borg使用配额和优先级在用户间共享数据，可以扩展到上万台机器。Quincy可以直接处理执行图，而Borg需要在其上层另外构建。</p><p>Cosmos[44]聚焦在批处理上，强调了用户可以公平获取他们已经捐献给集群的资源。每个作业分别有一个管理器来获取资源；只有很少公开的细节。</p><p>微软的Apollo系统[13]为每个短期批处理作业分别使用单独的调度器，以获得高吞吐量，其集群规模看起来与Borg的Cell相当。Apollo投机地执行低优先级后台任务来提升资源利用率，代价是有时有长达多日的队列延迟。Apollo的各节点都一个关于开始时间的预测矩阵，其行列分别为CPU和内存两个资源维度。调度器会综合开始时间、估计的启动开销、获取远程数据的开销来决定部署位置，并用一个随机延时来减少冲突。Borg使用的是中央调度器，基于之前的分配来决定部署位置，可以处理更多的资源维度，而且更关注高可用、长期运行的应用；Apollo也许能处理比Borg更高的任务到达率。</p><p>阿里巴巴的伏羲（Fuxi）[84]支持数据分析的负载，从2009年就开始运行了。类似Borgmaster，一个集中的FuxiMaster（也做了容错多副本）从节点上获取可用资源的信息、接受应用的资源请求，然后匹配两者。伏羲的增量调度策略与Borg的任务等价类是相反的：伏羲用最新的可用资源匹配等待队列里的任务（译注：Borg是用任务匹配资源）。类似Mesos，伏羲允许定义“虚拟资源”类型。只有对合成工作负载的实验结果是公开的。</p><p>Omega[69]支持多个并发的调度器，粗略相当于没有持久存储和链接分片的Borgmaster。Omega调度器使用乐观并发控制的方式去操作一个共享的集群预期的和观察的状态表示。集群状态存储在一个集中持久存储中，用单独的连接组件与Borglet同步。Omage架构设计为支持多种不同的工作负载，它们有自己特定的RPC接口、状态迁移和调度策略（例如长期运行的服务、多个框架批处理作业、如集群存储这样的基础服务、Google云平台上的虚拟机）。相反，Borg提供了一种通用方案，同样的RPC接口、状态迁移、调度策略，为支持多种不同的负载，其规模和复杂度逐渐增加，但目前来说可扩展性还不算一个问题（§3.4）。</p><p>Google的开源项目Kubernetes系统[53]把应用放在Docker容器内[28]，再分发到多个机器上。它既可以运行在物理机上（像Borg那样），也可以运行在多个云供应商（比如Google Compute Engine，GCE）的主机上。Kubernetes正在快速开发中，它的很多开发者也参与开发了Borg。Google提供了一个托管的版本，称为Google Container Engine（GKE）[39]。我们会在下一节里面讨论Kubernetes从Borg中学到了哪些东西。</p><p>在高性能计算社区对这个领域有长期的研究传统（如Maui, Moab, Platform LSF[2, 47, 50]）；但是这和Google Cell所面对的规模、工作负载、容错性是不同的。总体而言，为达到高用率，这些系统需要让任务在一个很长的队列中等待。</p><p>虚拟化供应商，例如VMware[77]，和数据中心方案供应商，例如HP和IBM[46]提供了典型情况下可以扩展到一千台机器规模的集群管理解决方案。另外，一些研究小组的原型系统以多种方式提升了调度质量（如[25, 40, 72, 74]）。</p><p>最后，正如我们所指出的，大规模集群管理的另外一个重要部分是自动化和无人化。[43]指出，失效预案、多租户、健康检查、准入控制，以及可重启性对实现单个运维人员管理更多的机器的目标是必要的。Borg的设计哲学也是这样的，而且支撑了我们的每个SRE管理数万台机器。</p><blockquote><p>Borg从它的前任继承了很多东西，即我们内部的全局工作队列（Global Work Queue）系统，它最初是由Jeff Dean，Olcan Sercinoglu, 和Percy Liang开发的。<br>Conder[85]曾被广泛应用于收集空闲资源，其ClassAds机制[86]支持声明式的语句和自动属性匹配。</p></blockquote><h1 id="8-经验教训和未来工作"><a href="#8-经验教训和未来工作" class="headerlink" title="8. 经验教训和未来工作"></a>8. 经验教训和未来工作</h1><p>在这一节中我们介绍了十多年来我们在生产环境运行Borg得到的定性的经验教训，然后介绍设计Kubernetes[53]是如何吸收这些经验的。</p><h2 id="8-1-教训"><a href="#8-1-教训" class="headerlink" title="8.1 教训"></a>8.1 教训</h2><p>我们从一些Borg作为反面警示的特性开始，然后介绍Kubernetes的替代方案。</p><p><strong>将作业作为唯一的任务分组机制比较受限</strong></p><p>Borg没有内置的方法将多个作业组成单个实体来管理，或将相关的服务实例关联起来（例如，测试通道和生产通道）。作为一个技巧，用户把他们的服务拓扑编码到作业的名称中，然后构建了更高层的管理工具来解析这些名称。这个问题的另外一面是，没办法指向服务的任意子集，这就导致了僵硬的语义，以至于无法滚动升级或改变作业的实例数。</p><p>为了避免这些困难，Kubernetes不再使用作业这个概念，而是用标签（Label）来组织它的调度单元（Pod）。标签是任意的键值对，用户可以对系统的任何对象打上标签。Borg作业可以等效地通过对一组Pod打上 &lt;作业：作业名&gt; 这样的标签来实现。其它有用的分组方式也可以用标签来表示，例如服务、层级、发布类型（如，生产、就绪、测试）。Kubernetes用标签查询的方式来选取待操作的目标对象。这样就比固定的作业分组更加灵活。</p><p><strong>同一台机器的任务共享一个IP太复杂了</strong></p><p>Borg中，同一台机器上的所有任务都使用主机的同一个IP地址，共享端口空间。这就带来几个麻烦：Borg必须把端口当做资源来调度；任务必须先声明它需要多少端口，而且需要支持启动时传入可用端口号；Borglet必须强制端口隔离；命名和RPC系统必须像IP一样处理端口（译注：最后这一点我认为是必要的）。</p><p>多亏了Linux的namespace、虚拟机、IPv6和软件定义网络SDN的出现，Kubernetes可以用一种更用户友好的方式来消解这些复杂性：每个Pod和Service都自己的IP地址，允许开发者选择端口而不是让他们的软件支持基础设施的分配，这也消除了基础设施管理端口的复杂性。</p><p><strong>给资深用户优化而忽略了初级用户</strong></p><p> Borg提供了一大堆针对“资深用户”的特性，这样他们就可以仔细地调节他们程序的运行方式（BCL规范约有230个参数）：开始的目的是为了支持Google的大型资源用户，提升他们的效率会带来显著的效益。但不幸的是，这么复杂的API让初级用户用起来很复杂，而且限制了API的演化。我们的解决方案是在Borg上又做了一些自动化的工具和服务，从实验中决定合理的配置。由于应用支持容错，实验可以自由进行：即使自动化出了问题，也只是小麻烦，不会导致灾难。</p><h2 id="8-2-经验"><a href="#8-2-经验" class="headerlink" title="8.2 经验"></a>8.2 经验</h2><p>另一方面，有不少Borg的设计特性是非常有益的，而且经历了时间考验。</p><p><strong>Alloc是有用的</strong></p><p>Borg的Alloc抽象适用于广泛使用的保存日志模式（§2.4），另一个流行的模式是：一个简单的数据加载任务定期更新Web服务器使用的数据。Alloc和软件包机制允许这些辅助服务由不同的小组开发。Kubernetes对应于Alloc的概念是Pod，它是对一个或多个容器的资源封装，其中的容器共享Pod的资源，而且总是被调度到同一台机器上。Kubernetes使用Pod里的辅助容器来替代Alloc里面的任务，不过思路是一样的。</p><p><strong>集群管理不只是任务管理</strong></p><p>虽然Borg的主要角色是管理任务和机器的生命周期，但Borg上的应用还从其它的集群服务中收益良多，例如域名服务和负载均衡。Kubernetes用Service这个抽象概念来支持域名服务和负载均衡：Service有一个域名和用标签选出的多个Pod的动态集合。集群中的任何容器都可以通过Service域名连接到该服务。幕后，Kubernetes自动将连接到该Service的负载分散到与其标签匹配的Pod之间，由于Pod挂掉后会被重新调度到其它机器上，Kubernetes还会跟踪这些Pod的位置。</p><p><strong>自省是至关重要的</strong></p><p>虽然Borg总体上是工作良好的，但出了问题后，定位根本原因是非常有挑战性的。Borg的一个关键设计选择是把所有的调试信息暴露给用户而不是隐藏起来：Borg有几千个用户，所以“自助”是调试的第一步。虽然一些用户的依赖项让我们难以废弃一些特性或修改内部策略，但这还是成功的，我们还没找到其它实际的替代方式。为管理大量的数据，我们提供了多个层次的UI和调试工具，这样用户就可以快速定位与其作业相关的异常事件，深入挖掘来自其应用和基础设施本身的详细事件和错误日志。</p><p>Kubernetes也计划引入Borg的大部分自省技术。和Kubernetes一起发布了很多工具，比如用于资源监控的cAdvisor[15]，它基于Elasticsearch/Kibana[30]和Fluentd[32]聚合日志。Master可以用来查询某个对象的状态快照。Kubernetes提供了一致机制，所有可以记录事件的组件（例如，被调度的Pod、出错的容器）都可以被客户端访问。</p><p><strong>Master是分布式系统的核心</strong></p><p>Borgmaster最初设计为一个单体的系统，随着时间发展，它演变成了一组服务生态系统的核心。用户作业管理的管理是由这些服务协同完成的。比如，我们把调度器和主要的UI（Sigma）分离成单独的进程，增加了一组服务，包括准入控制、纵向和横向扩展、任务重新装箱、周期性作业提交（cron）、工作流管理，用于离线查询的系统活动归档等。总体而言，这让我们能扩展工作负载和特性集合，但无需牺牲性能和可维护性。</p><p>Kubernetes的架构走的更远一些：它的核心是一个仅处理请求和操作底层状态目标的API服务。集群管理逻辑构建为一个小型的、可组合的微服务，作为API服务的客户端，如故障后仍维持Pod副本个数在期望值的副本管理器，以及管理机器生命周期的节点管理器。</p><h2 id="8-3-总结"><a href="#8-3-总结" class="headerlink" title="8.3 总结"></a>8.3 总结</h2><p>在过去十年间，所有几乎所有的Google集群负载都迁移到了Borg上。我们仍在持续改进它，并把经验应用到了Kubernetes上。</p><h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h1><p>这篇文章的作者负责撰写文章，并完成了评估实验。几十位设计、实现和维护Borg组件和生态系统的工程师才是它成功的关键。我们在这里列出直接参与设计、实现和维护Borgmaster及Borglet的人员。如果有遗漏，我们深表歉意。</p><p>早期版本的Borgmaster设计和实现人员有：Jeremy Dion和Mark Vandevoorde，以及Ben Smith, Ken Ashcraft, Maricia Scott, Ming-Yee Iu 和 Monika Henzinger。早期版本的Borglet主要是由Paul Menage设计和实现的（译注：见[62]）。</p><p>后续的参与者包括：Abhishek Rai, Abhishek Verma, Andy Zheng, Ashwin Kumar, Beng-Hong Lim, Bin Zhang, Bolu Szewczyk, Brian Budge, Brian Grant, Brian Wickman, Chengdu Huang, Cynthia Wong, Daniel Smith, Dave Bort, David Oppenheimer, David Wall, Dawn Chen, Eric Haugen, Eric Tune, Ethan Solomita, Gaurav Dhiman, Geeta Chaudhry, Greg Roelofs, Grzegorz Czajkowski, James Eady, Jarek Kusmierek, Jaroslaw Przybylowicz, Jason Hickey, Javier Kohen, Jeremy Lau, Jerzy Szczepkowski, John Wilkes, Jonathan Wilson, Joso Eterovic, Jutta Degener, Kai Backman, Kamil Yurtsever, Kenji Kaneda, Kevan Miller, Kurt Steinkraus, Leo Landa, Liza Fireman, Madhukar Korupolu, Mark Logan, Markus Gutschke, Matt Sparks, Maya Haridasan, Michael Abd-El-Malek, Michael Kenniston, Mukesh Kumar, Nate Calvin, Onufry Wojtaszczyk, Patrick Johnson, Pedro Valenzuela, Piotr Witusowski, Praveen Kallakuri, Rafal Sokolowski, Richard Gooch, Rishi Gosalia, Rob Radez, Robert Hagmann, Robert Jardine, Robert Kennedy, Rohit Jnagal, Roy Bryant, Rune Dahl, Scott Garriss, Scott Johnson, Sean Howarth, Sheena Madan, Smeeta Jalan, Stan Chesnutt, Temo Arobelidze, Tim Hockin, Todd Wang, Tomasz Blaszczyk, Tomasz Wozniak, Tomek Zielonka, Victor Marmol, Vish Kannan, Vrigo Gokhale, Walfredo Cirne, Walt Drummond, Weiran Liu, Xiaopan Zhang, Xiao Zhang, Ye Zhao, Zohaib Maya.</p><p>Borg SRE团队也是非常重要的，包括：Adam Rogoyski, Alex Milivojevic, Anil Das, Cody Smith, Cooper Bethea, Folke Behrens, Matt Liggett, James Sanford, John Millikin, Matt Brown, Miki Habryn, Peter Dahl, Robert van Gent, Seppi Wilhelmi, Seth Hettich, Torsten Marek, 和 Viraj Alankar。Borg配置语言（BCL）和<code>borgcfg</code>工具最初是Marcel van Lohuizen 和 Robert Griesemer开发的。</p><blockquote><p>我们不小心漏掉了 Brad Strand, Chris Colohan, Divyesh Shah, Eric Wilcox, 和 Pavanish Nirula。</p></blockquote><p>谢谢我们的审稿人（尤其是Eric Brewer, Malte Schwarzkopf 和 Tom Rodeheffer），以及我们的导师Christos Kozyrakis，对这篇论文的反馈。</p><h1 id="勘误"><a href="#勘误" class="headerlink" title="勘误"></a>勘误</h1><p>2015-04-23</p><p>定稿后，我们发现了若干无意的疏漏和歧义。（译注：译文已将勘误内容放置到对应章节。补充的两条参考文献序号有冲突，放在了列表之后，并继续编号为85，86）</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] O. A. Abdul-Rahman and K. Aida. <strong>Towards understanding the usage behavior of Google cloud users: the mice and elephants phenomenon.</strong>In Proc. IEEE Int’l Conf. on Cloud Computing Technology and Science (CloudCom), pages 272–277, Singapore, Dec. 2014.<br>[2] Adaptive Computing Enterprises Inc., Provo, UT. <strong>Maui Scheduler Administrator’s Guide</strong>, 3.2 edition, 2011.<br>[3] T. Akidau, A. Balikov, K. Bekiroğlu, S. Chernyak, J. Haberman, R. Lax, S. McVeety, D. Mills, P. Nordstrom,and S. Whittle. <strong>MillWheel: fault-tolerant stream processing at internet scale</strong>, In Proc. Int’l Conf. on Very Large Data Bases (VLDB), pages 734–746, Riva del Garda, Italy, Aug.2013.<br>[4] Y. Amir, B. Awerbuch, A. Barak, R. S. Borgstrom, and A. Keren. <strong>An opportunity cost approach for job assignment in a scalable computing cluster</strong>, IEEE Trans. Parallel Distrib.Syst., 11(7):760–768, July 2000.<br>[5] <strong>Apache Aurora</strong>. <a href="http://aurora.incubator.apache.org/" target="_blank" rel="noopener">http://aurora.incubator.apache.org/</a>, 2014.<br>[6] <strong>Aurora Configuration Tutorial</strong>. <a href="https://aurora.incubator.apache.org/documentation/latest/configuration-tutorial/" target="_blank" rel="noopener">https://aurora.incubator.apache.org/documentation/latest/configuration-tutorial/</a>, 2014.<br>[7] AWS. <strong>Amazon Web Services VM Instances</strong>. <a href="http://aws.amazon.com/ec2/instance-types/" target="_blank" rel="noopener">http://aws.amazon.com/ec2/instance-types/</a>, 2014.<br>[8] J. Baker, C. Bond, J. Corbett, J. Furman, A. Khorlin, J. Larson, J.-M. Leon, Y. Li, A. Lloyd, and V. Yushprakh. <strong>Megastore: Providing scalable, highly available storage for interactive services</strong>, In Proc. Conference on Innovative Data Systems Research (CIDR), pages 223–234, Asilomar, CA, USA, Jan. 2011.<br>[9] M. Baker and J. Ousterhout. <strong>Availability in the Sprite distributed file system</strong>, Operating Systems Review,25(2):95–98, Apr. 1991.<br>[10] L. A. Barroso, J. Clidaras, and U. Hölzle. <strong>The datacenter as a computer: an introduction to the design of warehouse-scale machines</strong>, Morgan Claypool Publishers, 2nd edition, 2013.<br>[11] L. A. Barroso, J. Dean, and U. Holzle. <strong>Web search for a planet: the Google cluster architecture</strong>, In IEEE Micro, pages 22–28, 2003.<br>[12] I. Bokharouss. <strong>GCL Viewer: a study in improving the understanding of GCL programs</strong>, Technical report, Eindhoven Univ. of Technology, 2008. MS thesis.<br>[13] E. Boutin, J. Ekanayake, W. Lin, B. Shi, J. Zhou, Z. Qian, M. Wu, and L. Zhou. <strong>Apollo: scalable and coordinated scheduling for cloud-scale computing</strong>, In Proc. USENIX Symp. on Operating Systems Design and Implementation (OSDI), Oct. 2014.<br>[14] M. Burrows. <strong>The Chubby lock service for loosely-coupled distributed systems</strong>, In Proc. USENIX Symp. on Operating Systems Design and Implementation (OSDI), pages 335–350,Seattle, WA, USA, 2006.<br>[15] <strong>cAdvisor</strong>. <a href="https://github.com/google/cadvisor" target="_blank" rel="noopener">https://github.com/google/cadvisor</a>, 2014<br>[16] <strong>CFS per-entity load patches</strong>. <a href="http://lwn.net/Articles/531853" target="_blank" rel="noopener">http://lwn.net/Articles/531853</a>, 2013.<br>[17] <strong>cgroups</strong>. <a href="http://en.wikipedia.org/wiki/Cgroups" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Cgroups</a>, 2014.<br>[18] C. Chambers, A. Raniwala, F. Perry, S. Adams, R. R. Henry, R. Bradshaw, and N. Weizenbaum. <strong>FlumeJava: easy, efficient data-parallel pipelines</strong>, In Proc. ACM SIGPLAN Conf. on Programming Language Design and Implementation (PLDI), pages 363–375, Toronto, Ontario, Canada, 2010.<br>[19] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A. Wallach, M. Burrows, T. Chandra, A. Fikes, and R. E. Gruber. <strong>Bigtable: a distributed storage system for structured data</strong>, ACM Trans. on Computer Systems, 26(2):4:1–4:26, June 2008.<br>[20] Y. Chen, S. Alspaugh, and R. H. Katz. <strong>Design insights for MapReduce from diverse production workloads</strong>, Technical Report UCB/EECS–2012–17, UC Berkeley, Jan. 2012.<br>[21] C. Curino, D. E. Difallah, C. Douglas, S. Krishnan, R. Ramakrishnan, and S. Rao. <strong>Reservation-based scheduling: if you’re late don’t blame us!</strong> In Proc. ACM Symp. on Cloud Computing (SoCC), pages 2:1–2:14, Seattle, WA, USA, 2014.<br>[22] J. Dean and L. A. Barroso. <strong>The tail at scale</strong>, Communications of the ACM, 56(2):74–80, Feb. 2012.<br>[23] J. Dean and S. Ghemawat. <strong>MapReduce: simplified data processing on large clusters</strong>, Communications of the ACM, 51(1):107–113, 2008.<br>[24] C. Delimitrou and C. Kozyrakis. <strong>Paragon: QoS-aware scheduling for heterogeneous datacenters</strong>, In Proc. Int’l Conf. on Architectural Support for Programming Languages and Operating Systems (ASPLOS), Mar. 201.<br>[25] C. Delimitrou and C. Kozyrakis. <strong>Quasar: resource-efficient and QoS-aware cluster management</strong>, In Proc. Int’l Conf. on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pages 127–144, Salt Lake City, UT, USA, 2014.<br>[26] S. Di, D. Kondo, and W. Cirne. <strong>Characterization and comparison of cloud versus Grid workloads</strong>, In International Conference on Cluster Computing (IEEE CLUSTER), pages 230–238, Beijing, China, Sept. 2012.<br>[27] S. Di, D. Kondo, and C. Franck. <strong>Characterizing cloud applications on a Google data center</strong>, In Proc. Int’l Conf. on Parallel Processing (ICPP), Lyon, France, Oct. 2013.<br>[28] <strong>Docker Project</strong>. <a href="https://www.docker.io/" target="_blank" rel="noopener">https://www.docker.io/</a>, 2014.<br>[29] D. Dolev, D. G. Feitelson, J. Y. Halpern, R. Kupferman, and N. Linial. <strong>No justified complaints: on fair sharing of multiple resources</strong>, In Proc. Innovations in Theoretical Computer Science (ITCS), pages 68–75, Cambridge, MA, USA, 2012.<br>[30] <strong>ElasticSearch</strong>. <a href="http://www.elasticsearch.org" target="_blank" rel="noopener">http://www.elasticsearch.org</a>, 2014.<br>[31] D. G. Feitelson. <strong>Workload Modeling for Computer Systems Performance Evaluation</strong>, Cambridge University Press, 2014.<br>[32] <strong>Fluentd</strong>. <a href="http://www.fluentd.org/" target="_blank" rel="noopener">http://www.fluentd.org/</a>, 2014.<br>[33] <strong>GCE. Google Compute Engine</strong>. <a href="http://cloud.google.com/products/compute-engine/" target="_blank" rel="noopener">http://cloud.google.com/products/compute-engine/</a>, 2014.<br>[34] S. Ghemawat, H. Gobioff, and S.-T. Leung. <strong>The Google File System</strong>, In Proc. ACM Symp. on Operating Systems Principles (SOSP), pages 29–43, Bolton Landing, NY, USA, 2003. ACM.<br>[35] A. Ghodsi, M. Zaharia, B. Hindman, A. Konwinski, S. Shenker, and I. Stoica. <strong>Dominant Resource Fairness: fair allocation of multiple resource types</strong>, In Proc. USENIX Symp. on Networked Systems Design and Implementation (NSDI), pages 323–326, 2011.<br>[36] A. Ghodsi, M. Zaharia, S. Shenker, and I. Stoica. <strong>Choosy: max-min fair sharing for datacenter jobs with constraints</strong>, In Proc. European Conf. on Computer Systems (EuroSys), pages 365–378, Prague, Czech Republic, 2013.<br>[37] D. Gmach, J. Rolia, and L. Cherkasova. <strong>Selling T-shirts and time shares in the cloud</strong>, In Proc. IEEE/ACM Int’l Symp. on Cluster, Cloud and Grid Computing (CCGrid), pages 539–546, Ottawa, Canada, 2012.<br>[38] <strong>Google App Engine</strong>. <a href="http://cloud.google.com/AppEngine" target="_blank" rel="noopener">http://cloud.google.com/AppEngine</a>, 2014.<br>[39] <strong>Google Container Engine (GKE)</strong>. <a href="https://cloud.google.com/container-engine/" target="_blank" rel="noopener">https://cloud.google.com/container-engine/</a>, 2015.<br>[40] R. Grandl, G. Ananthanarayanan, S. Kandula, S. Rao, and A. Akella. <strong>Multi-resource packing for cluster schedulers</strong>, In Proc. ACM SIGCOMM, Aug. 2014.<br>[41] <strong>Apache Hadoop Project</strong>. <a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a>, 2009.<br>[42] <strong>Hadoop MapReduce Next Generation – Capacity Scheduler</strong>. <a href="http://hadoop.apache.org/docs/r2.2.0/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.2.0/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html</a>, 2013.<br>[43] J. Hamilton. <strong>On designing and deploying internet-scale services</strong>. In Proc. Large Installation System Administration Conf. (LISA), pages 231–242, Dallas, TX, USA, Nov. 2007.<br>[44] P. Helland. <strong>Cosmos: big data and big challenges</strong>. <a href="http://research.microsoft.com/en-us/events/fs2011/helland_cosmos_big_data_and_big_challenges.pdf" target="_blank" rel="noopener">http://research.microsoft.com/en-us/events/fs2011/ helland_cosmos_big_data_and_big_challenges.pdf</a>, 2011.<br>[45] B. Hindman, A. Konwinski, M. Zaharia, A. Ghodsi, A. Joseph, R. Katz, S. Shenker, and I. Stoica. <strong>Mesos: a platform for fine-grained resource sharing in the data center</strong>. In Proc. USENIX Symp. on Networked Systems Design and Implementation (NSDI), 2011.<br>[46] <strong>IBM Platform Computing</strong>. <a href="http://www-03.ibm.com/systems/technicalcomputing/platformcomputing/products/clustermanager/index.html" target="_blank" rel="noopener">http://www-03.ibm.com/systems/technicalcomputing/platformcomputing/products/clustermanager/ index.html</a>.<br>[47] S. Iqbal, R. Gupta, and Y.-C. Fang. <strong>Planning considerations for job scheduling in HPC clusters</strong>, Dell Power Solutions, Feb. 2005.<br>[48] M. Isaard. <strong>Autopilot: Automatic data center management</strong>, ACM SIGOPS Operating Systems Review, 41(2), 2007.<br>[49] M. Isard, V. Prabhakaran, J. Currey, U. Wieder, K. Talwar, and A. Goldberg. <strong>Quincy: fair scheduling for distributed computing clusters</strong>, In Proc. ACM Symp. on Operating Systems Principles (SOSP), 2009.<br>[50] D. B. Jackson, Q. Snell, and M. J. Clement. <strong>Core algorithms of the Maui scheduler</strong>, In Proc. Int’l Workshop on Job Scheduling Strategies for Parallel Processing, pages 87–102. Springer-Verlag, 2001.<br>[51] M. Kambadur, T. Moseley, R. Hank, and M. A. Kim. <strong>Measuring interference between live datacenter applications</strong>, In Proc. Int’l Conf. for High Performance Computing, Networking, Storage and Analysis (SC), Salt Lake City, UT, Nov. 2012.<br>[52] S. Kavulya, J. Tan, R. Gandhi, and P. Narasimhan. <strong>An analysis of traces from a production MapReduce cluster</strong>, In Proc. IEEE/ACM Int’l Symp. on Cluster, Cloud and Grid Computing (CCGrid), pages 94–103, 2010.<br>[53] <strong>Kubernetes</strong>. <a href="http://kubernetes.io" target="_blank" rel="noopener">http://kubernetes.io</a>, Aug. 2014.<br>[54] <strong>Kernel Based Virtual Machine</strong>. <a href="http://www.linux-kvm.org" target="_blank" rel="noopener">http://www.linux-kvm.org</a>.<br>[55] L. Lamport. <strong>The part-time parliament</strong>, ACM Trans. on Computer Systems, 16(2):133–169, May 1998.<br>[56] J. Leverich and C. Kozyrakis. <strong>Reconciling high server utilization and sub-millisecond quality-of-service</strong>, In Proc. European Conf. on Computer Systems (EuroSys), page 4, 2014.<br>[57] Z. Liu and S. Cho. <strong>Characterizing machines and workloads on a Google cluster</strong>, In Proc. Int’l Workshop on Scheduling and Resource Management for Parallel and Distributed Systems (SRMPDS), Pittsburgh, PA, USA, Sept. 2012.<br>[58] <strong>Google LMCTFY project (let me contain that for you)</strong>. <a href="http://github.com/google/lmctfy" target="_blank" rel="noopener">http://github.com/google/lmctfy</a>, 2014.<br>[59] G. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert, I. Horn, N. Leiser, and G. Czajkowski. <strong>Pregel: a system for large-scale graph processing</strong>, In Proc. ACM SIGMOD Conference, pages 135–146, Indianapolis, IA, USA, 2010.<br>[60] J. Mars, L. Tang, R. Hundt, K. Skadron, and M. L. Soffa. <strong>Bubble-Up: increasing utilization in modern warehouse scale computers via sensible co-locations</strong>, In Proc. Int’l Symp. on Microarchitecture (Micro), Porto Alegre, Brazil, 2011.<br>[61] S. Melnik, A. Gubarev, J. J. Long, G. Romer, S. Shivakumar, M. Tolton, and T. Vassilakis. <strong>Dremel: interactive analysis of web-scale datasets</strong>, In Proc. Int’l Conf. on Very Large Data Bases (VLDB), pages 330–339, Singapore, Sept. 2010.<br>[62] P. Menage. <strong>Linux control groups</strong>. <a href="http://www.kernel.org/doc/Documentation/cgroups/cgroups.txt" target="_blank" rel="noopener">http://www.kernel.org/doc/Documentation/cgroups/cgroups.txt</a>, 2007–2014.<br>[63] A. K. Mishra, J. L. Hellerstein, W. Cirne, and C. R. Das. <strong>Towards characterizing cloud backend workloads: insights from Google compute clusters</strong>, ACM SIGMETRICS Performance Evaluation Review, 37:34–41, Mar. 2010.<br>[64] A. Narayanan. <strong>Tupperware: containerized deployment at Facebook</strong>. <a href="http://www.slideshare.net/dotCloud/tupperware-containerized-deployment-at-facebook" target="_blank" rel="noopener">http://www.slideshare.net/dotCloud/tupperware-containerized-deployment-at-facebook</a>, June 2014.<br>[65] K. Ousterhout, P. Wendell, M. Zaharia, and I. Stoica. <strong>Sparrow: distributed, low latency scheduling</strong>, In Proc. ACM Symp. on Operating Systems Principles (SOSP), pages 69–84, Farminton, PA, USA, 2013.<br>[66] D. C. Parkes, A. D. Procaccia, and N. Shah. <strong>Beyond Dominant Resource Fairness: extensions, limitations, and indivisibilities</strong>, In Proc. Electronic Commerce, pages 808–825, Valencia, Spain, 2012.<br>[67] <strong>Protocol buffers</strong>. <a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="noopener">https://developers.google.com/protocol-buffers/</a>, and <a href="https://github.com/google/protobuf/" target="_blank" rel="noopener">https://github.com/google/protobuf/</a>, 2014.<br>[68] C. Reiss, A. Tumanov, G. Ganger, R. Katz, and M. Kozuch. <strong>Heterogeneity and dynamicity of clouds at scale: Google trace analysis</strong>, In Proc. ACM Symp. on Cloud Computing (SoCC), San Jose, CA, USA, Oct. 2012.<br>[69] M. Schwarzkopf, A. Konwinski, M. Abd-El-Malek, and J. Wilkes. <strong>Omega: flexible, scalable schedulers for large compute clusters</strong>, In Proc. European Conf. on Computer Systems (EuroSys), Prague, Czech Republic, 2013.<br>[70] B. Sharma, V. Chudnovsky, J. L. Hellerstein, R. Rifaat, and C. R. Das. <strong>Modeling and synthesizing task placement constraints in Google compute clusters</strong>, In Proc. ACM Symp. on Cloud Computing (SoCC), pages 3:1–3:14, Cascais, Portugal, Oct. 2011.<br>[71] E. Shmueli and D. G. Feitelson. <strong>On simulation and design of parallel-systems schedulers: are we doing the right thing?</strong> IEEE Trans. on Parallel and Distributed Systems, 20(7):983–996, July 2009.<br>[72] A. Singh, M. Korupolu, and D. Mohapatra. <strong>Server-storage virtualization: integration and load balancing in data centers</strong>, In Proc. Int’l Conf. for High Performance Computing, Networking, Storage and Analysis (SC), pages 53:1–53:12, Austin, TX, USA, 2008.<br>[73] <strong>Apache Spark Project</strong>. <a href="http://spark.apache.org/" target="_blank" rel="noopener">http://spark.apache.org/</a>, 2014.<br>[74] A. Tumanov, J. Cipar, M. A. Kozuch, and G. R. Ganger. <strong>Alsched: algebraic scheduling of mixed workloads in heterogeneous clouds</strong>, In Proc. ACM Symp. on Cloud Computing (SoCC), San Jose, CA, USA, Oct. 2012.<br>[75] P. Turner, B. Rao, and N. Rao. <strong>CPU bandwidth control for CFS</strong>, In Proc. Linux Symposium, pages 245–254, July 2010.<br>[76] V. K. Vavilapalli, A. C. Murthy, C. Douglas, S. Agarwal, M. Konar, R. Evans, T. Graves, J. Lowe, H. Shah, S. Seth, B. Saha, C. Curino, O. O’Malley, S. Radia, B. Reed, and E. Baldeschwieler. <strong>Apache Hadoop YARN: Yet Another Resource Negotiator</strong>, In Proc. ACM Symp. on Cloud Computing (SoCC), Santa Clara, CA, USA, 2013.<br>[77] <strong>VMware VCloud Suite</strong>. <a href="http://www.vmware.com/products/vcloud-suite/" target="_blank" rel="noopener">http://www.vmware.com/products/vcloud-suite/</a>.<br>[78] A. Verma, M. Korupolu, and J. Wilkes. <strong>Evaluating job packing in warehouse-scale computing</strong>, In IEEE Cluster, pages 48–56, Madrid, Spain, Sept. 2014.<br>[79] W. Whitt. <strong>Open and closed models for networks of queues</strong>, AT&amp;T Bell Labs Technical Journal, 63(9), Nov. 1984.<br>[80] J. Wilkes. <strong>More Google cluster data</strong>. <a href="http://googleresearch.blogspot.com/2011/11/more-google-cluster-data.html" target="_blank" rel="noopener">http://googleresearch.blogspot.com/2011/11/more-google-cluster-data.html</a>, Nov. 2011.<br>[81] Y. Zhai, X. Zhang, S. Eranian, L. Tang, and J. Mars. <strong>HaPPy: Hyperthread-aware power profiling dynamically</strong>, In Proc. USENIX Annual Technical Conf. (USENIX ATC), pages 211–217, Philadelphia, PA, USA, June 2014. USENIX Association.<br>[82] Q. Zhang, J. Hellerstein, and R. Boutaba. <strong>Characterizing task usage shapes in Google’s compute clusters</strong>, In Proc. Int’l Workshop on Large-Scale Distributed Systems and Middleware (LADIS), 2011.<br>[83] X. Zhang, E. Tune, R. Hagmann, R. Jnagal, V. Gokhale, and J. Wilkes. <strong>CPI2: CPU performance isolation for shared compute clusters</strong>, In Proc. European Conf. on Computer Systems (EuroSys), Prague, Czech Republic, 2013.<br>[84] Z. Zhang, C. Li, Y. Tao, R. Yang, H. Tang, and J. Xu. <strong>Fuxi: a fault-tolerant resource management and job scheduling system at internet scale</strong>, In Proc. Int’l Conf. on Very Large Data Bases (VLDB), pages 1393–1404. VLDB Endowment Inc., Sept. 2014.<br>[85] Michael Litzkow, Miron Livny, and Matt Mutka. <strong>Condor - A Hunter of Idle Workstations</strong>, In Proc. Int’l Conf. on Distributed Computing Systems (ICDCS) , pages 104-111, June 1988.<br>[86] Rajesh Raman, Miron Livny, and Marvin Solomon. <strong>Matchmaking: Distributed Resource Management for High Throughput Computing</strong>, In Proc. Int’l Symp. on High Performance Distributed Computing (HPDC) , Chicago, IL, USA, July 1998.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;发表于EuroSys 2015的 &lt;strong&gt;&lt;em&gt;Large-scale cluster management at Google with Borg&lt;/em&gt;&lt;/strong&gt; 详细介绍了Google的Borg资源管理器。已经有网友“难易（HardySimpson）” 翻译了此文，这里对其稍作修订。之前读过两三遍此文，每遍都感觉有新的体会，这次修订就是为了更仔细地读一遍。&lt;/p&gt;
    
    </summary>
    
      <category term="yi" scheme="https://ying-zhang.github.io/categories/yi/"/>
    
    
  </entry>
  
  <entry>
    <title>【译文】Docker镜像格式规范，v1.2</title>
    <link href="https://ying-zhang.github.io/yi/2017/x-docker-image-spec-v1.2/"/>
    <id>https://ying-zhang.github.io/yi/2017/x-docker-image-spec-v1.2/</id>
    <published>2017-05-15T16:00:00.000Z</published>
    <updated>2018-06-03T15:14:29.884Z</updated>
    
    <content type="html"><![CDATA[<p>原文见 <a href="https://github.com/moby/moby/blob/master/image/spec/v1.2.md" target="_blank" rel="noopener">https://github.com/moby/moby/blob/master/image/spec/v1.2.md</a><br>Docker已经迁移到Moby项目了。</p><a id="more"></a><hr><h1 id="Docker镜像规范v1-2-0"><a href="#Docker镜像规范v1-2-0" class="headerlink" title="Docker镜像规范v1.2.0"></a>Docker镜像规范v1.2.0</h1><p><strong>镜像（Image）</strong>是在基础文件集（root filesystem）之上依次变更的集合，及在容器运行的默认执行参数。本规范概述这些文件变更及执行参数的格式，创建和使用它们的方法。<br>此版本的镜像规范自Docker 1.12开始采用。</p><blockquote><p>译注：本规范中的 <strong>filesystem</strong> 并非通常意义的文件系统，实际上只是一组文件及文件夹的集合，故译为 <strong>文件集</strong>。</p></blockquote><h2 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h2><p>本规范使用以下术语:</p><h3 id="层（Layer）"><a href="#层（Layer）" class="headerlink" title="层（Layer）"></a>层（Layer）</h3><p>镜像由 <strong>层</strong> 组成。 每一层都是若干文件的变更集合。层不包含环境变量或默认参数等元数据。这些元数据是镜像整体的属性，而不是特定层的。</p><h3 id="镜像的JSON描述文件"><a href="#镜像的JSON描述文件" class="headerlink" title="镜像的JSON描述文件"></a>镜像的JSON描述文件</h3><p>整个镜像有一个JSON描述文件，它包含镜像的基本信息，如创建的日期、作者、父镜像的ID、以及启动/运行的配置（如入口命令、默认参数、CPU / 内存份额、网络和数据卷等）。JSON文件还列出了组成镜像的每个层的加密散列及其命令历史。<br>该JSON文件是不可变的，更改它会导致重新计算整个镜像的ImageID（译注：见下面ImageID的计算方法小节），这意味着派生出一个新的镜像，而不是改变现有的镜像。</p><h3 id="镜像文件变更集（changeset）"><a href="#镜像文件变更集（changeset）" class="headerlink" title="镜像文件变更集（changeset）"></a>镜像文件变更集（changeset）</h3><p>每个层都是一组在其父层之上增加、修改或删除文件的归档。使用分层或联合文件系统（如AUFS），或通过从文件系统快照计算差异（Diff），可以将一系列的层（即文件变更集）合并成一个虚拟的单层文件集合（one cohesive filesystem）。</p><h3 id="层的DiffID"><a href="#层的DiffID" class="headerlink" title="层的DiffID"></a>层的DiffID</h3><p>将一个层的所有文件内容序列化后，计算出一个加密散列来作为该层的标识。具体是将层打包为一个<code>tar</code>包，然后计算其SHA256摘要，用十六进制编码表示长度为256比特的串（共64个字符），<br>如<code>sha256:a9561eb1b190625c9adb5a9513e72c4dedafc1cb2d4c5236c9a6957ec7dfd5a9</code>。<br>层的打包和解包必须是可重复的，以免更改层的ID，例如，应使用<code>tar-split</code>来保存tar包的header。注意，层的ID是基于未压缩的tar包计算的。</p><blockquote><p>译注：关于层的打包和解包的可重复性，<code>tar</code>程序将一组文件打包的 <strong>顺序</strong> 是与文件系统相关的，此处没有详细说明可重复性的实现方式，可参考Docker源码深入了解。<br>参考：<a href="https://unix.stackexchange.com/questions/120143/how-is-the-order-in-which-tar-works-on-files-determined" target="_blank" rel="noopener">tar打包的顺序</a>。</p></blockquote><h3 id="层的ChainID"><a href="#层的ChainID" class="headerlink" title="层的ChainID"></a>层的ChainID</h3><p>为方便起见，可以给一串有序的层计算出一个ID，称为 <strong>ChainID</strong>。<br>仅有一个层时，其ChainID与该层的DiffID相同。多个层时，其ChainID由下面的递归公式给出：</p><script type="math/tex; mode=display">ChainID(layerN)=SHA256hex(ChainID(layer(N-1))+ " \quad" +DiffID(layerN))</script><h3 id="镜像的ImageID"><a href="#镜像的ImageID" class="headerlink" title="镜像的ImageID"></a>镜像的ImageID</h3><p>每个镜像的ID是其JSON描述文件的SHA256散列值，用十六进制编码表示，<br>如<code>sha256:a9561eb1b190625c9adb5a9513e72c4dedafc1cb2d4c5236c9a6957ec7dfd5a9</code>。<br>由于JSON文件包含镜像所有层的散列ID，据此计算出的ImageID，使得可以对镜像的即各层按内容寻址（Content Addressable，地址即各层的DiffID）。</p><h3 id="标签（Tag）"><a href="#标签（Tag）" class="headerlink" title="标签（Tag）"></a>标签（Tag）</h3><p>Tag是用户为ImageID指定的说明文字。Tag中的字符只能是大小写英文字母、数字、短线、下划线和点，即<code>[a-zA-Z0-9_.-]</code>，首个字符不能是<code>.</code>或<code>-</code>。Tag不能超过127个字符。</p><h3 id="镜像名（Repository）"><a href="#镜像名（Repository）" class="headerlink" title="镜像名（Repository）"></a>镜像名（Repository）</h3><p>这里的<code>Repository</code>是指镜像全名在冒号<code>:</code>之前的部分，冒号<code>:</code>之后的部分是镜像的标签（tag），用来区分镜像的版本。 如名为<code>my-app:3.1.4</code>的镜像，<code>my-app</code>就是镜像的 Repository 部分。<br>Repository又可以用斜杠<code>/</code>分隔开，<code>/</code>之前的部分是可选的DNS格式的主机名。主机名必须符合DNS规则，但 <strong>不得</strong> 包含下划线<code>_</code>字符，主机名可以有如<code>：8080</code>格式的端口号。<br>镜像名可以包含小写字符，数字和分隔符。 分隔符是句点<code>.</code>，一个或两个下划线<code>_</code>，或一个或多个短横线<code>-</code>，镜像名 <strong>不允许</strong> 以分隔符开头或结尾。</p><blockquote><p>译注：</p><ul><li>这里的 Repository 容易与git的 <strong>代码仓库</strong> 概念混淆。</li><li>DNS名和主机名的格式稍有不同，一般来说，主机名不允许使用下划线<code>_</code>，参考<a href="https://tools.ietf.org/html/rfc1123" target="_blank" rel="noopener">RFC 1123</a></li></ul></blockquote><h2 id="镜像的JSON描述文件示例"><a href="#镜像的JSON描述文件示例" class="headerlink" title="镜像的JSON描述文件示例"></a>镜像的JSON描述文件示例</h2><p>下面是一个镜像的JSON描述文件示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">  &quot;author&quot;: &quot;Alyssa P. Hacker &amp;ltalyspdev@example.com&amp;gt&quot;,</span><br><span class="line">  &quot;config&quot;: &#123;</span><br><span class="line">    &quot;Cmd&quot;: [</span><br><span class="line">      &quot;--foreground&quot;,</span><br><span class="line">      &quot;--config&quot;,</span><br><span class="line">      &quot;/etc/my-app.d/default.cfg&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;CpuShares&quot;: 8,</span><br><span class="line">    &quot;Entrypoint&quot;: [</span><br><span class="line">      &quot;/bin/my-app-binary&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;Env&quot;: [</span><br><span class="line">      &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,</span><br><span class="line">      &quot;FOO=docker_is_a_really&quot;,</span><br><span class="line">      &quot;BAR=great_tool_you_know&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;ExposedPorts&quot;: &#123;</span><br><span class="line">      &quot;8080/tcp&quot;: &#123;&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;Memory&quot;: 2048,</span><br><span class="line">    &quot;MemorySwap&quot;: 4096,</span><br><span class="line">    &quot;User&quot;: &quot;alice&quot;,</span><br><span class="line">    &quot;Volumes&quot;: &#123;</span><br><span class="line">      &quot;/var/job-result-data&quot;: &#123;&#125;,</span><br><span class="line">      &quot;/var/log/my-app-logs&quot;: &#123;&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;WorkingDir&quot;: &quot;/home/alice&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;created&quot;: &quot;2015-10-31T22:22:56.015925234Z&quot;,</span><br><span class="line">  &quot;history&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;created&quot;: &quot;2015-10-31T22:22:54.690851953Z&quot;,</span><br><span class="line">      &quot;created_by&quot;: &quot;/bin/sh -c #(nop) ADD file:a3bc1e842b69636f9df5256c49c5374fb4eef1e281fe3f282c65fb853ee171c5 in /&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;created&quot;: &quot;2015-10-31T22:22:55.613815829Z&quot;,</span><br><span class="line">      &quot;created_by&quot;: &quot;/bin/sh -c #(nop) CMD [\&quot;sh\&quot;]&quot;,</span><br><span class="line">      &quot;empty_layer&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;os&quot;: &quot;linux&quot;,</span><br><span class="line">  &quot;rootfs&quot;: &#123;</span><br><span class="line">    &quot;diff_ids&quot;: [</span><br><span class="line">      &quot;sha256:c6f988f4874bb0add23a778f753c65efe992244e148a1d2ec2a8b664fb66bbd1&quot;,</span><br><span class="line">      &quot;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot;: &quot;layers&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，Docker生成的镜像JSON描述文件不包含为了格式化而插入的空格，这里是为了方便阅读。</p><h2 id="镜像的JSON描述文件说明"><a href="#镜像的JSON描述文件说明" class="headerlink" title="镜像的JSON描述文件说明"></a>镜像的JSON描述文件说明</h2><h3 id="created"><a href="#created" class="headerlink" title="created"></a>created</h3><p><code>string</code><br>镜像创建的日期和时间，<a href="https://zh.wikipedia.org/wiki/ISO_8601" target="_blank" rel="noopener">ISO-8601格式</a>。</p><h3 id="author"><a href="#author" class="headerlink" title="author"></a>author</h3><p><code>string</code><br>创建和负责维护改镜像的人员或组织名，或Email。</p><h3 id="architecture"><a href="#architecture" class="headerlink" title="architecture"></a>architecture</h3><p><code>string</code><br>镜像中可执行文件的CPU架构，可以是 </p><ul><li><code>386</code></li><li><code>amd64</code></li><li><code>arm</code><br>未来可能会支持更多的架构，有的容器引擎可能不支持某些架构。</li></ul><h3 id="os"><a href="#os" class="headerlink" title="os"></a>os</h3><p><code>string</code><br>镜像运行的操作系统名，可以是 </p><ul><li><code>darwin</code></li><li><code>freebsd</code></li><li><code>linux</code><br>未来可能会支持更多的架构，有的容器引擎可能不支持某些操作系统。</li></ul><h3 id="config"><a href="#config" class="headerlink" title="config"></a>config</h3><p><code>struct</code><br><code>config</code>结构是从镜像创建容器时，使用的基本执行参数。<code>config</code>可以是空值<code>null</code>，则创建容器时必须提供所有必要的执行参数。</p><p><code>config</code>结构的各字段说明</p><h4 id="User"><a href="#User" class="headerlink" title="User"></a>User</h4><p><code>string</code><br>容器中进程执行使用的用户名或UID。如果创建容器时没有在命令行给出，将使用此配置项的值。下面的格式都是有效的：</p><ul><li><code>user</code></li><li><code>uid</code></li><li><code>user:group</code></li><li><code>uid:gid</code></li><li><code>uid:group</code></li><li><code>user:gid</code></li></ul><p>如果没有给出组名 <code>group</code>/<code>gid</code>，默认的组使用容器中<code>/etc/passwd</code>文件对应的<code>user</code>/<code>uid</code>项。</p><h4 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h4><p><code>integer</code><br>内存限值（以 <strong>字节</strong> 为单位）。如果创建容器时没有在命令行给出，则使用此配置项的值。</p><h4 id="MemorySwap"><a href="#MemorySwap" class="headerlink" title="MemorySwap"></a>MemorySwap</h4><p><code>integer</code><br>总的内存使用量（内存 + swap），设置为<code>-1</code>则禁用 swap。如果创建容器时没有在命令行给出，则使用此配置项的值。</p><h4 id="CpuShares"><a href="#CpuShares" class="headerlink" title="CpuShares"></a>CpuShares</h4><p><code>integer</code><br>CPU份额（相对其它容器的权重）。如果创建容器时没有在命令行给出，则使用此配置项的值。</p><h4 id="ExposedPorts"><a href="#ExposedPorts" class="headerlink" title="ExposedPorts"></a>ExposedPorts</h4><p><code>struct</code><br>基于此镜像创建的容器公开的端口列表。此JSON结构的特殊之处在于它是由Go语言的<code>map[string]struct{}</code>结构直接序列化为JSON格式的，形式为每个键对应着 <strong>值为空对象{}</strong> 的JSON对象。如下面的例子所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;8080&quot;: &#123;&#125;,</span><br><span class="line">    &quot;53/udp&quot;: &#123;&#125;,</span><br><span class="line">    &quot;2356/tcp&quot;: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中的键可以是下面的格式：</p><ul><li><code>&quot;port/tcp&quot;</code></li><li><code>&quot;port/udp&quot;</code></li><li><code>&quot;port&quot;</code><br>如果没有给出协议，默认使用<code>tcp</code>协议。这是创建容器使用的默认值，可以与命令行提供的端口列表合并。</li></ul><h4 id="Env"><a href="#Env" class="headerlink" title="Env"></a>Env</h4><p><code>array of strings</code><br>Env的每项都是 <code>VARNAME=&quot;var value&quot;</code> 的格式。这是创建容器使用的默认值，可以与命令行提供的环境变量列表合并。</p><h4 id="Entrypoint"><a href="#Entrypoint" class="headerlink" title="Entrypoint"></a>Entrypoint</h4><p><code>array of strings</code><br>容器启动时执行的命令参数列表。这是创建容器使用的默认值，可以被命令行提供的入口命令替换。</p><h4 id="Cmd"><a href="#Cmd" class="headerlink" title="Cmd"></a>Cmd</h4><p><code>array of strings</code><br>容器启动时执行的命令参数列表（附加在<code>Entrypoint</code>之后）。这是创建容器使用的默认值，可以被命令行提供的入口命令替换。如果没有给出<code>Entrypoint</code>，那么<code>Cmd</code>列表的第一项将被认为是可执行的程序名。</p><h4 id="Healthcheck"><a href="#Healthcheck" class="headerlink" title="Healthcheck"></a>Healthcheck</h4><p><code>struct</code><br>用以检查容器是否正常的测试命令，如下面的例子所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;Test&quot;: [</span><br><span class="line">      &quot;CMD-SHELL&quot;,</span><br><span class="line">      &quot;/usr/bin/check-health localhost&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;Interval&quot;: 30000000000,</span><br><span class="line">  &quot;Timeout&quot;:  10000000000,</span><br><span class="line">  &quot;Retries&quot;:  3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>此结构有如下字段，</p><h5 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h5><p><code>array of strings</code><br>用以检查容器是否正常的测试命令，可以是</p><ul><li><code>[]</code> : 继承父镜像的健康检查命令；</li><li><code>[&quot;NONE&quot;]</code> : 禁用健康检查；</li><li><code>[&quot;CMD&quot;, arg1, arg2, ...]</code> : 直接执行命令和参数；</li><li><code>[&quot;CMD-SHELL&quot;, command]</code> : 使用系统默认shell执行命令；</li></ul><p>如果容器状态正常，测试命令退出后应返回 <code>0</code>，否则返回 <code>1</code>。</p><ul><li>Interval <code>integer</code>：相邻两次尝试的间隔，单位为纳秒；</li><li>Timeout <code>integer</code>：认为异常的超时间隔，单位为纳秒；</li><li>Retries <code>integer</code>：认为异常的重试次数。</li></ul><p>任何缺失的值都会从基础镜像继承。这是创建容器使用的默认值，可以与命令行提供的值合并（替代？）。</p><h5 id="Volumes"><a href="#Volumes" class="headerlink" title="Volumes"></a>Volumes</h5><p><code>struct</code><br>创建容器时作为数据卷的一组目录。此JSON结构的特殊之处在于它是由Go语言的<code>map[string]struct{}</code>结构直接序列化为JSON格式的，形式为每个键对应着 <strong>值为空对象{}</strong> 的JSON对象。如下面的例子所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;/var/my-app-data/&quot;: &#123;&#125;,</span><br><span class="line">    &quot;/etc/some-config.d/&quot;: &#123;&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h5 id="WorkingDir"><a href="#WorkingDir" class="headerlink" title="WorkingDir"></a>WorkingDir</h5><p><code>string</code><br>容器入口程序的工作目录，这是创建容器使用的默认值，可以被命令行提供的值替代。</p><h5 id="rootfs"><a href="#rootfs" class="headerlink" title="rootfs"></a>rootfs</h5><p><code>struct</code><br>rootfs结构是镜像各层的<code>DiffID</code>列表，此结构使镜像的描述文件的散列与各层的散列（及内容）相对应。rootfs有两个字段:</p><ul><li><code>type</code>，其值一般为 <code>layers</code>.</li><li><code>diff_ids</code> 各层散列（<code>DiffID</code>）的数组，顺序为从最底层到最顶层。</li></ul><p>下面是 rootfs 的一个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&quot;rootfs&quot;: &#123;</span><br><span class="line">  &quot;diff_ids&quot;: [</span><br><span class="line">    &quot;sha256:c6f988f4874bb0add23a778f753c65efe992244e148a1d2ec2a8b664fb66bbd1&quot;,</span><br><span class="line">    &quot;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef&quot;,</span><br><span class="line">    &quot;sha256:13f53e08df5a220ab6d13c58b2bf83a59cbdc2e04d0a3f041ddf4b0ba4112d49&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;type&quot;: &quot;layers&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="history"><a href="#history" class="headerlink" title="history"></a>history</h3><p><code>struct</code><br><code>history</code>结构是描述每层历史的一组对象，顺序为从最底层到最顶层。每个对象有以下字段。</p><ul><li><code>created</code>: 创建的日期和时间，<a href="https://zh.wikipedia.org/wiki/ISO_8601" target="_blank" rel="noopener">ISO-8601格式</a>；</li><li><code>author</code>: 创建的作者；</li><li><code>created_by</code>: 创建该层的命令；</li><li><code>comment</code>: 创建该层的注释；</li><li><code>empty_layer</code>: 标识此项历史记录是否会创建一个文件变更集。如果值为<code>true</code>，则此项历史不会对应一个实际的文件集（如<code>ENV</code>命令就对层的文件没有影响）。<br>下面是 history 结构的一个例子：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&quot;history&quot;: [</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;created&quot;: &quot;2015-10-31T22:22:54.690851953Z&quot;,</span><br><span class="line">    &quot;created_by&quot;: &quot;/bin/sh -c #(nop) ADD file:a3bc1e842b69636f9df5256c49c5374fb4eef1e281fe3f282c65fb853ee171c5 in /&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;created&quot;: &quot;2015-10-31T22:22:55.613815829Z&quot;,</span><br><span class="line">    &quot;created_by&quot;: &quot;/bin/sh -c #(nop) CMD [\&quot;sh\&quot;]&quot;,</span><br><span class="line">    &quot;empty_layer&quot;: true</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></li></ul><p>镜像的JSON文件中任何额外的字段应被认为是特定于实现的，如果无法处理，应该将其忽略。</p><h2 id="创建镜像文件变更集"><a href="#创建镜像文件变更集" class="headerlink" title="创建镜像文件变更集"></a>创建镜像文件变更集</h2><p>创建镜像文件变更集的例子如下：<br>首先，镜像的基础文件是一个空的目录，使用了随机生成的目录名<code>c3167915dc9d</code>（层的DiffID是基于目录内的文件内容生成的）。</p><p>然后在其中创建文件和目录:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">c3167915dc9d/</span><br><span class="line">    etc/</span><br><span class="line">        my-app-config</span><br><span class="line">    bin/</span><br><span class="line">        my-app-binary</span><br><span class="line">        my-app-tools</span><br></pre></td></tr></table></figure></p><p>将目录<code>c3167915dc9d</code>提交为一个 <code>tar</code> 包（无压缩），其中包含如下的文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">etc/my-app-config</span><br><span class="line">bin/my-app-binary</span><br><span class="line">bin/my-app-tools</span><br></pre></td></tr></table></figure><p>如果要在此基础上更改文件，则创建一个新的目录，假如为<code>f60c56784b83</code>，将其初始化为父镜像的快照，即与目录<code>c3167915dc9d</code>的内容相同。</p><blockquote><p>注意：支持 Copy-on-Write 或联合机制的文件系统创建快照很高效。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">f60c56784b83/</span><br><span class="line">    etc/</span><br><span class="line">        my-app-config</span><br><span class="line">    bin/</span><br><span class="line">        my-app-binary</span><br><span class="line">        my-app-tools</span><br></pre></td></tr></table></figure><p>然后添加一个配置目录<code>/etc/my-app.d</code>，其中包含默认的配置文件。可执行程序<code>my-app-tools</code>也更新了，以便处理新的配置文件路径。<br>修改后的目录<code>f60c56784b83</code>如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">f60c56784b83/</span><br><span class="line">    etc/</span><br><span class="line">        my-app.d/</span><br><span class="line">            default.cfg</span><br><span class="line">    bin/</span><br><span class="line">        my-app-binary</span><br><span class="line">        my-app-tools</span><br></pre></td></tr></table></figure></p><p>其中移除了<code>/etc/my-app-config</code>，然后创建了新的目录和文件<code>/etc/my-app.d/default.cfg</code>。<code>/bin/my-app-tools</code>也替换成新的版本。在将此目录提交为变更集之前，首先需要与其父镜像的快照<code>f60c56784b83</code>比较，找出增加、修改及删除的文件和目录。本例中找到如下的变更集：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">增加：  /etc/my-app.d/default.cfg</span><br><span class="line">修改：  /bin/my-app-tools</span><br><span class="line">删除：  /etc/my-app-config</span><br></pre></td></tr></table></figure></p><p>创建一个 <strong>仅包含</strong> 此变更集的tar包：增加和修改的文件内容及目录被完整地包含在tar包中；而删除的项则对应为相同路径的空文件，其文件名或目录名增加<code>.wh.</code>前缀（表示已删除）。</p><blockquote><p>注意：无法直接创建以名称<code>.wh.</code>开头的文件或目录。</p></blockquote><p>目录<code>f60c56784b83</code>生成的<code>tar</code> 包中有如下的文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/etc/my-app.d/default.cfg</span><br><span class="line">/bin/my-app-tools</span><br><span class="line">/etc/.wh.my-app-config</span><br></pre></td></tr></table></figure><p>任何镜像都是由若干类似的文件变更集的tar包组成的。</p><h2 id="镜像的组合格式"><a href="#镜像的组合格式" class="headerlink" title="镜像的组合格式"></a>镜像的组合格式</h2><p>包含镜像完整内容的单一tar包格式如下：</p><ul><li>镜像名：tag</li><li>镜像的 JSON 配置文件</li><li>各层的tar包</li></ul><p>如镜像<code>library/busybox</code>的组合tar包内容如下（使用<code>tree</code>命令输出）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── 47bcc53f74dc94b1920f0b34f6036096526296767650f223433fe65c35f149eb.json</span><br><span class="line">├── 5f29f704785248ddb9d06b90a11b5ea36c534865e9035e4022bb2e71d4ecbb9a</span><br><span class="line">│   ├── VERSION</span><br><span class="line">│   ├── json</span><br><span class="line">│   └── layer.tar</span><br><span class="line">├── a65da33792c5187473faa80fa3e1b975acba06712852d1dea860692ccddf3198</span><br><span class="line">│   ├── VERSION</span><br><span class="line">│   ├── json</span><br><span class="line">│   └── layer.tar</span><br><span class="line">├── manifest.json</span><br><span class="line">└── repositories</span><br></pre></td></tr></table></figure><p>镜像的每层都对应一个目录，其名称是64个十六进制的字符，是根据该层的文件内容确定性地生成的。</p><blockquote><p>注意：该目录名 <strong>不必</strong> 是层的<code>DiffID</code>或<code>ChainID</code>。</p></blockquote><p>每个目录包含3个文件：</p><ul><li><code>VERSION</code> - <code>json</code>文件模式的版本号；</li><li><code>json</code> - 旧的JSON格式镜像层元数据。v1.2版的镜像规范中，各层没有JSON元数据，但在v1版中是存在的。此文件是为了向后兼容v1版格式。</li><li><code>layer.tar</code> - 该层的tar包。</li></ul><p>注意：这个目录结构仅用于向后兼容。当前的实现使用<code>manifest.json</code>文件中列出的目录。</p><p><code>VERSION</code>文件只是JSON元数据模式的版本号：<code>1.0</code>。</p><p><code>repositories</code>也是一个JSON文件，包含镜像名和tag列表：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;  </span><br><span class="line">    &quot;busybox&quot;:&#123;  </span><br><span class="line">        &quot;latest&quot;:&quot;5f29f704785248ddb9d06b90a11b5ea36c534865e9035e4022bb2e71d4ecbb9a&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中有镜像的<code>repository</code>和一组tag列表。每个tag关联着镜像的 ID。该文件仅用于向后兼容。当前的实现使用<code>manifest.json</code>文件。</p><p><code>manifest.json</code>文件是顶层镜像的JSON配置。<br>该文件包含以下元数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;Config&quot;: &quot;47bcc53f74dc94b1920f0b34f6036096526296767650f223433fe65c35f149eb.json&quot;,</span><br><span class="line">    &quot;RepoTags&quot;: [&quot;busybox:latest&quot;],</span><br><span class="line">    &quot;Layers&quot;: [</span><br><span class="line">      &quot;a65da33792c5187473faa80fa3e1b975acba06712852d1dea860692ccddf3198/layer.tar&quot;,</span><br><span class="line">      &quot;5f29f704785248ddb9d06b90a11b5ea36c534865e9035e4022bb2e71d4ecbb9a/layer.tar&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p><p>上面这个JSON数组中，每项都对应着一个镜像。</p><ul><li><code>Config</code> 指向该镜像的JSON文件；</li><li><code>RepoTags</code> 是该镜像的名称；</li><li><code>Layers</code> 指向镜像各层的 tar 包；</li><li><code>Parent</code> 可选，指向其父镜像的 imageID，父镜像的ID必须在同一个 <code>manifest.json</code> 文件中存在。</li></ul><p>不要把 <code>manifest.json</code> 与用来push和pull镜像的分发清单（distribution manifest）相混淆。<br>一般来说，支持v1.2版本镜像规范的实现将使用<code>manifest.json</code>文件，早期的实现仍使用 <code>*/json</code>和<code>repositories</code>文件。</p><h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><p>其它相关文档：</p><ul><li><a href="https://github.com/opencontainers/image-spec" target="_blank" rel="noopener">Open Containers Initiative Image Spec</a></li><li><a href="https://github.com/docker/distribution/blob/master/docs/spec/manifest-v2-2.md" target="_blank" rel="noopener">Image Manifest Version 2, Schema 2</a></li><li><a href="https://github.com/docker/distribution/blob/master/docs/spec/api.md" target="_blank" rel="noopener">Docker Registry HTTP API V2</a></li><li><a href="https://github.com/apache/mesos/blob/master/docs/container-image.md" target="_blank" rel="noopener">Supporting Container Images in Mesos Containerizer</a></li></ul><h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><blockquote><p>注意：不要把上面的 <strong>镜像格式</strong> 与镜像的 <strong>主机存储布局</strong> 搞混了。</p><ul><li>镜像格式是执行<code>docker save &lt;镜像名或ID&gt;</code>之后得到的对应镜像<code>tar</code>包的格式。</li><li>镜像在主机的存储布局，以及镜像push和pull都 <strong>不会</strong> 用到打包成一个文件的镜像，因为这样不利于多个层并行加速下载和利用本地缓存的层。</li></ul><p>镜像的各层存在顺序依赖，而镜像也有父子继承关系。<br>最初Docker只支持AUFS存储驱动，但AUFS没有合并到Linux内核，虽然Ubuntu内置了AUFS，但RHEL/CentOS则需要添加对应的内核模块。目前Docker在RHEL/CentOS默认使用OverlayFS作为存储驱动。OverlayFS只支持上下两层，所以其主机存储布局与AUFS不同，但镜像格式不受影响。</p></blockquote><h2 id="alpine镜像的主机存储布局"><a href="#alpine镜像的主机存储布局" class="headerlink" title="alpine镜像的主机存储布局"></a>alpine镜像的主机存储布局</h2><p>alpine镜像仅有一个层，比较简单。Ubuntu使用AUFS存储驱动的文件布局如下。layer.tar包 已经被解开了。</p><ul><li>./aufs是解开layer.tar后的文件内容；</li><li>./aufs/mnt是容器文件系统的挂载点；</li><li>./containers是创建的容器的读写层；</li><li>./image/aufs/distribution中两个文件夹相当于正反查找的指针；</li><li>./image/aufs/imagedb/content/sha256/[id] 接近镜像的JSON描述文件，但与上面的v1.2规范不完全一致；</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"># tree /var/lib/docker</span><br><span class="line">/var/lib/docker</span><br><span class="line">├── aufs</span><br><span class="line">│   ├── diff</span><br><span class="line">│   │   └── 0b9c9a223af5f795049b86fc4f3dace61a44ced8a08a3cc8ccad0699eecec951</span><br><span class="line">│   │       ├── bin</span><br><span class="line">│   │       │   ├── ash -&gt; /bin/busybox</span><br><span class="line">│   │       │  # ... alpine镜像中的文件列表（大部分是指向/bin/busybox的软链接）</span><br><span class="line">│   ├── layers</span><br><span class="line">│   │   └── 0b9c9a223af5f795049b86fc4f3dace61a44ced8a08a3cc8ccad0699eecec951</span><br><span class="line">│   └── mnt</span><br><span class="line">│       └── 0b9c9a223af5f795049b86fc4f3dace61a44ced8a08a3cc8ccad0699eecec951</span><br><span class="line">├── containers</span><br><span class="line">├── image</span><br><span class="line">│   └── aufs</span><br><span class="line">│       ├── distribution</span><br><span class="line">│       │   ├── diffid-by-digest</span><br><span class="line">│       │   │   └── sha256</span><br><span class="line">│       │   │       └── cfc728c1c5584d8e0ae69368fc9c34d54d72651355573ba42554c2469a0a6299</span><br><span class="line">│       │   └── v2metadata-by-diffid</span><br><span class="line">│       │       └── sha256</span><br><span class="line">│       │           └── e154057080f406372ebecadc0bfb5ff8a7982a0d13823bab1be5b86926c6f860</span><br><span class="line">│       ├── imagedb</span><br><span class="line">│       │   ├── content</span><br><span class="line">│       │   │   └── sha256</span><br><span class="line">│       │   │       └── 02674b9cb179d57c68b526733adf38b458bd31ba0abff0c2bf5ceca5bad72cd9</span><br><span class="line">│       │   └── metadata</span><br><span class="line">│       │       └── sha256</span><br><span class="line">│       ├── layerdb</span><br><span class="line">│       │   ├── sha256</span><br><span class="line">│       │   │   └── e154057080f406372ebecadc0bfb5ff8a7982a0d13823bab1be5b86926c6f860</span><br><span class="line">│       │   │       ├── cache-id </span><br><span class="line">│       │   │       ├── diff</span><br><span class="line">│       │   │       ├── size</span><br><span class="line">│       │   │       └── tar-split.json.gz # 如果是中间层，此处会有 parent 文件</span><br><span class="line">│       │   └── tmp</span><br><span class="line">│       └── repositories.json</span><br><span class="line">├── network</span><br><span class="line">│   └── files</span><br><span class="line">│       └── local-kv.db</span><br><span class="line">├── plugins</span><br><span class="line">│   ├── storage</span><br><span class="line">│   │   └── blobs</span><br><span class="line">│   │       └── tmp</span><br><span class="line">│   └── tmp</span><br><span class="line">├── swarm</span><br><span class="line">├── tmp</span><br><span class="line">├── trust</span><br><span class="line">└── volumes</span><br><span class="line">    └── metadata.db</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文见 &lt;a href=&quot;https://github.com/moby/moby/blob/master/image/spec/v1.2.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/moby/moby/blob/master/image/spec/v1.2.md&lt;/a&gt;&lt;br&gt;Docker已经迁移到Moby项目了。&lt;/p&gt;
    
    </summary>
    
      <category term="yi" scheme="https://ying-zhang.github.io/categories/yi/"/>
    
    
  </entry>
  
  <entry>
    <title>CentOS 7 及 Ubuntu 16.04 设置 NAT 网络</title>
    <link href="https://ying-zhang.github.io/setup/2017/setup-nat-x-route/"/>
    <id>https://ying-zhang.github.io/setup/2017/setup-nat-x-route/</id>
    <published>2017-04-14T16:00:00.000Z</published>
    <updated>2018-06-03T15:10:23.086Z</updated>
    
    <content type="html"><![CDATA[<p>记录一下设置一台双网卡的CentOS服务器提供 NAT 转发，作为内网网关，其它服务器的默认网关更改为此节点，添加路由，以及处理外部ssh登录变慢的问题。</p><a id="more"></a><hr><p>小组有一个Dell的刀片服务器机柜，每台机器都是双网卡，分别连到了2个LAN。</p><ul><li>一个LAN是学校的公网IP（下文记为<code>2.2.2.0/24</code>网段）。装好CentOS 7系统后，<code>em1</code>网卡在公网LAN，可以在校内直接访问<code>em1</code>的IP，但由于学校网络管理限制，校外无法访问。所以说这个公网IP跟私网IP差不了多少。</li><li>另一个LAN是用于远程管理的机房内私网IP（下文记为<code>10.0.0.0/24</code>网段），<code>em2</code>网卡在这个私网LAN。服务器的iDRAC也在这个私网里。这个私网的网关是某个机器上的VPN服务提供的，IP是<code>10.0.0.1</code>。登录到这个VPN之后，就可以远程访问iDRAC，也可以通过私网IP ssh登录到机器。</li></ul><p>一直是远程管理，只去过一次机房，还不清楚服务器的具体组网拓扑。按理也可以修改一些设置，通过VPN的网关访问外网，不过没有VPN这台机器的管理权限，只好另外找机器设置NAT。</p><h1 id="CentOS-7-设置和使用NAT"><a href="#CentOS-7-设置和使用NAT" class="headerlink" title="CentOS 7 设置和使用NAT"></a>CentOS 7 设置和使用NAT</h1><p>学校的网络管理限制了刀片集群的网段不能通过登录个人外网帐号的方式连接外网，必须通过填表申请才能开通外网访问。现在只有一个<code>147</code>的公网IP（记对应的机器是<code>n147</code>）直通校外网。<br>之前是通过在<code>n147</code>上提供Squid HTTP代理服务的方式使其它机器能够访问外网，但代理用起来实在是不方便，所以改成NAT方式，这样其它机器将<code>n147</code>的私网IP作为网关，使用私网IP就可以访问外网了。在NAT模式下，<code>n147</code>就像一个软件实现的家用路由器。</p><h2 id="NAT网关的设置"><a href="#NAT网关的设置" class="headerlink" title="NAT网关的设置"></a>NAT网关的设置</h2><p>作为网关的机器名是<code>n147</code>，公网IP是<code>2.2.2.147/24</code>，对应<code>em1</code>网卡；私网IP是<code>10.0.0.147/24</code>，对应<code>em2</code>网卡。</p><h3 id="允许IP转发"><a href="#允许IP转发" class="headerlink" title="允许IP转发"></a>允许IP转发</h3><p>其它机器从<code>10.0.0.0/24</code>网段发送的数据包会被<code>em2</code>网卡接收，如果目标IP是外网，需要交给<code>em1</code>网卡发送出去。需要开启IP转发选项，才能允许不同网卡间转发数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 查看是否启用IP转发，如果是0则没有开启，是1则已经开启</span><br><span class="line">cat /proc/sys/net/ipv4/ip_forward</span><br><span class="line"></span><br><span class="line"># 可以修改上述文件的值来改变设置，但重启后会恢复默认值。</span><br><span class="line"># 需要将设置写入系统配置文件 /etc/sysctl.conf 或 /etc/sysctl.d/ip_forward.conf</span><br><span class="line"># 内容为</span><br><span class="line">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure></p><h3 id="设置iptables规则"><a href="#设置iptables规则" class="headerlink" title="设置iptables规则"></a>设置<code>iptables</code>规则</h3><p>安装必要软件并启用服务：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install -y net-tools iproute iptables iptables-services</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl enable iptables</span><br></pre></td></tr></table></figure></p><blockquote><p><code>net-tools</code>这个程序包有 <code>ifconfig</code>，<code>netstat</code>，<code>route</code>等命令，而<code>iproute2</code>（rpm包名为<code>iproute</code>）包括<code>tc</code>，<code>ip</code>，<code>ss</code>等命令，是<code>net-tools</code>的改进。</p></blockquote><p>通过<code>iptables</code>命令行可以添加NAT规则，但重启后也是会恢复默认值，应当将修改后的规则设置用<code>iptables-save</code>命令输出，然后保存起来。<br>这里直接使用<code>iptables-save</code>生成的配置项，保存到配置文件 <code>/etc/sysconfig/iptables</code>，内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># Generated by iptables-save v1.4.21 on Thu Apr 20 22:14:39 2017</span><br><span class="line">*nat</span><br><span class="line">:PREROUTING ACCEPT [0:0]</span><br><span class="line">:INPUT ACCEPT [0:0]</span><br><span class="line">:OUTPUT ACCEPT [0:0]</span><br><span class="line">:POSTROUTING ACCEPT [0:0]</span><br><span class="line">-A POSTROUTING -o em1 -j MASQUERADE  </span><br><span class="line">COMMIT</span><br><span class="line"></span><br><span class="line">*filter</span><br><span class="line">:INPUT ACCEPT [0:0]</span><br><span class="line">:FORWARD ACCEPT [0:0]</span><br><span class="line">:OUTPUT ACCEPT [0:0]</span><br><span class="line">-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br><span class="line">-A INPUT -p icmp -j ACCEPT</span><br><span class="line">-A INPUT -i lo -j ACCEPT</span><br><span class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT</span><br><span class="line">-A FORWARD -i em2 -j ACCEPT</span><br><span class="line">COMMIT</span><br></pre></td></tr></table></figure></p><p>其中涉及NAT转发的是<code>-A POSTROUTING -o em1 -j MASQUERADE</code> 和 <code>-A FORWARD -i em2 -j ACCEPT</code>。<br>此外还删除了原来禁止<code>ping</code>的规则：<br><code>-A INPUT -j REJECT --reject-with icmp-host-prohibited</code><br><code>-A FORWARD -j REJECT --reject-with icmp-host-prohibited</code></p><p>重启<code>iptables</code>服务<code>systemctl restart iptables</code>。</p><blockquote><p>可以修改<code>/etc/sysconfig/iptables-config</code> 配置文件，设置下面三个选项均为<code>yes</code>来自动保存<code>iptables</code>规则</p><ul><li><code>IPTABLES_MODULES_UNLOAD=&quot;yes&quot;</code></li><li><code>IPTABLES_SAVE_ON_STOP=&quot;yes&quot;</code></li><li><code>IPTABLES_SAVE_ON_RESTART=&quot;yes&quot;</code></li></ul><p>参考</p><ul><li><a href="http://salogs.com/news/2015/08/20/iptables-save/" target="_blank" rel="noopener">保存iptable规则并开机自动加载</a></li><li><a href="http://blog.csdn.net/hepeng597/article/details/8270138" target="_blank" rel="noopener">iptables用法初解</a></li></ul></blockquote><h2 id="设置其它-CentOS-7-机器使用NAT网络"><a href="#设置其它-CentOS-7-机器使用NAT网络" class="headerlink" title="设置其它 CentOS 7 机器使用NAT网络"></a>设置其它 CentOS 7 机器使用NAT网络</h2><h3 id="切换默认网关"><a href="#切换默认网关" class="headerlink" title="切换默认网关"></a>切换默认网关</h3><p>安装系统后，默认网关是<code>em1</code>所在LAN的<code>2.2.2.1</code>，需要将其更改为<code>em2</code>所在LAN的<code>10.0.0.147</code>，修改如下的网卡配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># /etc/sysconfig/network-scripts/ifcfg-em1</span><br><span class="line">DEFROUTE=no</span><br><span class="line"></span><br><span class="line"># /etc/sysconfig/network-scripts/ifcfg-em2</span><br><span class="line">DEFROUTE=yes</span><br><span class="line"># ...</span><br><span class="line">GATEWAY=10.0.0.147</span><br><span class="line">DNS1=233.5.5.5</span><br><span class="line">DNS2=223.6.6.6</span><br></pre></td></tr></table></figure></p><p>其中<code>em2</code>的网关即刚才配置的<code>n147</code>的私网IP，由于没有在<code>n147</code>上运行DNS服务，这里使用的是阿里的DNS。也可以安装配置<code>dnsmasq</code>等DNS服务器。</p><h3 id="为em1添加静态路由"><a href="#为em1添加静态路由" class="headerlink" title="为em1添加静态路由"></a>为<code>em1</code>添加静态路由</h3><p>修改默认网关后，查看路由表，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># route -n</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         10.0.0.147      0.0.0.0         UG    100    0        0 em2</span><br><span class="line">10.0.0.0        0.0.0.0         255.255.0.0     U     100    0        0 em2</span><br><span class="line">2.2.2.0         0.0.0.0         255.255.255.0   U     100    0        0 em1</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br></pre></td></tr></table></figure></p><p>发现从<code>em1</code>收发的数据包也要经过默认网关<code>10.0.0.147</code>，而这个网关在机房的私网内，<strong>外部不能直接访问，导致外部无法公网IP访问服务器</strong>。为此，需要为<code>em1</code>添加静态路由，不走<code>10.0.0.147</code>，新建文件<code>/etc/sysconfig/network-scripts/route-em1</code>，内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2.2.0.0/16    via 2.2.2.1</span><br><span class="line">172.0.0.0/8   via 2.2.2.1</span><br></pre></td></tr></table></figure></p><p>其中</p><ul><li><code>2.2.0.0/16</code>网段是学校 <strong>有线</strong> 网络的IP网段</li><li><code>172.0.0.0/8</code>网段是学校 <strong>无线</strong> 网络的IP网段。<blockquote><p>注意</p></blockquote></li><li><code>docker0</code>网桥默认也是B类私网的<code>172.x.0.0/16</code>网段，但其路由项更具体，所以<a href="http://answ.me/post/configure-docker-subnet/" target="_blank" rel="noopener">不会造成冲突</a>。</li><li><code>docker0</code>网桥实际也工作在NAT模式，也需要开启IP转发。</li></ul><p>重启网络，更新配置，<code>systemctl restart network</code>。</p><blockquote><p>参考：<a href="https://www.thomas-krenn.com/en/wiki/Two_Default_Gateways_on_One_System" target="_blank" rel="noopener">Two Default Gateways on One System</a></p></blockquote><h1 id="Ubuntu-16-04-设置和使用NAT"><a href="#Ubuntu-16-04-设置和使用NAT" class="headerlink" title="Ubuntu 16.04 设置和使用NAT"></a>Ubuntu 16.04 设置和使用NAT</h1><p>Ubuntu 16.04 参考上面 CentOS 7 设置和使用NAT的步骤即可————怎么可能！<br>因为用到的工具都是<code>net-tools</code>，<code>iproute</code>和<code>iptables</code>这3个包里的，配置文件的内容是一样的，但配置文件的路径和启动方式就不一样了。</p><h2 id="设置NAT"><a href="#设置NAT" class="headerlink" title="设置NAT"></a>设置NAT</h2><h3 id="允许IP转发-1"><a href="#允许IP转发-1" class="headerlink" title="允许IP转发"></a>允许IP转发</h3><p>直接修改系统配置文件 <code>/etc/sysctl.conf</code>，里面已经有支持的配置项，取消<code>net.ipv4.ip_forward = 1</code>的注释即可。</p><h3 id="设置iptables规则-1"><a href="#设置iptables规则-1" class="headerlink" title="设置iptables规则"></a>设置iptables规则</h3><p>还是使用的<code>iptables</code>，为了使修改后的规则能够保存，规则跟上面CentOS的基本一样。为什么说是基本呢？网卡的默认名字改了： CentOS 7下是<code>em1</code>，<code>em2</code>，Ubuntu 16.04下是<code>eno1</code>，<code>eno2</code>，所以要把规则中对应的网卡名改过来。</p><p>然后要找到Ubuntu 16.04下系统会自动读取的iptables规则文件路径，参考<a href="https://help.ubuntu.com/community/IptablesHowTo" target="_blank" rel="noopener">IptablesHowTo - Ubuntu wiki</a>，，<strong>随便把规则保存到哪，反正系统不会自动加载</strong>，需要自己添加一个启动脚本。<br>因为机器是多网卡，启动脚本不好关联某个网卡，所以放在与网卡启动关联的脚本目录里，脚本文件是 <code>/etc/network/if-pre-up.d/iptablesload</code>，内容如下，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">iptables-restore &lt; /etc/iptables.rules</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure></p><p>可见<code>/etc/iptables.rules</code>是保存的<code>iptables</code>规则，这个位置是任意的，只要跟启动脚本中保持一致就行了。启动脚本的名字也是任意的，只要放在那个路径下就可以了。<strong>但是，你要自己来写这个脚本</strong>。</p><p>编辑好<code>/etc/iptables.rules</code> 和 <code>/etc/network/if-pre-up.d/iptablesload</code>之后，重启网络服务。</p><p>虽然都是用<code>systemd</code>来管理系统服务，但服务的名字又不一样了，CentOS的网络服务名称是<code>network.service</code>，而Ubuntu则是<code>networking.service</code>。<br>执行命令<code>sudo systemctl restart networking</code>，重启网络服务。不过，其实我们是用<code>iptables</code>来实现的NAT，而不是<code>networking.service</code>相关服务，不过由于上面的那个脚本<code>iptablesload</code>会在网卡启动之前被执行，所以顺便完成了我们的目标。</p><h2 id="设置其它机器使用NAT网络"><a href="#设置其它机器使用NAT网络" class="headerlink" title="设置其它机器使用NAT网络"></a>设置其它机器使用NAT网络</h2><p>同样，在其它Ubuntu机器上也要切换默认网关，为eno1添加静态路由。情况又不一样了，Ubuntu的所有网卡配置和静态路由都保存在<code>/etc/network/interface</code>这个文件里，这个倒是方便了—— <strong><a href="https://askubuntu.com/questions/168033/how-to-set-static-routes-in-ubuntu-server" target="_blank" rel="noopener">如果面对空空的配置文件，你能猜到各配置项是什么的时候</a></strong>。<br>好在安装系统的时候设置了网卡，给<code>eno2</code>生成了一些配置项可以参考。修改后的内容如下。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line"></span><br><span class="line">auto eno1</span><br><span class="line">iface eno1 inet static</span><br><span class="line">  address 2.2.2.140</span><br><span class="line">  netmask 255.255.255.0</span><br><span class="line">  network 2.2.2.0</span><br><span class="line">  broadcast 2.2.2.255</span><br><span class="line">  # gateway 2.2.2.1</span><br><span class="line">  up ip route add 2.2.0.0/16   via 2.2.2.1 || true</span><br><span class="line">  up ip route add 2.2.2.0/24   via 2.2.2.1 || true</span><br><span class="line">  up ip route add 172.0.0.0/8  via 2.2.2.1 || true</span><br><span class="line"></span><br><span class="line"># The primary network interface</span><br><span class="line">auto eno2</span><br><span class="line">iface eno2 inet static</span><br><span class="line">  address 10.0.0.140</span><br><span class="line">  netmask 255.255.255.0</span><br><span class="line">  network 10.0.0.0</span><br><span class="line">  broadcast 10.0.0.255</span><br><span class="line">  gateway 10.0.0.147</span><br><span class="line">  # dns-* options are implemented by the resolvconf package, if installed</span><br><span class="line">  dns-nameservers 233.5.5.5</span><br></pre></td></tr></table></figure></p><blockquote><p>注意</p><ul><li>不是像CentOS那样明确地在各网卡的配置文件中说明是否该网卡作为默认路由网关，而是哪个网卡写了<code>gateway</code>就以它作为默认网关，如果2个网卡都写了，只有最后写的那个有效，所以最好明确地只保留一个<code>gateway</code>项。</li><li><code>up ip route add 2.2.0.0/16   via 2.2.2.1 || true</code>其实也就是一句启动网卡后顺便执行的脚本，如果你愿意，这里写一句<code>up echo helloworld</code>也没问题。后面的<code>|| true</code>是让脚本执行时忽略可能的错误，继续执行。这里使用的是<code>ip</code>命令，如果使用<code>route</code>命令，效果也是一样的，前提是已经安装了<code>net-tools</code>或<code>iproute</code>软件包。使用<code>netmask</code>和<code>CIDR</code>格式都可以。</li><li>哪个网卡的路由就写到对应的网卡下，这样执行<code>ifup eno1</code>这样的单独启动某个网卡的命令也会自动执行相应的命令添加该网卡的路由。</li></ul></blockquote><p>执行命令<code>sudo systemctl restart networking</code>，重启网络服务。<br>查看一下更新后的路由表，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># route -n</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         10.0.0.147      0.0.0.0         UG    0      0        0 eno2</span><br><span class="line">10.0.0.0        0.0.0.0         255.255.255.0   U     0      0        0 eno2</span><br><span class="line">2.2.0.0         2.2.2.1         255.255.0.0     UG    0      0        0 eno1</span><br><span class="line">2.2.2.0         0.0.0.0         255.255.255.0   U     0      0        0 eno1</span><br><span class="line">172.0.0.0       2.2.2.1         255.0.0.0       UG    0      0        0 eno1</span><br></pre></td></tr></table></figure></p><p>注意倒数第二行：<code>2.2.2.0    0.0.0.0    255.255.255.0   U    0    0    0    eno1</code>，这个是自动添加的。<br>它的网关并不是<code>2.2.2.1</code>，即便在<code>interface</code>中强制器网关为<code>2.2.2.1</code>，也会被改为<code>0.0.0.0</code>。因为<code>2.2.2.0/24</code>是本LAN的数据包，经<code>ARP</code>协议获得目标的<code>MAC</code>地址后，会被直接发到目标地址，而不会经网关<code>2.2.2.1</code>转发，虽然路由表中默认网关是<code>0.0.0.0</code>，也不会按路由表转发到<code>10.0.0.147</code>。</p><h1 id="其它问题"><a href="#其它问题" class="headerlink" title="其它问题"></a>其它问题</h1><p>下面的问题是在除NAT网关外的其它机器上设置的。</p><h2 id="禁用各机器的SSHD-DNS选项，解决ssh登录很慢的问题"><a href="#禁用各机器的SSHD-DNS选项，解决ssh登录很慢的问题" class="headerlink" title="禁用各机器的SSHD DNS选项，解决ssh登录很慢的问题"></a>禁用各机器的SSHD DNS选项，解决ssh登录很慢的问题</h2><p>修改默认网关，添加路由之后，虽然可以从外部通过公网IP <code>ping</code>通机房内的机器，但<code>ssh</code>登录过程需要等待很长时间。<br>参考<a href="http://blog.itpub.net/7345798/viewspace-1055461/" target="_blank" rel="noopener">ssh连接的时候很慢，ping的速度非常好</a>这篇文章，修改各机器上<code>sshd</code>的选项如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -i &quot;&apos;s/.*UseDNS.*/UseDNS no/g&apos;&quot; /etc/ssh/sshd_config</span><br><span class="line">systemctl restart sshd</span><br></pre></td></tr></table></figure></p><h2 id="取消原来设置的http代理"><a href="#取消原来设置的http代理" class="headerlink" title="取消原来设置的http代理"></a>取消原来设置的http代理</h2><p>注释掉配置文件中<code>http_proxy</code>和<code>https_proxy</code>环境变量的声明，并执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">unset http_proxy</span><br><span class="line">unset https_proxy</span><br></pre></td></tr></table></figure></p><h1 id="PS-使用-SSH-隧道"><a href="#PS-使用-SSH-隧道" class="headerlink" title="PS: 使用 SSH 隧道"></a>PS: 使用 SSH 隧道</h1><p>一般可以通过服务器的公网IP在校内登录到机器上，有时把机器的配置搞乱了，需要连接到内网，使用iDRAC来管理机器，这时就要连接VPN了。其实也可以不连接VPN，而利用其它正常机器的SSH创建隧道，实现连接内网的目的。<br>以Windows客户端为例，安装了Windows版的<code>git</code>后，会附带一些<code>mingw</code>命令程序（不是完整的<code>mingw</code>），首先将这些命令的可执行文件所在路径添加到<code>Path</code>环境变量，比如是<code>E:\App\git\usr\bin;E:\App\git\mingw64\bin;E:\App\git\bin</code>，然后就可以在Windows命令行使用这些命令了。其中就有<code>ssh.exe</code>。<br>在Windows命令行窗口执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -NfD 1088 -i C:\Users\ying\.ssh\id_rsa root@n147</span><br></pre></td></tr></table></figure></p><p>这个命令执行成功后会退出，返回到命令提示符，但实际仍在后台监听本机的1088端口<code>127.0.0.1:1088</code>。<strong>如果需要停止SSH隧道，关闭该命令窗口即可</strong>。<br>因为我在Windows的<code>C:\Windows\System32\drivers\etc\hosts</code>文件中添加了<code>n147</code>的项，所以可以直接输入名字而不必是IP地址。</p><p>在IE或控制面板打开<code>Internet选项</code>，</p><ul><li>在<code>连接</code>选项卡单击<code>局域网设置</code>按钮，</li><li>在弹出的对话框勾选<code>为LAN使用代理服务器</code>，然后单击<code>高级</code>，</li><li>在弹出的对话框取消勾选<code>对所有协议使用相同的代理服务器</code>，然后在<code>套接字</code>对应的文本框填入<code>127.0.0.1</code>和上面命令中监听的端口号<code>1088</code>，</li><li>在<code>例外</code>文本框中删掉<code>10.*0;</code>的内容，然后一路确定关闭所有对话框。<br>这时应该可以用IE或Chrome访问机房内网的iDRAC。<strong>如果需要正常访问网页，需要取消勾选<code>为LAN使用代理服务器</code></strong>。</li></ul><p><img src="/img/sock5-proxy.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录一下设置一台双网卡的CentOS服务器提供 NAT 转发，作为内网网关，其它服务器的默认网关更改为此节点，添加路由，以及处理外部ssh登录变慢的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="setup" scheme="https://ying-zhang.github.io/categories/setup/"/>
    
    
  </entry>
  
  <entry>
    <title>设置及使用HTTP代理</title>
    <link href="https://ying-zhang.github.io/setup/2017/setup-proxy/"/>
    <id>https://ying-zhang.github.io/setup/2017/setup-proxy/</id>
    <published>2017-04-13T16:00:00.000Z</published>
    <updated>2018-06-03T15:10:50.257Z</updated>
    
    <content type="html"><![CDATA[<p>记录一下设置Squid作为HTTP代理，及docker、yum、apt等的代理配置。</p><p>TODO: socks 5代理</p><a id="more"></a><hr><h1 id="使用Squid提供HTTP代理"><a href="#使用Squid提供HTTP代理" class="headerlink" title="使用Squid提供HTTP代理"></a>使用Squid提供HTTP代理</h1><h2 id="主机上安装和设置Squid"><a href="#主机上安装和设置Squid" class="headerlink" title="主机上安装和设置Squid"></a>主机上安装和设置Squid</h2><p>作为网关的<code>n147</code>机器，公网IP是<code>2.2.2.147</code>。安装Squid，然后修改配置，启用服务。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yum install -y squid # CentOS</span><br><span class="line">apt install -y squid # Ubuntu</span><br><span class="line">apk add squid     # Alpine</span><br><span class="line"></span><br><span class="line"># squid的配置文件在 /etc/squid/squid.conf，修改内容可参考下面的 Dockerfile</span><br><span class="line"></span><br><span class="line"># 修改配置后，初始化squid的工作目录</span><br><span class="line">squid -z</span><br><span class="line"></span><br><span class="line"># 启动服务</span><br><span class="line">systemctl enable squid</span><br><span class="line">systemctl start  squid</span><br></pre></td></tr></table></figure></p><h2 id="以Docker容器的方式运行Squid"><a href="#以Docker容器的方式运行Squid" class="headerlink" title="以Docker容器的方式运行Squid"></a>以Docker容器的方式运行Squid</h2><p>Dockerfile内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:latest</span><br><span class="line"></span><br><span class="line">RUN apk update --no-cache; \</span><br><span class="line">    apk add squid --no-cache</span><br><span class="line"></span><br><span class="line"># 可以在squid.conf中限制允许访问此代理的IP范围，否则只有内网IP可以访问</span><br><span class="line">RUN sed  -i &quot;/RFC 4291/a acl ics src 2.2.2.0/24&quot; squid.conf; \</span><br><span class="line">    sed  -i &quot;/RFC 4291/a acl ics src 2.2.3.3/32&quot; squid.conf</span><br><span class="line"></span><br><span class="line"># 可以修改默认的端口号，如果修改了默认端口，需要修改下面的 EXPOSE 部分</span><br><span class="line">RUN sed -i &quot;/http_port/c http_port 8888&quot; squid.conf</span><br><span class="line"></span><br><span class="line"># 开启cache</span><br><span class="line">RUN sed -i &apos;/cache_dir/s/#//g&apos; /etc/squid/squid.conf</span><br><span class="line"></span><br><span class="line"># 或者直接使用修改过的配置文件</span><br><span class="line"># ADD squid.conf /etc/squid/squid.conf</span><br><span class="line"></span><br><span class="line"># squid -z用于初始化，创建cache目录，但直接在Dockerfile中</span><br><span class="line"># RUN squid -z</span><br><span class="line"># 却无法创建cache目录，导致squid无法启动</span><br><span class="line"># 故将初始化和启动命令写入脚本中</span><br><span class="line"></span><br><span class="line">RUN echo -e &apos;#!/bin/sh\n[ -d /var/cache/squid/00 ] || squid -z\nsquid -N&apos; &gt;/squid.sh; \</span><br><span class="line">    chmod +x /squid.sh</span><br><span class="line"></span><br><span class="line">EXPOSE 3128</span><br><span class="line">CMD [&quot;/squid.sh&quot;]</span><br></pre></td></tr></table></figure></p><p>构造镜像：<code>docker build ./ -t squid:latest</code><br>启动容器：<code>docker run -d -p 3128:3128 --name squid squid:latest</code></p><h1 id="使用HTTP代理"><a href="#使用HTTP代理" class="headerlink" title="使用HTTP代理"></a>使用HTTP代理</h1><p>内网其它不能直接访问外网的机器可以设置使用<code>n147</code>提供的代理服务。</p><h2 id="全局的环境变量"><a href="#全局的环境变量" class="headerlink" title="全局的环境变量"></a>全局的环境变量</h2><p>在<code>/etc/environment</code>（不需要<code>export</code>），<code>/etc/profile</code>或<code>/etc/profile.d/http_proxy.sh</code>导出<code>http_proxy</code>和<code>https_proxy</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export http_proxy=http://2.2.2.147:3128</span><br><span class="line">export https_proxy=http://2.2.2.147:3128</span><br></pre></td></tr></table></figure></p><p><code>squid</code>可以作为https代理，只要设置 <code>https_proxy=http://2.2.2.147:3128</code>， 即这个环境变量以<code>http://</code>开头。</p><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><p>Docker需要<a href="https://docs.docker.com/engine/admin/systemd/" target="_blank" rel="noopener">单独设置代理</a>，新建文件<code>/etc/systemd/system/docker.service.d/http-proxy.conf</code>，内容如下（注意多项环境变量之间要有空格，还设置了对私有镜像仓库不使用代理）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">Environment=&quot;HTTP_PROXY=http://2.2.2.147:3128&quot; &quot;HTTPS_PROXY=http://2.2.2.147:3128&quot;  &quot;NO_PROXY=localhost,10.0.0.147&quot;</span><br></pre></td></tr></table></figure></p><p>重启docker daemon： <code>systemctl restart docker</code>，执行<code>docker info</code>查看是否生效。</p><h2 id="yum"><a href="#yum" class="headerlink" title="yum"></a>yum</h2><p>yum 会使用全局代理设置，也可以单独设置代理，在<code>/etc/yum.conf</code>中增加：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proxy=http://2.2.2.147:3128</span><br></pre></td></tr></table></figure></p><h2 id="apt"><a href="#apt" class="headerlink" title="apt"></a>apt</h2><p>在文件<code>/etc/apt/apt.conf</code>中增加：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Acquire::http::proxy  &quot;http://2.2.2.147:3128&quot;;</span><br><span class="line">Acquire::https::proxy &quot;http://2.2.2.147:3128&quot;;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录一下设置Squid作为HTTP代理，及docker、yum、apt等的代理配置。&lt;/p&gt;
&lt;p&gt;TODO: socks 5代理&lt;/p&gt;
    
    </summary>
    
      <category term="setup" scheme="https://ying-zhang.github.io/categories/setup/"/>
    
    
  </entry>
  
  <entry>
    <title>【译文】Spanner, TrueTime 和CAP理论</title>
    <link href="https://ying-zhang.github.io/yi/2017/x-spanner-truetime-cap/"/>
    <id>https://ying-zhang.github.io/yi/2017/x-spanner-truetime-cap/</id>
    <published>2017-03-05T16:00:00.000Z</published>
    <updated>2018-06-03T15:14:19.566Z</updated>
    
    <content type="html"><![CDATA[<p>作者：<a href="https://en.wikipedia.org/wiki/Eric_Brewer_%28scientist%29" target="_blank" rel="noopener">Eric Brewer，VP, Infrastructure, Google</a><br>2017-02-14<br>英文原文：<a href="https://research.google.com/pubs/pub45855.html" target="_blank" rel="noopener">Spanner, TrueTime and the CAP Theorem</a> ,<a href="https://research.google.com/pubs/archive/45855.pdf" target="_blank" rel="noopener">英文全文 PDF</a><br><a href="/doc/Spanner-TrueTime-CAP.pdf">译文全文PDF</a></p><p>2018-06更新：推荐阅读《设计数据密集型应用（Designing Data-Intensive Applications）》第9章</p><a id="more"></a><hr><h1 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h1><p><a href="https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86" target="_blank" rel="noopener">CAP定理</a>是分布式系统中一个“著名”的结论，它又被称为布鲁尔定理（Brewer’s theorem，看看上面的本文作者是谁？）。CAP定理说的是一种不可能性，可能让人联想到另一个类似的不可能定理 “<a href="https://zh.wikipedia.org/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86" target="_blank" rel="noopener">哥德尔不完备性定理</a>”。CAP定理可能是互联网公司在面试时用来区分科班和半路出家程序员的必考题了。<br>实际上 <strong>这个定理的重要性被高估了</strong>。注意到 <strong>就是本文的作者（Eric Brewer）提出了CAP定理</strong>，而他还在2012年发表了一篇文章 “<a href="http://www.infoq.com/cn/articles/cap-twelve-years-later-how-the-rules-have-changed" target="_blank" rel="noopener">CAP理论十二年回顾：”规则”变了</a>” 的文章，再加上这篇 <strong>借Spanner来讨论CAP定理</strong> 的文章，实际上是委婉地承认了这一点。</p><p>CAP定理说这3个字母最多只能同时实现2个字母的组合，但这3个字母并非同一层次的概念：A（可用性）和C（一致性）是数据副本的属性，但P（容忍网络分区）反映的是物理世界网络的状态。<br><strong>网络总是可能会断的</strong>。为实现A，需要客户端到服务器之间的网络正常，为实现C，需要服务器之间的网络正常。如果网络一切正常，那么AC能同时实现，CAP定理 <strong>在正常情况下并没有什么作用</strong>。如果网络中断，AC或者有1个无法实现，或者2个都无法实现，好吧，等着挨老板的骂吧（一个更好的办法是 <strong>准备预案</strong>，可能是 <strong>技术上的</strong>，也可能是 <strong>公关</strong> 预案）。 <strong>AC</strong> 不可能同时实现，是物理世界本身的限制。 下面的文章中认为Google的网络可靠性是足够高的，所以他们认为同时实现了CAP。<br>CAP只是一个定性的理论，讨论的情况或者是0， 或者是100%。首先，工程上的事没有什么能100%，比如系统可用性，可以说99.99%，99.999%，但没有一个工程师拍胸脯说能达到100%；其次，这3个字母都是可以更细致地量化的（C的量化比较复杂）：</p><ul><li>对于P，如果一台机器与集群失联了，一般不会认为发生了网络分区，分布式集群的管理系统应该能够容忍这个故障，继续正常运行；那么2台机器呢，n台机器呢？恰好 1：1的分裂为2个分区只是无数可能中的一种，其概率是 0 （$ 1/\infty $）。到何种程度才认为处于网络分区状态呢？</li><li>对于A，就是常说的“n个9”了，通过可用时间可以准确地测量。如果一个系统不可用会怎样？ <strong>12306.cn</strong> 网站每天23:00~06:00停止购票服务，好像也没有造成多大的不便嘛。</li><li>对于C，一致性的量化比较复杂，从Linearisability，Atomicity/Strong Consistency，到Eventually Consistency，有多种不同程度的一致性。对于最终一致性（Eventually Consistency），而言，多久算是 “最终” 也是需要量化的。关于量化这一点，在“<a href="http://www.infoq.com/cn/articles/cap-twelve-years-later-how-the-rules-have-changed" target="_blank" rel="noopener">CAP理论十二年回顾：”规则”变了</a>” 这篇文章中也有讨论。</li></ul><h2 id="CAP定理和一致性相关文章"><a href="#CAP定理和一致性相关文章" class="headerlink" title="CAP定理和一致性相关文章"></a>CAP定理和一致性相关文章</h2><p>Blog</p><ul><li><a href="http://www.yunweipai.com/archives/8432.html" target="_blank" rel="noopener">不懂点CAP理论，你好意思说你是做分布式的吗？</a></li><li><a href="https://codahale.com/you-cant-sacrifice-partition-tolerance/" target="_blank" rel="noopener">You Can’t Sacrifice Partition Tolerance</a></li><li><a href="http://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html" target="_blank" rel="noopener">Please stop calling databases CP or AP</a></li><li><a href="https://github.com/aphyr/partitions-post" target="_blank" rel="noopener">关于网络分区的一篇blog</a></li></ul><p>Paper</p><ul><li><a href="http://queue.acm.org/detail.cfm?id=2462076" target="_blank" rel="noopener">Eventual Consistency Today - Limitations, Extensions,and Beyond - CACM1305</a></li><li><a href="https://www.microsoft.com/en-us/research/publication/replicated-data-consistency-explained-through-baseball/" target="_blank" rel="noopener">Replicated Data Consistency Explained Through Baseball - CACM1312</a>，译文<a href="/doc/CACM1312_Replicated_Data_Consistency_Explained_Through_Baseball.pdf">以棒球赛为例解释复制数据的一致性问题</a></li><li><a href="www.bailis.org/papers/pbs-vldbj2014.pd">Quantifying Eventual Consistency with PBS - CACM1408</a>，译文<a href="/doc/CACM1408_Quantifying_Eventual_Consistency_with_PBS.pdf">利用PBS 量化最终一致性</a>；作者<a href="http://www.bailis.org/" target="_blank" rel="noopener">Peter Bailis</a>也是一位大牛。</li><li><a href="http://cs.nju.edu.cn/yuhuang/huangyufiles/papers/2017-pa2a-tc.pdf" target="_blank" rel="noopener">Probabilistically-Atomic 2-Atomicity: Enabling Almost Strong Consistency in Distributed Storage Systems</a>， <a href="http://ieeexplore.ieee.org/document/7547362/" target="_blank" rel="noopener">IEEE Xplore上的版本</a></li><li><a href="https://www.ksp.kit.edu/9783731501862" target="_blank" rel="noopener">PhD14 - Benchmarking Eventually Consistent Distributed Storage System - David Bermbach</a></li><li><a href="http://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6155638" target="_blank" rel="noopener">IEEE Computer - ( Vol. 45 Issue 2 ) The CAP Theorem’s Growing Impact</a></li><li><a href="https://arxiv.org/abs/1509.05393" target="_blank" rel="noopener">A Critique of the CAP Theorem</a><blockquote><p>The CAP Theorem is a frequently cited impossibility result in distributed systems, especially among NoSQL distributed databases. In this paper we survey some of the confusion about the meaning of CAP, including inconsistencies and ambiguities in its definitions, and we highlight some problems in its formalization. CAP is often interpreted as proof that eventually consistent databases have better availability properties than strongly consistent databases; although there is some truth in this, we show that more careful reasoning is required. These problems cast doubt on the utility of CAP as a tool for reasoning about trade-offs in practical systems. As alternative to CAP, we propose a “delay-sensitivity” framework, which analyzes the sensitivity of operation latency to network delay, and which may help practitioners reason about the trade-offs between consistency guarantees and tolerance of network faults.</p></blockquote></li></ul><h2 id="关于物理时间"><a href="#关于物理时间" class="headerlink" title="关于物理时间"></a>关于物理时间</h2><ul><li><a href="http://dl.acm.org/citation.cfm?id=2347750" target="_blank" rel="noopener">Toward higher precision - PTP协议 - CACM-2012-10</a></li><li><a href="https://spectracom.com/sites/default/files/document-files/Time%20for%20Datacenters%20to%20Consider%20Time%20as%20a%20Service_WP12-101_A.pdf" target="_blank" rel="noopener">Time for Data Centers to Consider Time as a Service</a></li><li><a href="https://en.wikipedia.org/wiki/Global_Positioning_System" target="_blank" rel="noopener">GPS - Global Positioning System - wiki</a></li><li><p><a href="http://www.beidou.gov.cn/attach/beidou/China&#39;s%20BeiDou%20Navigation%20Satellite%20System%28Chinese%29.pdf" target="_blank" rel="noopener">中国北斗卫星导航系统白皮书</a></p><blockquote><p>正在运行的北斗二号系统发播B1I和B2I公开服务信号，免费向亚太地区提供公开服务。服务区为南北纬55度、东经55度到180度区域，定位精度优于10米，测速精度优于0.2米/秒，<strong>授时精度优于50纳秒</strong>。</p></blockquote></li><li><p><a href="http://www.ucolick.org/~sla/leapsecs/timescales.html" target="_blank" rel="noopener">Time Scales</a></p></li><li><a href="http://gjss.ndrc.gov.cn/gzdtx/201309/t20130926_683874.html" target="_blank" rel="noopener">长短波授时系统</a></li></ul><p>如果在万能的淘宝上搜“时钟同步服务器，GPS，北斗”，就会看到很多产品，价格不比一台服务器贵。比如下面的链接（免费的广告啊~~）<br>高精度的时间同步是一个系统工程。即便是局域网的范围，不是简单买一台NTP服务器，然后接到网络里就算完工了。当然，还是要看精度要求有多高，NTP的精度还是比较低的。<br>通过网络同步时间的问题在于计算机网络（以太网）尽力而为和多层协议带来的 <strong>固有的通信延迟不确定性</strong>。延迟大并不可怕，只要是稳定的延迟，就可以预先扣除，但延迟的不确定性就很难处理了。可能的方案是使用专用，没有任何协议的物理线路，就跟电力线路一样，延迟几乎没有波动。</p><ul><li><a href="http://www.syn029.com/h-index.html" target="_blank" rel="noopener">西安同步电子科技有限公司</a>，<a href="https://shop102437782.taobao.com/index.htm" target="_blank" rel="noopener">他们的淘宝店</a></li><li><a href="http://www.jingtech.cn/col.jsp?id=130" target="_blank" rel="noopener">西安景驰电子科技有限公司</a>，<a href="https://zhuanlan.zhihu.com/p/21596625" target="_blank" rel="noopener">TS3200 系列GPS/BD 同步时钟 - 知乎专栏</a></li><li><a href="http://www.bonzn.cn/col.jsp?id=105" target="_blank" rel="noopener">广州邦正电力科技有限公司</a>，</li></ul><p>为什么2家都是西安的？不一定是巧合，很可能是因为中国科学院国家授时中心就在西安临潼。<br>只说GPS/北斗芯片的话，其实只有几十块钱，不但智能手机必备，现在比较流行的共享单车都装了这些定位芯片。当然，从一个GPS芯片到一个时钟同步服务器产品还是要有很多外围设备的，作为外行，就不深入讨论了。</p><h2 id="Cloud-Spanner的相关报道"><a href="#Cloud-Spanner的相关报道" class="headerlink" title="Cloud Spanner的相关报道"></a>Cloud Spanner的相关报道</h2><p><a href="http://www.infoq.com/cn/news/2017/02/Google-Cloud-Spanner-hit-CAP" target="_blank" rel="noopener">Infoq - 谷歌新发布的分布式数据库服务，是要打破CAP定理了吗？</a><br><a href="http://www.infoq.com/cn/news/2017/03/google-cloud-spanner-beta" target="_blank" rel="noopener">Infoq - 谷歌对外发布了云Spanner Beta版</a></p><h2 id="分布式系统课程"><a href="#分布式系统课程" class="headerlink" title="分布式系统课程"></a>分布式系统课程</h2><ul><li><a href="https://courses.cs.washington.edu/courses/cse552/13au/calendar/lecturelist.html" target="_blank" rel="noopener">Washington Univ. CSE552: Distributed and Parallel Systems - Fall 2013</a></li><li><a href="http://nil.csail.mit.edu/6.824/2016/schedule.html" target="_blank" rel="noopener">MIT 6.824: Distributed Systems - Spring 2016</a></li><li><a href="http://www.bigoh.net/wiki/index.php/Dis-alg" target="_blank" rel="noopener">分布式算法入门</a></li><li><a href="https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/" target="_blank" rel="noopener">Notes on Distributed Systems for Young Bloods</a></li></ul><hr><h1 id="译文"><a href="#译文" class="headerlink" title="译文"></a>译文</h1><p>Spanner是Google的高可用的全球SQL数据库[CDE + 12：Spanner]。它管理着大规模的复制的数据。大规模既指数据量方面，又有事务量方面。它为写入其中的每项数据分配全局一致的实时时间戳，客户端可以在整个数据库上执行全局一致的读操作，而无需使用锁（译注：因为Spanner使用的是物理时间，而且是全球分布的，所以这里的全局既可以理解为逻辑上的整体，也可以理解为全球性的）。<br>CAP定理[Bre12]说，下面三个期望的属性中，你最多只能同时达到两个：</p><ul><li>C：一致性（Consistency），本文中我们可以认为这是指顺序一致性（Serializability）；</li><li>A：读取和更新的100％可用性（Availability）；</li><li>P：对网络分区（Partitions）的容忍。</li></ul><p>舍弃其中一个字母，就剩下三种系统：CA，CP和AP。请注意，并非自然就会有这三个属性中的两个，有许多系统只有其中的一个属性，甚至一个也没有。<br>对于“广域”上的分布式系统，通常认为网络分区是不可避免的，尽管不一定常见[BK14]。一旦你认为网络分区是不可避免的，任何分布式系统必须准备好放弃一致性（剩下AP）或可用性（剩下CP），这不是人们想做的选择。事实上，CAP定理的出发点是让设计者认真对待这种权衡。但是有两个重要的警告：首先，你只需要在实际发生网络分区期间放弃去某些东西，即时那时也有有许多缓解措施（参见文章“CAP理论12年回顾”[Bre12]）。其次，CAP定理关注的是100%可用性，而本文是关于现实的高可用性涉及的权衡（译注：高但不是100%）。</p><h2 id="Spanner声称同时达到了CA"><a href="#Spanner声称同时达到了CA" class="headerlink" title="Spanner声称同时达到了CA"></a>Spanner声称同时达到了CA</h2><p>尽管是一个全球分布式系统，Spanner却声称具有一致性和高可用性，这意味着没有网络分区，因此很多人表示怀疑 。这是否意味着Spanner是CAP定义的CA系统？简短的答案是技术上“不是”，但效果上“是”，用户可以并确实认为是CA系统。<br>纯粹主义的答案是“否”，因为网络分区总是可能发生，事实上在Google也确实发生过。在网络分区时，Spanner选择C而放弃了A。因此从技术上来说，它是一个CP系统。我们下面探讨网络分区的影响。<br>考虑到始终提供一致性（C），Spanner声称为CA的真正问题是，它的核心用户是否认可它的可用性（A）。如果实际可用性足够高，用户可以忽略运行中断，则Spanner是可以声称达到了“有效CA”的。这并不意味着100％的可用性（Spanner目前和将来也不会提供），而是如5个或更多个“9”（即1/〖10〗^5或更少的失效）。反过来，真正的试金石是，那些希望自己本身的服务高可用的用户，他们是否会编写处理运行中断异常的代码：如果他们没有编写这些代码，那么他们已经假设Spanner的高可用性了。基于大量的Spanner内部用户，我们知道他们认为Spanner是高可用的。<br>第二点是存在许多其它运行中断的原因，除了“生死与共”的Spanner之外，其它原因也会让用户的服务失效。我们实际上关心差异化可用性，即用户是否确实已经发现Spanner已停掉了。差异化可用性比Spanner的实际可用性还要高。也就是说，你必须真的听到大树倒下的声音才算是出了麻烦（译注：也就是说，Spanner的短暂不可用不一定会立即造成用户的系统不可用）。<br>第三个问题是运行中断是否由于网络分区造成的。如果Spanner运行中断的主要原因不是网络分区，那么声称CA就更充分了。例如，任何数据库在所有副本都脱机的情况下都不能提供可用性，这与网络分区无关。这种多副本情况下的运行中断应该是非常罕见的，但如果网络分区的概率显著的更小，那么就可以有效地忽略网络分区对可用性的影响。对于Spanner，这意味着可用性中断的发生，实际并非是由于网络分区，而是一些其它的多种故障（因为单一故障不会造成可用性中断）。</p><h2 id="可用性的统计数据"><a href="#可用性的统计数据" class="headerlink" title="可用性的统计数据"></a>可用性的统计数据</h2><p>在深入Spanner之前，值得先讨论一下Chubby的演进。Chubby是另一个提供CA的广域系统。在Chubby的论文[Bur06]中提到700天中发生了9次30 s或更长时间的运行中断，其中6次与网络相关（如[BK14]中讨论的）。这对应的可用性最多也不超过5个9，如果我们更贴近实际，假设每次中断平均有10 min，那么就只有4个9；如果每次中断有几个小时的话，就只有3个9了。<br>对于锁和一致性读/写操作，随着多项网络、架构和运维的改进，<strong>目前的广域分布的Chubby集群能提供99.99958％的平均可用性</strong>（即仅有30 s多一点的运行中断）。从2009年开始，由于可用性“超额”，Chubby的站点可靠性工程师（SRE）开始人为地强制定期中断服务（译注：即应急演习），以确保我们能发现对Chubby的依赖和其故障可能造成的影响。<br>在内部，Spanner提供与Chubby水平相当的可靠性，少于5.9 s。云版本与内部版本有相同的基础，但添加了一些新的部分，所以它的可靠性在短期内可能稍低一些。<br><img src="/img/spanner-availability.png" alt="Spanner可用性数据"><br>上面的饼图显示了内部Spanner意外事件的原因。事件是意外的，但并非所有都严重到中断服务。一些事件可以轻易地处理掉。图中的数值是事件发生的频率而不是造成的后果。</p><ul><li>大量的事件（<strong>用户事件</strong>）是由于用户错误，例如超载或配置错误，并且大多只影响该用户，然而其它类别则可能影响区域中的所有用户。</li><li><strong>集群事件</strong> 反映除网络外的底层基础架构问题，如服务器和电源的问题。Spanner通过使用其它副本自动地处理这些事件，但有时需要SRE参与修复不完整的副本。</li><li><strong>运维事件</strong> 是由SRE引起的事故，例如配置错误。</li><li><strong>Bug事件</strong> 意味着软件bug触发的问题，这可能导致或大或小不同范围的运行中断。两个最大的中断都是由同时影响了某个数据库的所有副本的软件bug造成的。</li><li><strong>其它事件</strong> 是各种大多只发生一次的问题。</li></ul><p><strong>网络事件</strong> （低于8％）是网络分区和网络配置问题。还没有发生过较大集群的网络分区事件，也没有发生过一个分区的少数一方超过Spanner的Quorum的情况。我们确实看到个别数据中心或区域与其它网络断开。我们还有一些错误配置，短时调低了带宽，还有一些与硬件故障相关的暂时的延迟。曾经有一个事件，其中某个方向的网络中断，导致一个奇怪的分区，必须通过关闭一些节点才能解决。到目前为止，网络事件没有造成过大规模的运行中断。<br>总而言之，要声称“有效CA”，系统必须处于这种相对概率状态：<br>1）至少它在实践中必须具有非常高的可用性，以便用户可以忽略异常；<br>2）由网络分区造成的运行中断应只占很小一部分。<br>Spanner同时满足两者。</p><h2 id="这就是网络"><a href="#这就是网络" class="headerlink" title="这就是网络"></a>这就是网络</h2><p>许多人认为，Spanner通过使用<code>TrueTime</code> 可以绕过CAP。<code>TrueTime</code> 是一个提供全局同步时钟的服务。<code>TrueTime</code> 是非比寻常的，但为实现CA，<code>TrueTime</code> 的作用并不显著。后面的小节会介绍<code>TrueTime</code> 。某种程度说，Spanner的特别之处是，Google私有的广域网，加上多年的运维改进，显著降低了网络分区的发生，从而使高可用性成为可能。<br>首先，Google运行自己的私有全球网络。Spanner并非在公共的互联网上运行 —— 实际上，Spanner的每个数据包只流过Google控制的路由器和链路（不包括到远程客户端的任何边缘链路）。此外，每个数据中心通常至少有三个独立的光纤将其连接到私有的全球网络。因此确保任何两个数据中心之间有多条网络通路 。类似的，数据中心内的设备和链路也是冗余的。因此，通常的灾难性事件，如光纤被切断，不会导致网络分区或运行中断。<br>因此，网络分区的真正风险不是网络被切断，而是某些大范围的配置或软件升级同时破坏了多个链路。这是一个真正的风险，并且Google持续地努力防止和缓解这一风险。一般的策略是限制任何更新的影响范围（“爆炸半径”），以便我们不可避免地推送一个错误的变更后，它只破坏一部分链路或副本。我们在修复问题之前不会尝试任何其它变更。<br>虽然网络分区大大减少了，但光速是有限的。广域上的一致性操作的往返时间（RTT）下限仍比较大，洲际约有几十毫秒或更长。（光速约0.5 ft/ns，若洲际为1 000 mile的距离，约合5 000 000 ft，则最少需要10 ms）。Google将一个“区域”的范围限制在RTT 2 ms之内，以在延迟和容灾之间达到平衡。Spanner通过尽可能的事务批量化来缓解延迟，但这并不能降低单个事务的延迟。对于读操作，延迟通常较低，这是由于全局时间戳和使用本地副本的能力（如下节所述）。<br>具有较弱一致性的模型可能具有较低的更新延迟。然而，如果距离不够远，就会存在一个持久性较低的窗口。因为在数据被复制到另一个站点之前，如果本地站点遭受了灾害，所有的数据都可能被彻底破坏掉（译注：弱一致性模型会推迟数据的跨站点复制操作以降低延迟）。</p><h2 id="网络分区时会发生什么"><a href="#网络分区时会发生什么" class="headerlink" title="网络分区时会发生什么"></a>网络分区时会发生什么</h2><p>为了理解分区，我们需要更多地了解一下Spanner的工作原理。和大多数ACID数据库一样，Spanner使用两阶段提交（2PC）和严格的两阶段锁，以确保隔离性和强一致性。2PC被称为“反可用性”协议[Hel16]，因为事务期间所有成员必须正常工作。为缓解这一问题，Spanner的每个成员实际是一个Paxos组（译注：多个节点组成逻辑上的单个节点），即便Paxos组中某个节点宕机了，每个2PC“成员”也是高可用的。每个分组也是数据放置和复制的基本单元。<br>前面提到，一般来说当发生网络分区时，Spanner会选择C而非A。在实践中，这是考虑到：</p><ul><li>使用Paxos组来达成关于某个更新的共识；如果Paxos Leader由于网络分区而不能维持Quorum，则更新被暂停，并且系统不可用（由CAP的定义）。最终，如果大多数成员可用的话，新的Leader就可能选举出来；</li><li>对跨组事务使用2PC还意味着组内成员的网络分区可以阻止提交。</li></ul><p>在实践中最可能的结果是，网络分区的一侧满足Quorum，并将继续运行，也许需要重新选举Leader。因此，服务继续可用，但是另一侧分区的成员数较少，不满足Quorum，它们的用户无法访问该服务。这个例子说明了差异化可用性的重要性：那些无法访问服务的用户可能会有其它更严重的问题，例如失去连接，也可能已经宕机了。这意味着构建在Spanner之上的多区域服务，即使在网络分区时也能相对良好地运行。存在比较小的可能性，Spanner的某一部分会完全不可用。<br>只要所有事务相关的组都有Quorum选举的Leader，并位于分区的同一侧，Spanner中的事务就会正常运行。这意味着一些事务正常提交，有些事务则会超时，但它们总是满足一致性的。Spanner的一个特性是，任何正常返回的读操作都是一致的，即使事务稍后终止了（由于超时在内的任何原因）。<br>除了常规事务之外，Spanner还支持快照读，即读取过去特定时刻的数据值。Spanner维护多个时间版本的值，每个版本都有一个时间戳，因此可以为快照读操作返回正确的版本。特别地，每个副本都知道生成快照的时间，并且任何副本能以本节点直接回复该时间点之前的读操作（除非它太旧了，以至于已经被垃圾收集）（译注：一般需要从多个节点读取数据并验证多数节点间是否一致）。类似地，很容易同时跨多个组异步读取。快照读完全不需要锁。事实上，只读事务被实现为在当前时刻（在任何最新的副本上）的快照读。<br>因此，快照读对网络分区而言更加健壮。特别的，快照读能在以下情况下正常工作：</p><ol><li>对于发起读操作的一侧网络分区，每个组至少存在一个副本</li><li>对于这些副本，读时间戳是过去的。</li></ol><p>如果Leader由于网络分区而暂停（这可能一直持续到网络分区结束），这时第2种情况可能就不成立了。因为这一侧的网络分区上可能无法选出新的Leader（译注：见下节引用的解释）。在网络分区期间，时间戳在分区开始之前的读操作很可能在分区的两侧都能成功，因为任何可达的副本有要读取的数据就足够了。</p><h2 id="关于TrueTime"><a href="#关于TrueTime" class="headerlink" title="关于TrueTime"></a>关于TrueTime</h2><p>通常，同步时钟可以用于避免分布式系统中的通信。Barbara Liskov提供了一个不错的概述和多个示例[Lis91] 。对于我们的目的，<code>TrueTime</code> 是一个误差有界但非0的全局同步时钟：它返回的是一个时间区间，能保证执行调用的真实时刻落在这个区间内。因此，如果两个区间不重叠，我们能明确地将调用按真实时间排序。但如果区间存在重叠，我们就无法给出这两个调用的顺序了（译注：即并发的）。<br>Spanner的一个微妙的之处是它用锁来实现顺序一致性（Serializability），但它用<code>TrueTime</code> 来实现外部一致性（External Consistency，接近于线性一致性，Linearizability）。Spanner的外部一致性不变量（Invariant）是：对任何两个事务 $T_1$ 和 $T_2$ （即使在地球的两端），<strong> 如果 $T_2$ 在 $T_1$ 提交之后才开始提交，则 $T_2$ 的时间戳大于 $T_1$ 的时间戳。</strong><br>引自Liskov [Lis91，第7节]：</p><blockquote><p>同步时钟可以用来降低违反外部一致性的概率。假设主节点（Primary）拥有租约（Lease，即一段时间的所有权），需要考虑整个副本组。副节点（Backup）发送到主节点的每条消息相当于是对主节点的一个租约。如果主节点持有一个来自次多数（Sub-majority ）副节点的未到期租约，则主节点能以单节点进行读操作。<br>…<br>该系统中的不变量是：每当主节点执行读取时，它持有来自多数副节点的一个有效租约。如果时钟不同步，这个不变量将不再成立。</p></blockquote><p>Spanner使用<code>TrueTime</code> 作为时钟，以确保不变量成立。具体地，在提交期间，Leader可能必须等待，直到它确定提交时间在过去（基于误差界限）。实践中，这种“提交等待”的时间并不太长，而且与（内部）事务通信并行地进行。一般来说，外部一致性需要单调增加的时间戳，“等待不确定性结束”也是一种常见的模式。<br>Spanner旨在通过对当选的Leader使用可顺延的租约，来延长Leader的在位时间（通常为10s）。如Liskov所讨论的，每次Quorum达成共识时（译注：可能是关于其它事项），租约就会被顺延，因为参与者刚刚验证了Leader是有效的。当Leader失效时，有两个选项：1）等待租约过期，然后选举新的Leader；或2）重启旧的Leader，这可能更快些。对于一些故障，我们可以发出一个“最后一息”的UDP数据包来释放租约，这是一个优化，以使租约尽快到期。由于计划外故障在Google的数据中心中很少见，所以长期的租约是合理的。租约还确保时间在Leader之间都是单调增长的，并且在没有Leader的情况下，使副节点能够在租约有效期内继续提供读取服务。<br>然而，<code>TrueTime</code> 的真正价值在于它在一致性快照方面的能力。回顾一下，多版本并发控制系统（Multi-Version Concurrency-Control systems，MVCC）[Ree78]有悠久的历史，它将旧版本分开保存，从而允许读取过时的版本，而不考虑当前的事务活动。这是一个非常有用和被低估的特性：具体到Spanner上，快照是一致的（在抓取快照时），因此如果你的系统中的某个不变量成立，它在快照中也会成立。即使你不知道是什么不变量！基本上，快照是在持续不断的多个事务之间抓取的，并且反映截至此时的所有内容，当然不会超过这些内容。如果没有事务一致的快照，则很难从过去的时刻重新开始，因为这种快照的内容可能反映的是未完成的事务，这种事务可能违反一些不变量或完整性约束。正是缺乏一致性，导致有时难以从备份恢复系统。特别是有可能出现数据损坏，需要手动修复 。<br>例如，考虑使用MapReduce对数据库执行大规模的分析查询。Bigtable存储着旧版本的数据，时间在数据分片上是“锯齿状”的，这使得结果不可预测，有时不一致（特别是对于较近的数据）。在Spanner上，同一个MapReduce可以选择精确的时间戳，并获得可重复和一致的结果。<br><code>TrueTime</code> 还使得跨多个独立系统抓取快照成为可能，只要它们使用（单调增加的）<code>TrueTime</code> 时间戳提交，对抓取快照的时间达成一致，并存储多个时间版本的数据（通常在日志中）。这不仅限于Spanner：你可以实现自己的事务系统，然后确保在两个系统（或甚至k个系统）上一致的快照。一般来说，在这些系统上需要一个2PC（同时持有锁）以就抓取快照的时间达成一致，并确认成功，但系统不需要就其它事项达成一致，甚至这些系统可能会有很大的差异。<br>你还可以使用时间戳做为工作流传递的令牌。例如，如果对系统进行更新，则可以将更新的时间戳传递到工作流的下一个阶段，以便可以确定系统时间是否在该事件之后。在网络分区的情况下，这可能是不成立的，在这种情况下，如果想要一致性，下一个阶段应该等待（或如果想要可用性就继续下去）。没有时间令牌，很难知道你是否需要等待。使用时间戳不是解决这个问题的唯一方法，但这种方法是优雅且健壮的，能够保证最终一致性（Eventual Consistency）。当不同的阶段没有约定规则且管理员不同时，这是特别有用的——因为双方可以在没有通信的情况下对时间达成一致 。<br>快照是关于过去的，但你也可以对未来达成一致。Spanner的一项特性是，为实现模式变更，可以就未来的某个时刻达成一致。这允许暂存对新模式的变更，以便能够同时提供新旧两个版本。一旦就绪，就可以选择一个时刻，在所有副本上以原子的方式切换到新的模式上（也可以选择暂存之前的时刻，但那时你可能还没有准备好）。至少理论上，你可以执行一些未来的操作，如计划删除或可预见的变更。<br><code>TrueTime</code> 本身可能受到网络分区的影响。时间的来源是GPS接收器和原子钟的组合，两者都可以通过它们自身的微小漂移来保持精确的时间（译注：微小漂移是保持时间同步的调节手段，并不是说这两种时钟源不稳定）。由于每个数据中心都有冗余的“Time Master”，因此网络分区的两侧很可能继续获取准确的时间。然而，各个节点需要与Time Master的网络连接，否则它们自己的时钟将偏移。因此，在网络分区期间，它们与Time Master的偏差会逐渐地增长，取决于本地时钟漂移的速率限值。基于<code>TrueTime</code> 的操作，例如Paxos Leader选举或事务提交，必须等待一段时间，但操作仍能够完成（假设2PC及Quorum通信正常）。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>Spanner合理地声称是一个“有效CA”系统。尽管运行在广域上，但它总是一致的，并达到了大于5个 9的可用性。与Chubby一样，同时达到CA在实践中是可能的，前提是像Google那样能控制整个网络，但这在广域上是罕见的。此外，还需要大量冗余的网络链路、处理相关故障的架构规划、以及非常细致的运维，特别是对于升级。如果还是不幸发生了运行中断，Spanner选择一致性而不是可用性。<br>Spanner使用两阶段提交来实现顺序一致性，它使用<code>TrueTime</code> 实现外部一致性、无锁的一致性读取、以及一致性快照。 </p><h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>特别感谢Spanner 和<code>TrueTime</code> 的专家：Andrew Fikes，Wilson Hsieh，和Peter Hochschild。 另外还要感谢 Brian Cooper，Kurt Rosenfeld，Chris Taylor，Susan Shepard，Sunil Mushran，Steve Middlekauff，Cliff Frey，Cian Cullinan，Robert Kubis，Deepti Srivastava，Sean Quinlan，Mike Burrows 和 Sebastian Kanthak。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[BK14] P. Bailis and K. Kingsbury. <a href="http://cacm.acm.org/magazines/2014/9/177925-the-network-is-reliable/abstract" target="_blank" rel="noopener">The Network is Reliable</a>, Communications of the ACM. Vol. 57 No. 9,<br>Pages 48-55. September 2014. Also: [<a href="https://aphyr.com/posts/288-the-network-is-reliable" target="_blank" rel="noopener">https://aphyr.com/posts/288-the-network-is-reliable</a>]<br>[Bre12] E. Brewer. <a href="https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed" target="_blank" rel="noopener">CAP Twelve Years Later: How the “Rules” Have Changed</a>, IEEE Computer, Vol. 45, Issue 2, February 2012. pp. 23—29. <a href="http://www.infoq.com/cn/articles/cap-twelve-years-later-how-the-rules-have-changed" target="_blank" rel="noopener">CAP理论十二年回顾：”规则”变了</a>（译注：这是本文作者之前的一篇文章）<br>[Bur06] M. Burrows. <a href="https://research.google.com/archive/chubby-osdi06.pdf" target="_blank" rel="noopener">The Chubby lock service for loosely-coupled distributed systems</a>. Proceedings of OSDI `06: Fourth Symposium on Operating System Design and Implementation, Seattle, WA, November 2006.<br>[CDE+12] J. Corbett, J. Dean, et. al.  Spanner: Google’s Globally-Distributed Database. Proceedings of OSDI ‘12: Tenth Symposium on Operating System Design and Implementation, Hollywood, CA, October, 2012. <a href="http://dblab.xmu.edu.cn/post/google-spanner/" target="_blank" rel="noopener">厦门大学计算机系 林子雨 老师的译文</a><br>[Hel16] P. Helland. <a href="http://queue.acm.org/detail.cfm?id=2953944" target="_blank" rel="noopener">Standing on Giant Distributed Shoulders: Farsighted Physicists of Yore were Danged  Smart!</a> ACM Queue, Vol. 14, Issue 2, March-April 2016.<br>[Lis91] B. Liskov. <a href="http://dl.acm.org/citation.cfm?id=112601" target="_blank" rel="noopener">Practical Uses of Synchronized Clocks in Distributed Systems</a>. ACM Principles of Distributed Computing (PODC). Montreal, Canada, August 1991.<br>[MHL+92] C. Mohan, D. Haderle, B. Lindsay, H. Pirahesh and P. Schwartz. <a href="http://dl.acm.org/citation.cfm?id=128770" target="_blank" rel="noopener">ARIES: A Transaction Recovery  Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging</a>. ACM Transactions on Database Systems, Vol. 17, No. 1, March 1992, pp. 94-162.<br>[Ree78] D. Reed. <a href="http://publications.csail.mit.edu/lcs/specpub.php?id=773" target="_blank" rel="noopener">Naming and Synchronization in a Decentralized Computer System</a>, PhD Dissertation, MIT Laboratory for Computer Science, Technical Report MIT-LCS-TR-205. October 1978 [See Section 6.3 for list of versions with timestamps]</p><hr><p><img src="/img/spanner-books.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者：&lt;a href=&quot;https://en.wikipedia.org/wiki/Eric_Brewer_%28scientist%29&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Eric Brewer，VP, Infrastructure, Google&lt;/a&gt;&lt;br&gt;2017-02-14&lt;br&gt;英文原文：&lt;a href=&quot;https://research.google.com/pubs/pub45855.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Spanner, TrueTime and the CAP Theorem&lt;/a&gt; ,&lt;a href=&quot;https://research.google.com/pubs/archive/45855.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;英文全文 PDF&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;/doc/Spanner-TrueTime-CAP.pdf&quot;&gt;译文全文PDF&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2018-06更新：推荐阅读《设计数据密集型应用（Designing Data-Intensive Applications）》第9章&lt;/p&gt;
    
    </summary>
    
      <category term="yi" scheme="https://ying-zhang.github.io/categories/yi/"/>
    
    
  </entry>
  
  <entry>
    <title>CCF目录单页版</title>
    <link href="https://ying-zhang.github.io/misc/2017/ccf-all-in-one/"/>
    <id>https://ying-zhang.github.io/misc/2017/ccf-all-in-one/</id>
    <published>2017-02-24T16:00:00.000Z</published>
    <updated>2018-11-08T15:49:03.883Z</updated>
    
    <content type="html"><![CDATA[<p>前一段时间整理论文列表，感觉分成多页的目录用起来不太方便。于是就粘贴复制，把它们合并到一起。<br>Markdown排版比较麻烦，分别保存为HTML格式和Excel格式。<br>CCF网站2016年底改版了一次，目前还保留着旧版网站，新旧网站都有目录的内容。</p><p>各链接如下：</p><ul><li><strong><a href="/doc/ccf-all-in-one-2017-02-25.html">我合并后的CCF目录完整列表，HTML链接，2017-02-25</a></strong> </li><li><strong><a href="/doc/ccf_all_in_one_2017-02-25.xlsx">我合并后的CCF目录完整列表，Excel文件</a></strong></li><li>CCF <strong>新</strong> 网站链接：<a href="http://www.ccf.org.cn/xspj/gyml/" target="_blank" rel="noopener">CCF目录网页版</a>，<a href="http://www.ccf.org.cn/ccf/contentcore/resource/download?ID=32826" target="_blank" rel="noopener">2015版的PDF</a></li><li>CCF <strong>旧</strong> 网站链接：<a href="http://history.ccf.org.cn/paiming.jsp.htm" target="_blank" rel="noopener">CCF目录网页版</a>，<a href="http://history.ccf.org.cn/2015ccfmulu.pdf" target="_blank" rel="noopener">2015版的PDF</a> </li></ul><a id="more"></a><hr><h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>表格中的类别简写分别是:</p><ul><li>AI：人工智能</li><li>系统：计算机体系结构/并行与分布计算/存储系统</li><li>软工：软件工程/系统软件/程序设计语言</li><li>数据库：数据库/数据检索/内容检索</li><li>安全：网络与信息安全</li><li>多媒体：计算机图形学与多媒体</li><li>网络：计算机网络</li><li>理论：计算机科学理论</li><li>其它：交叉/综合/新兴</li><li>交互：人机交互与普适计算</li></ul><p>表格中是按拼音排序的，排序字段依次是：方向，类型（会议/刊物），级别（A/B/C）。</p><h1 id="CCF目录中存在的问题"><a href="#CCF目录中存在的问题" class="headerlink" title="CCF目录中存在的问题"></a>CCF目录中存在的问题</h1><h2 id="同一刊物同时被列入不同方向"><a href="#同一刊物同时被列入不同方向" class="headerlink" title="同一刊物同时被列入不同方向"></a>同一刊物同时被列入不同方向</h2><p>多个研究方向经常出现交叉，所以这种情况也是可以接受的。<br>不过软工方向的一些会议，比如OSDI，就没有被重复列入系统方向。<br>由于列表是按研究方向组织的，不太容易发现重复，如果按会议/期刊排序，就很容易发现了。</p><ul><li>B类刊物 <code>DKE: Data and Knowledge Engineering</code> 分别被列入了 AI 和 数据库 方向</li><li>C类刊物 <code>IJIS: International Journal of Intelligent Systems</code> 分别被列入了 AI 和 数据库 方向</li><li>C类刊物 <code>IPL: Information Processing Letters</code> 分别被列入了 理论 和 数据库 方向</li><li>B类刊物 <code>TOMCCAP: ACM Transactions on Multimedia Computing, Communications and Applications</code> 分别被列入了 网络 和 多媒体 方向</li><li>A类会议 <code>HPCA: High-Performance Computer Architecture</code> （系统方向）的链接是[<a href="http://dblp.org/db/conf/cnhpca/" target="_blank" rel="noopener">http://dblp.org/db/conf/cnhpca/</a>] ，这个是国内的同名会议， <strong>我把链接改成了国际的HPCA会议</strong> [<a href="http://dblp.org/db/conf/hpca/" target="_blank" rel="noopener">http://dblp.org/db/conf/hpca/</a>]</li><li>C类会议 <code>CLOUD</code> [<a href="http://dblp.org/db/conf/IEEEcloud/" target="_blank" rel="noopener">http://dblp.org/db/conf/IEEEcloud/</a>] 2018年分裂为两个 <strong>同名</strong> 但不同人员组织的会议，论文分别由IEEE和Springer发表，不知以后其中一个会不会改名字，<strong>建议以发表在IEEE的为准</strong> 。</li></ul><h2 id="同一方向中的重复会议"><a href="#同一方向中的重复会议" class="headerlink" title="同一方向中的重复会议"></a>同一方向中的重复会议</h2><ul><li>安全方向的 C类会议 <code>ASIACCS</code>和 A类会议 <code>CCS</code>给出的链接都是 [<a href="http://dblp.org/db/conf/ccs/" target="_blank" rel="noopener">http://dblp.org/db/conf/ccs/</a>] ，这个 <strong>不是</strong> 错误，因为dblp上确实是在同一页面显示了 <code>ASIACCS</code> 和 <code>CCS</code>，不过列表中 <code>ASIACCS</code>的全称不太恰当</li><li>交互方向的 C类会议 <code>DIS: ACM Conference on Designing Interactive  Systems</code> 在第2条和第11条重复出现了两次</li></ul><h1 id="TODO-NOMS-vs-APNOMS"><a href="#TODO-NOMS-vs-APNOMS" class="headerlink" title="TODO NOMS vs. APNOMS"></a>TODO NOMS vs. APNOMS</h1><h1 id="TODO-一个新的-期刊-，SIGMetrics下的-POMACS"><a href="#TODO-一个新的-期刊-，SIGMetrics下的-POMACS" class="headerlink" title="TODO 一个新的 期刊 ，SIGMetrics下的 POMACS"></a>TODO 一个新的 <strong>期刊</strong> ，SIGMetrics下的 POMACS</h1><p>Proceedings of the ACM on Measurement and Analysis of Computing Systems [<a href="https://dl.acm.org/citation.cfm?id=J1567" target="_blank" rel="noopener">https://dl.acm.org/citation.cfm?id=J1567</a>]</p><p><img src="/img/ccf_sum.png" alt="会议/刊物分方向汇总"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前一段时间整理论文列表，感觉分成多页的目录用起来不太方便。于是就粘贴复制，把它们合并到一起。&lt;br&gt;Markdown排版比较麻烦，分别保存为HTML格式和Excel格式。&lt;br&gt;CCF网站2016年底改版了一次，目前还保留着旧版网站，新旧网站都有目录的内容。&lt;/p&gt;
&lt;p&gt;各链接如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/doc/ccf-all-in-one-2017-02-25.html&quot;&gt;我合并后的CCF目录完整列表，HTML链接，2017-02-25&lt;/a&gt;&lt;/strong&gt; &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/doc/ccf_all_in_one_2017-02-25.xlsx&quot;&gt;我合并后的CCF目录完整列表，Excel文件&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;CCF &lt;strong&gt;新&lt;/strong&gt; 网站链接：&lt;a href=&quot;http://www.ccf.org.cn/xspj/gyml/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CCF目录网页版&lt;/a&gt;，&lt;a href=&quot;http://www.ccf.org.cn/ccf/contentcore/resource/download?ID=32826&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2015版的PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CCF &lt;strong&gt;旧&lt;/strong&gt; 网站链接：&lt;a href=&quot;http://history.ccf.org.cn/paiming.jsp.htm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CCF目录网页版&lt;/a&gt;，&lt;a href=&quot;http://history.ccf.org.cn/2015ccfmulu.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2015版的PDF&lt;/a&gt; &lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="misc" scheme="https://ying-zhang.github.io/categories/misc/"/>
    
    
  </entry>
  
  <entry>
    <title>如何收集和整理论文（面向CS专业）</title>
    <link href="https://ying-zhang.github.io/misc/2016/we-love-paper/"/>
    <id>https://ying-zhang.github.io/misc/2016/we-love-paper/</id>
    <published>2016-09-27T16:00:00.000Z</published>
    <updated>2018-11-10T04:43:40.516Z</updated>
    
    <content type="html"><![CDATA[<p>论文（Paper）是每个研究生读研路上挥之不去的“阴云”。<br>无论是否已经有了一个好的课题或想法，都首先要收集某个研究方向一定数量的论文，来了解相关的工作和最新进展（State of the art &amp; practice）。<br>本文介绍了如何检索、收集计算机科学（CS）专业的论文，还介绍了相关的机构，学术会议和论文数据库。<br>文末有 <a href="#hosts"><strong>Bonus</strong></a> 哦;-)</p><a id="more"></a><hr><h1 id="tl-dr-太长不看版"><a href="#tl-dr-太长不看版" class="headerlink" title="tl;dr 太长不看版"></a>tl;dr 太长不看版</h1><ul><li>从<a href="https://ying-zhang.github.io/misc/2017/ccf-all-in-one/">CCF推荐目录</a>中自己感兴趣的方向的 <strong>A类会议及期刊</strong> 中找论文即可。</li><li>云计算，程序分析方向的<a href="#tldr">会议和期刊链接列表</a></li><li><a href="#hosts"><strong>Bonus</strong></a> 修改Hosts</li></ul><hr><h1 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h1><p>按理说，开篇应该先要强调一下Paper对于科研的重要性的，直接把前辈的经验拿来吧：</p><ul><li>周志华老师的一篇关于<a href="/doc/research_and_paper_zhou_zhihua_2007_ppt.pdf">做研究与写论文的ppt</a></li><li>凌晓峰和杨强的<a href="http://item.jd.com/11127141.html" target="_blank" rel="noopener">《学术研究 - 你的成功之道》</a>，这本书的英文原版是<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6813064" target="_blank" rel="noopener">Crafting Your Research Future - A Guide to Successful Master’s and Ph.D. Degrees in Science &amp; Engineering</a></li></ul><p>首先要从前辈的经验中端正对Paper的态度：Paper不是科研的原因，而是结果（的一部分）。结果肯定是必要的，自然也就少不了Paper或者总结报告；<br>再者要借鉴前辈的学习方法和技巧，所谓“工欲善其事，必先利其器”，除了科研课题本身，养成一套高效的科研方法和习惯也是重要的。<br>重要的是要 <strong>有意识地探索和总结适合自己的科研方法</strong>，既要低头苦干，又要抬头看路，还要回头总结。</p><h2 id="论文发表的过程"><a href="#论文发表的过程" class="headerlink" title="论文发表的过程"></a>论文发表的过程</h2><pre>                                  / 期刊，特辑/专刊 → 多轮审稿 → 上线 \Idea -> 编程、实验、写Paper、投稿 <                                    ->出版，检索                                  \ 会议           → 审稿 → 赴会报告 /</pre><p>简单介绍一下发表论文的过程：</p><ul><li>首先投稿的Paper作者，一般是高校的的研究生，也有教师，比如<a href="https://amplab.cs.berkeley.edu/" target="_blank" rel="noopener">UC Berkeley 的AMPLab</a>；还有一些公司的研究院，比如<a href="https://www.microsoft.com/en-us/research/" target="_blank" rel="noopener">微软</a>，<a href="https://research.google.com/pubs/papers.html" target="_blank" rel="noopener">谷歌</a>。显然，论文的出身对质量有很大影响。</li><li>期刊是传统的研究成果发表方式，一般期刊是季度，少有月度出版的，每期称为一个Issue，一年的各期集结为一个Volume。一般可以随时投稿给期刊，没有截稿日期（Deadline，ddl）的压力。投稿后一般要经过同行评审（Peer Review），针对审稿人的建议做大修，小修（Major，Minor Revision）等两三轮修改才能被接收，期间跨度一年多是常有的情况。不过如果有的期刊安排了专刊（Special Issue）计划，会公布一个截稿日期，审稿的进度会稍快些。<br>期刊分为 <strong>Transaction, Journal 和 Magazine</strong> 。这三者的学术严肃性依次降低，这可以从它们的封面上直观地看出来。严格来说Magazine不算是学术期刊了，上面很少发表新的原创性的内容，而是对当前进展的简介和综述，也会转发一些已经发表过的重要的Paper。 <strong>不过对于新手来说，先浏览一下Magazine，建立一个基本的概念还是很有必要的，特别是 <a href="http://dl.acm.org/citation.cfm?id=J79" target="_blank" rel="noopener">Communications of the ACM（CACM, ACM通讯）</a> 值得关注</strong>。</li><li>对快速发展的CS专业来说，期刊的节奏有点慢了，而且期刊版面有限，每期只能发布几篇到十几篇不等（有的期刊则动辄一卷几千页，所以，文章质量嘛……），所以上面发表的一般是一些理论性比较强的论文，或者综述性的论文；很多新成果转而发表在学术会议上来，这跟传统学科不太一样。<br>很多会议每年举行一次，时间上也是比较固定的月份，会提前在会议网站上发布下一年的call for paper（cfp，征稿启事）和deadline（截稿日期）。投稿后，一般经过两三个月的审稿就会通知作者是否录用（Notifications）。被接收的Paper会要求按格式和Reviewers的意见稍修改后提交正式的最终版，称为Camera Ready。最后需要作者赴会做Presentation。<br>会议录用的所有Paper会结集出版，称为 <strong>Proceedings</strong> 。有的会议还会推荐一些优秀的Paper到合作的期刊，扩展后作为期刊论文发表。<br>会议分为 <strong>Symposium , Conference 和 Workshop</strong>。这三者的学术严肃性依次降低，大部分会议都称为 <strong>Conference</strong>。一般来说 <strong>Workshop</strong> 是随某个 <strong>Conference</strong> 一同举办，可能没有固定的主题，Paper质量与主会议有所差别。</li></ul><p>通过这个过程，我们还可以知道如何 <strong>尽快</strong> 找到一篇感兴趣的文章：</p><ul><li>对于期刊，一般投稿是很多的，编辑部会把已经接收但还没有排到出版期号的文章先放到网上在线出版，称为Early Access，即在线预出版；</li><li>对于会议，在确定了接收的文章后，会在会议网站的Program/Accepted Papers/Schedule等类似链接下给出列表，同时会Email通知作者准备提交Camera Ready版。这时有的作者就会把Camera Ready版放到自己的主页上。之后会议组委将论文集结提供给所有作者，还会将论文集发布到ACM或IEEE（这两个机构直接参与组织了很多会议）的论文数据库中。不同的会议组委效率不同，有的在开会前就上线出版了，有的在会议结束后还要等一段时间。</li></ul><h1 id="CS论文数据库"><a href="#CS论文数据库" class="headerlink" title="CS论文数据库"></a>CS论文数据库</h1><h2 id="ACM-IEEE-Computer等"><a href="#ACM-IEEE-Computer等" class="headerlink" title="ACM, IEEE Computer等"></a>ACM, IEEE Computer等</h2><p>一般会议和期刊都有自己的网站，但很少能在上面获取到论文全文。又因为来源分散，直接从它们那里检索Paper很不方便。有几个大型的论文数据库，它们与期刊或者会议主办方合作，或者自己组织会议或编辑出版期刊，比如下面的表格及<a href="#lib">图书馆页面截图</a>。</p><blockquote><p>注意， DL和机构的网站有很多介绍性的内容是重复的，下载论文全文要去DL的页面。</p></blockquote><div class="table-container"><table><thead><tr><th>机构</th><th>Digital Library （DL）</th><th>机构首页</th></tr></thead><tbody><tr><td>Association for Computing Machinery, ACM</td><td>ACM Digital Library  <a href="https://dl.acm.org/" target="_blank" rel="noopener">https://dl.acm.org/</a></td><td><a href="https://www.acm.org/" target="_blank" rel="noopener">https://www.acm.org/</a></td></tr><tr><td>IEEE Computer Society</td><td>IEEE Xplore DL <a href="http://ieeexplore.ieee.org/" target="_blank" rel="noopener">http://ieeexplore.ieee.org/</a></td><td><a href="https://www.computer.org/" target="_blank" rel="noopener">https://www.computer.org/</a></td></tr><tr><td>Elsevier ScienceDirect</td><td><a href="http://www.sciencedirect.com/" target="_blank" rel="noopener">http://www.sciencedirect.com/</a></td><td><a href="https://www.elsevier.com/" target="_blank" rel="noopener">https://www.elsevier.com/</a></td></tr><tr><td>Springer</td><td>Springer Link <a href="http://link.springer.com/" target="_blank" rel="noopener">http://link.springer.com/</a></td><td><a href="http://www.springer.com/" target="_blank" rel="noopener">http://www.springer.com/</a></td></tr><tr><td>Wiley</td><td>Wiley Online Lib <a href="http://onlinelibrary.wiley.com/" target="_blank" rel="noopener">http://onlinelibrary.wiley.com/</a></td><td><a href="http://www.wiley.com/" target="_blank" rel="noopener">http://www.wiley.com/</a></td></tr></tbody></table></div><p>ACM 和 IEEE Computer Society（计算机学会，IEEE还有电气、电子、通信等其它多个学会） 的网址后缀是 <strong>.org</strong>，这两个是CS领域最重要的学术组织，很多的CS学术会议都是由它们组织的。<br>Elsevier，Springer，Wiley的网址后缀则是 <strong>.com</strong> ，这些是学术出版商，内容以期刊为主，涵盖了CS及其它多个学科。<br>上面这几个数据库是 <strong>主要的论文全文来源</strong>。它们各自收录的会议和期刊基本没有重叠，从它们的数据库下载的Paper也都有各自的排版样式。</p><blockquote><p>ACM作为最“正统”的计算机学术组织，它的DL除了收录ACM组织的会议和期刊全文之外，还会索引其它几家数据库的 <strong>元数据</strong>，但没有全文，不过可以通过DOI链接跳转到这几家数据库的全文页面。<strong><a href="https://en.wikipedia.org/wiki/Association_for_Computing_Machinery" target="_blank" rel="noopener">ACM - Wikipedia</a></strong><br>IEEE出版的一些论文在 computer.org （实际是<a href="https://www.computer.org/csdl/" target="_blank" rel="noopener">CSDL</a>）和 Xplore DL 都可能搜到，但这两个数据库是 <strong>分别</strong> 收费的，能在Xplore DL下载的不一定能在Computer.org下载。 <strong><a href="https://en.wikipedia.org/wiki/IEEE_Computer_Society" target="_blank" rel="noopener">IEEE Computer Society - Wikipedia</a></strong></p></blockquote><h3 id="ACM-SIGs"><a href="#ACM-SIGs" class="headerlink" title="ACM SIGs"></a>ACM SIGs</h3><p>ACM之下针对CS多个子方向的“分舵”，称为Special Interest Group，SIG，目前有三十多个<a href="http://www.acm.org/sigs/" target="_blank" rel="noopener">ACM SIGs</a>（或参考DL的这个链接<a href="http://dl.acm.org/sigs.cfm" target="_blank" rel="noopener">SIGs ACM DL</a>），比如</p><ul><li>体系结构方向的<a href="http://www.sigarch.org/" target="_blank" rel="noopener">SIGARCH</a>、<a href="http://www.sighpc.org/" target="_blank" rel="noopener">SIGHPC</a>、<a href="http://www.sigmetrics.org/" target="_blank" rel="noopener">SIGMETRICS</a>、<a href="http://www.sigmicro.org/" target="_blank" rel="noopener">SIGMICRO</a>、<a href="http://www.sigmobile.org/" target="_blank" rel="noopener">SIGMOBILE</a>，</li><li>网络方向的<a href="http://www.sigcomm.org/" target="_blank" rel="noopener">SIGCOMM</a>，</li><li>数据库方向的<a href="http://www.sigmod.org/" target="_blank" rel="noopener">SIGMOD</a>，</li><li>系统方向的<a href="http://www.sigops.org/" target="_blank" rel="noopener">SIGOPS</a>，</li><li>软件工程方向的<a href="http://www.sigplan.org/" target="_blank" rel="noopener">SIGPLAN</a>、<a href="http://www.sigsoft.org/" target="_blank" rel="noopener">SIGSOFT</a></li></ul><p>这些SIGs除了组织一系列的学术会议，还会评选本方向的一些奖项，包括 <strong><a href="https://www.sigsoft.org/awards/distinguishedPaperAward.html" target="_blank" rel="noopener">最佳论文</a></strong>，<strong><a href="https://www.sigsoft.org/awards/dissertationAward.html" target="_blank" rel="noopener">优秀博士论文</a></strong> 等（论文数据库中有时没有标明哪些是 Best Paper）。<br>此外，</p><ul><li>有网站维护了一个<a href="http://jeffhuang.com/best_paper_awards.html" target="_blank" rel="noopener">部分会议的最佳论文列表</a>，</li><li>还有下面要介绍的USENIX的<a href="https://www.usenix.org/conferences/best-papers" target="_blank" rel="noopener">各会议最佳论文</a>。</li></ul><p>有的SIG会选择一些高质量的文章，以Review，Newsletter 或 Notes 的形式重新发表，引用的时候最好引用最初的来源。</p><h2 id="USENIX"><a href="#USENIX" class="headerlink" title="USENIX"></a><a href="https://www.usenix.org/" target="_blank" rel="noopener">USENIX</a></h2><p>要是学校的图书馆不差钱，把所有有价值的论文数据库都买买买来，那么下面截图中的电子资源列表应该很全了吧？然而还是少了一个重要的数据库：USENIX —— 它是免费的。<br>话说<strong><a href="https://www.usenix.org/" target="_blank" rel="noopener">USENIX</a></strong> 实在是个良心组织。USENIX最初称为Unix User Group。它组织了OSDI 、ATC、FAST、NSDI、LISA等会议，不但学术水平很高，贴近工业界，而且免费提供全文下载，还提供一些论文作者在会议上的slides及演讲视频。slides是对文章的提炼，读论文时可以参考。拿slides和视频来学习做Presentation，练习英语听力和口语也不错。</p><h2 id="arXiv"><a href="#arXiv" class="headerlink" title="arXiv"></a><a href="http://arxiv.org/" target="_blank" rel="noopener">arXiv</a></h2><p><a href="http://arxiv.org/" target="_blank" rel="noopener">arXiv</a>， 是archive（归档）的意思，是一个由康乃尔大学维护的免费的多学科论文<strong>预</strong>出版（preprint）数据库。所谓<strong>预</strong>出版，就是说论文还没有经过同行评审，文责自负，文章质量参差不齐，所以一般不会作为正式的学术成果。不过有的学科习惯上先把文章公开到arXiv上，然后再提交到会议上。</p><p><a name="lib"><img src="/img/lib.png" alt="图书馆电子资源"></a></p><h2 id="EI和SCI"><a href="#EI和SCI" class="headerlink" title="EI和SCI"></a>EI和SCI</h2><p>分别搜索上面的数据库还是有点麻烦，于是就有了一些聚合数据库，又称为索引。想必很多同学在读研之前早就听说EI和SCI，</p><ul><li>EI <strong>Engineering Index</strong> <a href="https://www.engineeringvillage.com/" target="_blank" rel="noopener">https://www.engineeringvillage.com/</a></li><li>SCI <strong>Science Citation Index</strong> <a href="http://apps.webofknowledge.com/" target="_blank" rel="noopener">http://apps.webofknowledge.com/</a></li></ul><p><strong>只看 URL 还以为是 山寨网站</strong>，它们的Web界面体验也不太友好，而且它们不止有CS一个学科，直接通过关键词搜索经常会给出不相关的内容。其实这两个数据库通常是在 <strong>已知文章标题的情况下</strong> 检索是不是被它们收录了，而 <strong>不是</strong> 用来收集文章的。</p><p>要确定某个会议论文集或者期刊<a href="http://www.philippe-fournier-viger.com/links.php" target="_blank" rel="noopener">是否被EI或SCI收录</a>，</p><ul><li>在<a href="https://www.elsevier.com/solutions/engineering-village/content" target="_blank" rel="noopener">EI收录列表</a> 页内搜索Compendex Source List，会找到一个Excel表格的链接，下载下来会发现这个表格是受保护的，但可以筛选标题（而且最后一个WorkSheet有中文翻译哦，满满的土洋结合，中国特色）。嘘~~ 也许你可以参考<a href="/doc/crack_xls_vb.txt">这个脚本解除保护</a>，还要建议把title列中每个单元格开头的<code>=</code>替换掉。这个Excel的title是排好序的，方便顺序浏览，比如有个杂志名叫<code>Computing</code>，真是起的好名字，如果直接搜索是肯定搜出一堆结果，所以，即便找到名字一样的期刊，最好也要再确认一下ISSN号。<strong>但是！</strong>，这个Excel表格并不完整，如果没有在表中搜索到，还是需要在EI的网站上搜索文章标题才能最终确认。对了，EI的数据库叫 <strong>Compendex</strong>。</li><li>在<code>webofknowledge</code>的网站查询之前，<strong>一定</strong> 要选择数据库为<code>检索 Web of Science 核心合集</code>，等页面自动刷新之后，还要在页面下部展开“更多设置”，只选中<code>Science Citation Index Expanded (SCIEXPANDED) 1900年至今</code>这一项，然后才能查询出根正苗红的<code>SCI（E）</code>。请<strong>务必</strong>参考<a href="/doc/SCI_E_Web_of_Science.pdf">这个截图</a>。可以在<a href="http://ip-science.thomsonreuters.com/cgi-bin/jrnlst/jlsearch.cgi?PC=K" target="_blank" rel="noopener">SCI收录列表</a>直接输入期刊的名称来查询该期刊是否被SCI收录，但感觉这个查的也不全。还是要充分利用SCI的中国特色了，因为还有一个国内整理的SCI期刊列表：<a href="https://scit.nju.edu.cn/10973/list.htm" target="_blank" rel="noopener">中国科学技术信息研究所SCI（E）论文期刊分区列表</a>，这是一个有一万三千多行的Excel表格，简单粗暴。</li></ul><hr><p>上面的这些数据库可以免费检索标题和摘要，购买全文则价格不菲。如果学校的图书馆购买了这些数据库，一般会识别用户的IP地址，在学校网络范围内可以直接下载PDF全文。<br>校外就没有这么方便了，好在很多作者在Paper被录用后会在自己的主页上挂出PDF全文，从Google Scholar上可以搜索到这些PDF全文的链接，非常方便。<br>话说只要是能花钱买到的东西，去万能的 <strong>淘宝</strong> 肯定能找到，就看是买 <strong>VPN/代理，单篇文章，还是 整个数据库</strong> 了。</p><h2 id="dblp"><a href="#dblp" class="headerlink" title="dblp"></a>dblp</h2><p>dblp [<a href="https://dblp.org" target="_blank" rel="noopener">https://dblp.org</a>] ，或[<a href="https://dblp.uni-trier.de]，" target="_blank" rel="noopener">https://dblp.uni-trier.de]，</a> 是专注于CS学科的文献 <strong>元数据索引</strong> 数据库，优势是收集得相当完整，链接也很有规律，比如特定会议的 FSE 2016 <a href="https://dblp.org/db/conf/sigsoft/fse2016.html" target="_blank" rel="noopener">https://dblp.org/db/conf/sigsoft/fse2016.html</a> 或者某个作者的全部论文列表（dblp对重名作者处理得很好），但只能搜索标题或作者等元数据，用来初步筛选论文非常方便，需要获取全文时还是要跳转到上面的几个数据库，数据更新也稍微滞后一点。<br>2015版CCF目录中的会议和期刊都是dblp的链接。</p><p>dblp 列出了关于CS论文的一些统计数据，比如（2016年10月查询）</p><ul><li><a href="https://dblp.dagstuhl.de/statistics/recordsindblp.html" target="_blank" rel="noopener">累计论文记录数量</a>，</li><li><a href="https://dblp.dagstuhl.de/statistics/publicationsperyear.html" target="_blank" rel="noopener">每年发表的论文数量</a>，</li><li><a href="https://dblp.dagstuhl.de/statistics/distributionofpublicationtype.html" target="_blank" rel="noopener">论文发表的类型</a>，其中会议论文占53%，</li><li>论文总数 3,587,354 ， 作者人数 1,825,286，会议数4,912，期刊数 1,491。</li></ul><p>另外，ACM DL也有一个<a href="http://dl.acm.org/contents_guide.cfm" target="_blank" rel="noopener">类似的统计</a>。<br><img src="/img/pubs.png" alt="每年发表的CS论文数量"></p><p>而且dblp整站的数据都可以下载为一个<a href="https://dblp.dagstuhl.de/xml/" target="_blank" rel="noopener">xml文件</a>，以供进一步挖掘。</p><h2 id="DOI"><a href="#DOI" class="headerlink" title="DOI"></a>DOI</h2><p>在查找或引用论文时经常会遇到DOI(Digital Object Identifier)，<a href="https://zh.wikipedia.org/wiki/DOI" target="_blank" rel="noopener">wikipedia介绍DOI</a>“是一套识别数字资源的机制，涵括的对象有视频、报告或书籍等等。它既有一套为资源命名的机制，也有一套将识别号解析为具体地址的协议”。有一个 [<a href="https://sci-hub.tw" target="_blank" rel="noopener">https://sci-hub.tw</a>] 网站，可以通过DOI获取不少文章的全文。</p><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>从Google Scholar搜索全文时可能会跳转到下面这几个网站，因为它们会保存一些别人分享的全文。</p><ul><li>Semantic Scholar [<a href="https://www.semanticscholar.org" target="_blank" rel="noopener">https://www.semanticscholar.org</a>]</li><li>CiteSeerX [<a href="http://citeseerx.ist.psu.edu/" target="_blank" rel="noopener">http://citeseerx.ist.psu.edu/</a>]</li><li>ResearchGate [<a href="https://www.researchgate.net/" target="_blank" rel="noopener">https://www.researchgate.net/</a>] ，这是一个学术社交网络</li></ul><h1 id="CCF目录"><a href="#CCF目录" class="headerlink" title="CCF目录"></a>CCF目录</h1><p>EI和SCI只是两个论文数据库，但能够发表被EI和SCI收录的文章变成了能够毕业，能否获得奖学金，能否获得基金的指标。由于时代的限制，EI和SCI被赋予了不相称的地位和意义，而且短期看还是如此。<br>更 “<strong>不幸</strong>” 的是，对于CS的学生，还有一个<a href="http://history.ccf.org.cn/sites/ccf/paiming.jsp" target="_blank" rel="noopener">CCF目录</a>（<a href="http://history.ccf.org.cn/sites/paiming/2015ccfmulu.pdf" target="_blank" rel="noopener">2015版的PDF</a>）摆在面前。其实并非是不幸，而是十分幸运，因为CCF目录不像是一个紧箍咒，而更像是一个入门指南。</p><p>首先说<a href="http://www.ccf.org.cn/" target="_blank" rel="noopener">中国计算机学会 CCF</a>是国内的类似于ACM的计算机学术组织。也许某位同学的导师就是CCF会员。相比EI和SCI收录的成百上千的会议和期刊，CCF维护的目录显然<a href="https://ying-zhang.github.io/misc/2017/ccf-all-in-one/">精简得多</a>。<br>考虑到对EI和SCI指标要求的实际情况，目录选取的 <strong>大多</strong> 是被EI或SCI收录的，具体划分为10个子方向，并区分出A，B，C三个等级。<br>A，B类的会议和期刊的文章学术质量较高。这个质量不是简单通过所谓影响因子等机械的数据来评价的，而是综合了多种因素，国际上也获得比较广泛认可的。比如，翻一下本科的《现代操作系统》这本经典教材的参考文献，会发现其中引用的有不少SOSP，OSDI，ASPLOS，TCS等CCF A类会议和期刊。</p><blockquote><p>如果只看标题和摘要，有的期刊/会议文章看起来非常值得一读，比如 <a href="https://dblp.org/db/journals/fgcs/" target="_blank" rel="noopener">Future Generation Computer Systems，FGCS</a>上的文章。但如果仔细读一下文章全文，经常是大失所望。好在CCF只给了FGCS C类的评级。<br><strong>随着越来越多的研究生进入工业界，论文对码农来说也就不那么神秘了。看到别人写的文章末尾附上了一大堆英文论文，也不会被震惊到只能点赞了，还要看看这些文章发在哪些会议或者期刊上，要是一堆CCF-C或者都不在CCF列表的（当然，一些较新的，没来得及收录的除外），那就呵呵了。</strong><br>其实二八定律也符合学术界，对CS专业来说比例可能更甚。<strong>事实是大部分的文章不值得细读</strong>。这时就显现出CCF评级的价值了。<strong>我的衷告是：仅从CCF-A类 会议 搜集资料就足够了</strong>，能提高检索效率，避免无用功。</p></blockquote><p>上面提到ACM有三十多个SIGs，而CCF则只划分了10个子方向，不同的视角有不同的划分结果，这里有ACM的更详细的<a href="http://dl.acm.org/ccs/ccs.cfm" target="_blank" rel="noopener">分类系统CCS</a>，以及有重叠的<a href="https://www.acm.org/special-interest-groups/sigs-by-knowledge-area" target="_blank" rel="noopener">SIGs大类划分</a>，还有<a href="https://en.wikipedia.org/wiki/Outline_of_computer_science" target="_blank" rel="noopener">wikipedia上的一个划分</a>。</p><h1 id="Google-Scholar（谷歌学术）"><a href="#Google-Scholar（谷歌学术）" class="headerlink" title="Google Scholar（谷歌学术）"></a>Google Scholar（谷歌学术）</h1><p><a href="https://scholar.google.com/" target="_blank" rel="noopener">Google Scholar</a>非常强大又简单易用。虽然它不只收录CS专业的文献，但很容易搜索到准确的结果。我习惯先在谷歌学术上搜索，如果搜不到就改用 <strong>高级搜索</strong>，实在不行再去ACM DL、IEEE Xplore或者Google网页搜索。</p><p><img src="/img/scholar_adv.png" alt="谷歌学术高级搜索" width="700"></p><h2 id="创建快讯"><a href="#创建快讯" class="headerlink" title="创建快讯"></a>创建快讯</h2><p>与Google网页搜索一样，可以在Google Scholar创建某个关键词或某篇文章的快讯（发送邮件通知最新的搜索结果）。<br>接收快讯 <strong>不需要</strong> 注册谷歌账号，任何有效的 Email 皆可。如果注册了谷歌学术账号，还可以获得个性化推荐的文章。</p><p>谷歌学术有 3 种快讯：</p><ol><li>关键词快讯：如果在谷歌学术搜索完整的文章标题，只有一条匹配结果的话，谷歌会很自信地 <strong>不</strong> 在页面左侧显示 “创建快讯” 的入口链接；有多条结果时，才会显示。这是关键词快讯，是从文章全文中检索的，跟普通的谷歌网页搜索快讯差不多，查询结果可能有不少无关项，准确度较差，不建议使用；</li><li>引用快讯：点击文章项的 “被引用次数：xx” 链接，在新的引用项列表页，左侧同样有 “创建快讯” 链接，这时创建的是引用该文章的快讯，相当于科研人员人工添加的项，是最准确的，<strong>推荐使用</strong>；不足之处是，对比较新的文章，还没有被引用过的话，就没有引用页，也就无法获取这个 “创建快讯” 入口链接… 解决办法可 <a href="https://webapps.stackexchange.com/questions/45333/how-to-create-a-citation-alert-for-a-paper-without-citation-in-google-scholar" target="_blank" rel="noopener">参考这个 StackExchange 问题</a> ；</li><li>作者快讯：如果某位作者在谷歌学术创建了个人主页（如 <a href="https://scholar.google.com/citations?user=RivxoIcAAAAJ" target="_blank" rel="noopener">苏振东教授的主页</a>），可以点击其主页上的 “关注” 按钮，获取其 <strong>新文章</strong>，<strong>该作者文章的新引用</strong>，<strong>相关研究的新文章</strong>，推荐前 2 个选项即可。</li></ol><p><img src="/img/scholar_newslet.png" alt="谷歌学术 - 引用快讯" width="500"></p><p><img src="/img/scholar_newslet_author.png" alt="谷歌学术 - 作者快讯" width="540"></p><blockquote><p>也可以体验一下<a href="http://www.bing.com/academic" target="_blank" rel="noopener">必应学术</a>、<a href="http://xueshu.baidu.com/" target="_blank" rel="noopener">百度学术</a>。真是没有对比就没有伤害啊…</p></blockquote><p><a name="tldr"></a></p><h1 id="tl-dr：链接列表"><a href="#tl-dr：链接列表" class="headerlink" title="tl,dr：链接列表"></a>tl,dr：链接列表</h1><h2 id="体系结构，分布式系统"><a href="#体系结构，分布式系统" class="headerlink" title="体系结构，分布式系统"></a>体系结构，分布式系统</h2><div class="table-container"><table><thead><tr><th>缩写</th><th>CCF级别</th><th>链接</th><th>全称</th></tr></thead><tbody><tr><td>ASPLOS</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE178&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/asplos/" target="_blank" rel="noopener">DBLP</a></td><td>Architectural Support for Programming Languages and Operating Systems</td></tr><tr><td>HPCA</td><td><strong>A</strong></td><td><a href="http://ieeexplore.ieee.org/servlet/opac?punumber=1000335" target="_blank" rel="noopener">IEEE</a> , <a href="https://dblp.org/db/conf/hpca/" target="_blank" rel="noopener">DBLP</a></td><td>High-Performance Computer Architecture</td></tr><tr><td>ISCA</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE239&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/isca/" target="_blank" rel="noopener">DBLP</a></td><td>Int. Symposium on Computer Architecture</td></tr><tr><td>MICRO</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE203&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/micro/" target="_blank" rel="noopener">DBLP</a></td><td>Microarchitecture</td></tr><tr><td>PPoPP</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE241&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/ppopp/" target="_blank" rel="noopener">DBLP</a></td><td>Principles and Practice of Parallel Programming</td></tr><tr><td>SC</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE207&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/sc/" target="_blank" rel="noopener">DBLP</a></td><td>Int. Conf. for High Performance Computing, Networking, Storage, and Analysis</td></tr><tr><td>ATC</td><td><strong>A</strong></td><td><a href="https://www.usenix.org/conferences/byname/131" target="_blank" rel="noopener">USENIX</a> , <a href="https://dblp.org/db/conf/usenix/" target="_blank" rel="noopener">DBLP</a></td><td>USENIX Annul Technical Conf.</td></tr><tr><td>EuroSys</td><td><strong>B</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE101&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/eurosys/" target="_blank" rel="noopener">DBLP</a></td><td>European Conf. on Computer Systems</td></tr><tr><td>HPDC</td><td><strong>B</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE300&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/hpdc/" target="_blank" rel="noopener">DBLP</a></td><td>High-Performance Distributed Computing</td></tr><tr><td>LISA</td><td><strong>B</strong></td><td><a href="https://www.usenix.org/conferences/byname/5" target="_blank" rel="noopener">USENIX</a> , <a href="https://dblp.org/db/conf/lisa/" target="_blank" rel="noopener">DBLP</a></td><td>Large Installation system Administration Conf.</td></tr><tr><td>PODC</td><td><strong>B</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE221&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/podc/" target="_blank" rel="noopener">DBLP</a></td><td>Symposium on Principles of Distributed Computing</td></tr><tr><td>SigMetrics</td><td><strong>B</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE187&amp;tab=pubs" target="_blank" rel="noopener">ACM</a>，<a href="http://dl.acm.org/citation.cfm?id=J618" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/sigmetrics/" target="_blank" rel="noopener">DBLP</a></td><td>Int. Conf. on Measurement and Modeling of Computer Systems</td></tr><tr><td>TC</td><td><strong>A</strong></td><td><a href="https://www.computer.org/web/tc" target="_blank" rel="noopener">IEEE</a> , <a href="https://dblp.org/db/journals/tc/" target="_blank" rel="noopener">DBLP</a></td><td>Trans. on Computers</td></tr><tr><td>ToCS</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/pub.cfm?id=J774&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/journals/tocs/" target="_blank" rel="noopener">DBLP</a></td><td>Trans. on Computer Systems</td></tr><tr><td>TPDS</td><td><strong>A</strong></td><td><a href="https://www.computer.org/web/tpds" target="_blank" rel="noopener">IEEE</a> , <a href="https://dblp.org/db/journals/tpds/" target="_blank" rel="noopener">DBLP</a></td><td>Trans. on Parallel and Distributed Systems</td></tr></tbody></table></div><h2 id="云计算，大数据"><a href="#云计算，大数据" class="headerlink" title="云计算，大数据"></a>云计算，大数据</h2><div class="table-container"><table><thead><tr><th>缩写</th><th>CCF级别</th><th>链接</th><th>全称</th></tr></thead><tbody><tr><td>SIGMOD</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE227&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/sigmod/" target="_blank" rel="noopener">DBLP</a></td><td>Conf. on Management of Data</td></tr><tr><td>PODS</td><td><strong>B</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE227&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/pods/" target="_blank" rel="noopener">DBLP</a></td><td>SIGMOD Conf. on Principles of DB Systems</td></tr><tr><td>SoCC</td><td><strong>B</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE227&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/cloud/" target="_blank" rel="noopener">DBLP</a></td><td>Symposium on Cloud Computing</td></tr><tr><td>VLDB Endowment</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/pub.cfm?id=J1174&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/vldb/" target="_blank" rel="noopener">DBLP</a></td><td>Int. Conf. on Very Large Data Bases</td></tr><tr><td>VLDB Journal</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/pub.cfm?id=J869&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/journals/vldb/" target="_blank" rel="noopener">DBLP</a></td><td>Int. Journal on Very Large Data Bases</td></tr><tr><td>NSDI</td><td><strong>B</strong></td><td><a href="https://www.usenix.org/conferences/byname/178" target="_blank" rel="noopener">USENIX</a> , <a href="https://dblp.org/db/conf/nsdi/" target="_blank" rel="noopener">DBLP</a></td><td>Network System Design and Implementation</td></tr><tr><td>SigComm</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE258&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/sigcomm/" target="_blank" rel="noopener">DBLP</a></td><td>The Conf. of the ACM Special Interest Group on Data Communication</td></tr><tr><td>ICAC</td><td></td><td><a href="https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1001178" target="_blank" rel="noopener">IEEE</a> , <a href="https://dblp.org/db/conf/icac/" target="_blank" rel="noopener">DBLP</a></td><td>IEEE Int. Conf. on Autonomic Computing</td></tr></tbody></table></div><p>体系结构中的 ASPLOS、ISCA、Micro、ATC、EuroSys、HPDC、LISA、SigMetrics、TC、TPDS等，及软工的OSDI、SOSP等也都有不少云计算相关的文章。<br>IEEE 云计算系列（CLOUD等）也可以看看。 <a href="http://cloudcomputing.ieee.org/conferences" target="_blank" rel="noopener">IEEE</a> , <a href="https://dblp.org/db/conf/IEEEcloud/" target="_blank" rel="noopener">DBLP</a><br>PS：从2017，2018年开始，CLOUD分裂成两拨人，在不同的地点开会，会议名字却一样，一拨的Paper是通过IEEE出版的，一拨则是Springer出版的。估计这种情况CCF列表里仅此一例吧。</p><h2 id="软件工程（偏程序分析）"><a href="#软件工程（偏程序分析）" class="headerlink" title="软件工程（偏程序分析）"></a>软件工程（偏程序分析）</h2><ul><li>Github上的<a href="https://github.com/tue-mdse/conferenceMetrics" target="_blank" rel="noopener">软件工程方向会议的数据</a></li><li>UIUC的<a href="http://taoxie.cs.illinois.edu/" target="_blank" rel="noopener">谢涛老师</a>维护的<a href="http://taoxie.cs.illinois.edu/seconferences.htm" target="_blank" rel="noopener">软件工程方向的会议统计列表</a> </li></ul><div class="table-container"><table><thead><tr><th>缩写</th><th>CCF级别</th><th>链接</th><th>全称</th></tr></thead><tbody><tr><td>ASE</td><td><strong>A</strong></td><td><a href="https://dblp.org/db/conf/kbse/" target="_blank" rel="noopener">DBLP</a></td><td>Int. Conf. on Automated Software Engineering</td></tr><tr><td>FSE/ESEC</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE201&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/sigsoft/" target="_blank" rel="noopener">DBLP</a></td><td>Symposium on the Foundation of Software Engineering / European Softw. Eng. Conf.</td></tr><tr><td>ICSE</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE228&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/icse/" target="_blank" rel="noopener">DBLP</a></td><td>Int. Conf. on Software Engineering 另，FOSE会议：七年一届的展望</td></tr><tr><td>OOPSLA</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE181&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/oopsla/" target="_blank" rel="noopener">DBLP</a></td><td>Conf. on Object-Oriented Programming Systems, Languages, and Applications</td></tr><tr><td>OSDI</td><td><strong>A</strong></td><td><a href="https://www.usenix.org/conferences/byname/179" target="_blank" rel="noopener">USENIX</a> , <a href="https://dblp.org/db/conf/osdi/" target="_blank" rel="noopener">DBLP</a></td><td>USENIX Symposium on Operating Systems Design and Implementations，<strong>双数</strong> 年份召开</td></tr><tr><td>SOSP</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE208&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/sosp/" target="_blank" rel="noopener">DBLP</a></td><td>Symposium on Operating Systems Principles， <strong>单数</strong> 年份召开，另，<a href="http://sigops.org/sosp/sosp15/history/index.html" target="_blank" rel="noopener">SOSP 2015 History Day</a></td></tr><tr><td>PLDI</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE200&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/pldi/" target="_blank" rel="noopener">DBLP</a></td><td>SIGPLAN Symposium on Programming Language Design and Implementation</td></tr><tr><td>POPL</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE180&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/popl/" target="_blank" rel="noopener">DBLP</a></td><td>SIGPLAN&amp;SIGACT Symposium on Principles of Programming Languages</td></tr><tr><td>ECOOP</td><td><strong>B</strong></td><td><a href="http://www.ecoop.org/" target="_blank" rel="noopener">ECOOP</a> , <a href="https://dblp.org/db/conf/ecoop/" target="_blank" rel="noopener">DBLP</a></td><td>European Conf. on Object-Oriented Programming</td></tr><tr><td>HotOS</td><td><strong>B</strong></td><td><a href="https://www.usenix.org/conferences/byname/155" target="_blank" rel="noopener">USENIX</a> , <a href="https://dblp.org/db/conf/hotos/" target="_blank" rel="noopener">DBLP</a></td><td>USENIX Workshop on Hot Topics in Operating Systems</td></tr><tr><td>ICSME</td><td><strong>B</strong></td><td><a href="http://conferences.computer.org/icsm/" target="_blank" rel="noopener">IEEE</a> , <a href="https://dblp.org/db/conf/icsm/" target="_blank" rel="noopener">DBLP</a></td><td>Int. Conf. on Software Maintenance</td></tr><tr><td>ISSTA</td><td><strong>B</strong></td><td><a href="http://dl.acm.org/event.cfm?id=RE222&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/conf/issta/" target="_blank" rel="noopener">DBLP</a></td><td>Int. Symposium on Software Testing and Analysis</td></tr><tr><td>TOPLAS</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/pub.cfm?id=J783&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/journals/toplas/" target="_blank" rel="noopener">DBLP</a></td><td>Trans. on Programming Languages and Systems</td></tr><tr><td>TOSEM</td><td><strong>A</strong></td><td><a href="http://dl.acm.org/pub.cfm?id=J790&amp;tab=pubs" target="_blank" rel="noopener">ACM</a> , <a href="https://dblp.org/db/journals/tosem/" target="_blank" rel="noopener">DBLP</a></td><td>Trans. on Software Engineering Methodology</td></tr><tr><td>TSE</td><td><strong>A</strong></td><td><a href="https://www.computer.org/web/tse" target="_blank" rel="noopener">IEEE</a> , <a href="https://dblp.org/db/journals/tse/" target="_blank" rel="noopener">DBLP</a></td><td>Trans. on Software Engineering</td></tr><tr><td>SPE</td><td><strong>B</strong></td><td><a href="http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1097-024X" target="_blank" rel="external">Wiley</a>, <a href="https://dblp.org/db/journals/spe/" target="_blank" rel="noopener">DBLP</a></td><td>Software - Practice and Experience</td></tr></tbody></table></div><h2 id="ACM-DL列表"><a href="#ACM-DL列表" class="headerlink" title="ACM DL列表"></a>ACM DL列表</h2><ul><li><a href="http://dl.acm.org/contents_dl.cfm" target="_blank" rel="noopener">收录会议和期刊的完整列表</a></li><li><a href="http://dl.acm.org/events.cfm" target="_blank" rel="noopener">会议</a></li><li><a href="http://dl.acm.org/proceedings.cfm" target="_blank" rel="noopener">会议历次论文集</a></li><li><a href="http://dl.acm.org/pubs.cfm" target="_blank" rel="noopener">期刊和学报</a></li><li><a href="http://dl.acm.org/mags.cfm" target="_blank" rel="noopener">杂志</a></li><li><a href="http://dl.acm.org/conferences.cfm" target="_blank" rel="noopener">ACM Conferences - past 12 months</a></li><li><a href="http://dl.acm.org/UpcomingConfLocations.xml" target="_blank" rel="noopener">ACM Upcoming Conferences - RSS</a></li></ul><p>关于ACM的杂志，特别推荐</p><ul><li><a href="http://dl.acm.org/citation.cfm?id=J79" target="_blank" rel="noopener">Communications of the ACM, CACM</a>， <a href="https://dblp.org/db/journals/cacm/" target="_blank" rel="noopener">in dblp</a></li><li><a href="http://dl.acm.org/toco_arch.cfm?id=J79&amp;lang=chinese" target="_blank" rel="noopener">CACM中国版</a>，CCF曾经 选译 一部分CACM文章为CACM中国版，但2016年后没有继续下去</li><li><a href="http://dl.acm.org/citation.cfm?id=J882" target="_blank" rel="noopener">Queue</a>也值得一看，有一些文章会同时发表在CACM的Research for Practice栏目</li></ul><p>期刊中，推荐<a href="http://dl.acm.org/citation.cfm?id=J204" target="_blank" rel="noopener">ACM Computing Surveys, CSUR</a>， <a href="https://dblp.org/db/journals/csur/" target="_blank" rel="noopener">in dblp</a></p><blockquote><p>看了ACM DL的列表页面，应该能体会到：1000项以内的列表还是不要分页的好。</p></blockquote><h2 id="IEEE-Computer列表"><a href="#IEEE-Computer列表" class="headerlink" title="IEEE Computer列表"></a>IEEE Computer列表</h2><ul><li><a href="https://www.computer.org/web/conferences/calendar/" target="_blank" rel="noopener">会议日历</a></li><li><a href="https://www.computer.org/web/publications/transactions" target="_blank" rel="noopener">期刊和学报</a></li><li><a href="https://www.computer.org/web/publications/magazines" target="_blank" rel="noopener">杂志</a></li></ul><h2 id="USENIX组织的会议列表"><a href="#USENIX组织的会议列表" class="headerlink" title="USENIX组织的会议列表"></a><a href="https://www.usenix.org/conferences/byname" target="_blank" rel="noopener">USENIX组织的会议列表</a></h2><p><a href="https://www.usenix.org/conferences/byname" target="_blank" rel="noopener">USENIX组织的会议列表</a>，其中包括ATC，FAST，LISA，MobiSys，NSDI，OSDI，VEE及HotCloud，HotOS等一系列 HotXXXX 的Workshop。</p><h2 id="国内三个学报"><a href="#国内三个学报" class="headerlink" title="国内三个学报"></a>国内三个学报</h2><ul><li><a href="http://www.jos.org.cn/ch/index.aspx" target="_blank" rel="noopener">软件学报</a>，<a href="http://rss.cnki.net/KNS/rss.aspx?journal=RJXB&amp;Virtual=KNS" target="_blank" rel="noopener">CNKI RSS</a></li><li><a href="http://cjc.ict.ac.cn/" target="_blank" rel="noopener">计算机学报</a>，<a href="http://rss.cnki.net/KNS/rss.aspx?journal=JSJX&amp;Virtual=KNS" target="_blank" rel="noopener">CNKI RSS</a></li><li><a href="http://crad.ict.ac.cn/CN/volumn/home.shtml" target="_blank" rel="noopener">计算机研究与发展</a> ，<a href="http://rss.cnki.net/KNS/rss.aspx?journal=JFYZ&amp;Virtual=KNS" target="_blank" rel="noopener">CNKI RSS</a></li></ul><h2 id="国内论文数据库"><a href="#国内论文数据库" class="headerlink" title="国内论文数据库"></a>国内论文数据库</h2><ul><li><a href="http://www.cnki.net/" target="_blank" rel="noopener">知网CNKI</a></li><li><a href="http://www.wanfangdata.com.cn/" target="_blank" rel="noopener">万方数据</a></li></ul><h2 id="谢涛老师的指导建议"><a href="#谢涛老师的指导建议" class="headerlink" title="谢涛老师的指导建议"></a>谢涛老师的指导建议</h2><ul><li><a href="http://taoxie.cs.illinois.edu/publications/writepapers.pdf" target="_blank" rel="noopener">Advice on Writing Research Papers - Tao Xie - PDF</a></li><li><a href="http://taoxie.cs.illinois.edu/adviceonresearch.html" target="_blank" rel="noopener">Advice on Getting a Start into Research</a></li></ul><h2 id="软件工程学科知识体系"><a href="#软件工程学科知识体系" class="headerlink" title="软件工程学科知识体系"></a>软件工程学科知识体系</h2><p>软件工程学科知识体系 Software Engineering Body of Knowledge, SWEBoK - ISO/IEC TR 19759:2005</p><ul><li><a href="https://en.wikipedia.org/wiki/Software_Engineering_Body_of_Knowledge" target="_blank" rel="noopener">Wikipedia 页</a> </li><li><a href="https://www.computer.org/education/bodies-of-knowledge/software-engineering" target="_blank" rel="noopener">IEEE Computer 学会</a></li><li><a href="/doc/SWEBoKv3.pdf">PDF 全文</a> （其实手册都挺枯燥的）</li></ul><h2 id="其它链接"><a href="#其它链接" class="headerlink" title="其它链接"></a>其它链接</h2><ul><li><a href="https://blog.acolyer.org/" target="_blank" rel="noopener">The morning paper</a>, an interesting-influential-important paper from the world of CS every weekday morning</li><li><a href="http://sites.computer.org/debull/bull_issues.html" target="_blank" rel="noopener">IEEE Technical Committee on Data Engineering</a></li><li><strong><a href="http://www1.cs.columbia.edu/~kaiser/relatedwork.htm" target="_blank" rel="noopener">Suggested Guidelines for Finding Materials to include in the “Related Work” Sections of Conference Papers</a></strong></li><li><a href="http://www.yocsef.org.cn/sites/yocweb/yocltzw.jsp?contentId=2658502145582" target="_blank" rel="noopener">YOCSEF专题论坛：从LNCS事件反思中国学术论文的发表</a>  </li></ul><h1 id="如何读论文"><a href="#如何读论文" class="headerlink" title="如何读论文"></a>如何读论文</h1><ul><li><a href="http://www.cs.columbia.edu/~hgs/netbib/efficientReading.pdf" target="_blank" rel="noopener">Efficient Reading of Papers in Science and Technology(pdf)</a></li><li><a href="http://blizzard.cs.uwaterloo.ca/keshav/home/Papers/data/07/paper-reading.pdf" target="_blank" rel="noopener">How to Read a Paper(pdf)</a></li><li><a href="https://www.cs.jhu.edu/~jason/advice/how-to-read-a-paper.html" target="_blank" rel="noopener">How to Read a Technical Paper</a></li><li><a href="http://item.jd.com/11127141.html" target="_blank" rel="noopener">《学术研究 - 你的成功之道》第3章</a></li></ul><h1 id="如何写论文"><a href="#如何写论文" class="headerlink" title="如何写论文"></a>如何写论文</h1><ul><li><a href="https://www.bilibili.com/video/av12841463/" target="_blank" rel="noopener">How to Write a Great Research Paper - Simon Peyton Jones - B站视频</a>, <a href="https://www.youtube.com/watch?v=VK51E3gHENc" target="_blank" rel="noopener">YouTube 原版</a></li></ul><h1 id="Todo-辅助工具"><a href="#Todo-辅助工具" class="headerlink" title="[Todo]辅助工具"></a>[Todo]辅助工具</h1><ul><li><a href="http://myhuiban.com" target="_blank" rel="noopener">会伴</a></li><li>Trans. on BigData的学术文献处理专刊 <a href="https://www.computer.org/csdl/trans/bd/2016/01/index.html" target="_blank" rel="noopener">Vol. 2 Issue 1</a>，<a href="https://www.computer.org/csdl/trans/bd/2016/02/index.html" target="_blank" rel="noopener">Vol. 2 Issue 2</a></li><li><a href="http://www.sciplore.org/" target="_blank" rel="noopener">Sciplore</a></li><li><a href="https://www.scopus.com/" target="_blank" rel="noopener">Scopus</a></li><li><a href="http://www.docear.org/" target="_blank" rel="noopener">Docear</a></li><li><a href="https://www.mendeley.com/" target="_blank" rel="noopener">Mendeley</a></li><li><a href="https://www.zotero.org/" target="_blank" rel="noopener">Zotero</a></li><li><a href="https://www.teambition.com/" target="_blank" rel="noopener">Teambition</a></li><li>Todo，如何整理文献，如何管理时间，<a href="https://www.zhihu.com/question/27956707" target="_blank" rel="noopener">科研小组里有哪些有效的组会形式 - 知乎</a></li></ul><blockquote><p>如果所在的实验室 <strong>没有什么积累</strong>，暂时没有好的idea/topic，不妨去浏览一下感兴趣的大方向的A类会议近三年或五年的文章列表，<strong>总会觉得</strong> 有几篇比其它文章更有意思，这就把范围缩小一些了；然后再从这几篇文章里提炼出关键词，去<a href="https://en.wikipedia.org/" target="_blank" rel="noopener">wikipedia</a>上搜索一下这个关键词，再从Related Work再扩展出去，体验一下这个细分领域涉及的问题。找出来这个细分领域里发文章比较多的作者和研究小组（实验室），去作者和小组的主页看看。这个前期工作其实花不了一周的时间，然后收集了一些相关的论文，粗览一遍，筛选出几篇或十几篇值得仔细研读的。<br>我们不妨通过相关论文的数量来定义一个细分的领域，比如武断地说，100篇或150篇。这个具体的数量不是关键，但一个领域能发的文章必定是有限的，太多的话说明问题太复杂，还要细分，太少的话，如果不是幸运地发现了新的方向，就是问题太 Trivial 了。而这其中，又只有几篇或十几篇是开创性的，值得非常仔细地研读的。<br>如果读完核心的几篇文章后还是没有新的想法，那就只好重复上面的过程，重新寻找另外感兴趣的领域了。<br>PS，<strong>相比上面列出来一堆链接，其实这几句话才是这篇文章的重点啊 ;-)</strong></p></blockquote><p>一些标题有<code>A systematic review on ...</code>综述文章，其中会介绍收集相关论文的过程，方法都类似，可以找一篇当作论文搜集方法的教程来看。</p><p>再列出知乎上的几个相关问题吧</p><ul><li><a href="https://www.zhihu.com/question/26901116" target="_blank" rel="noopener">如何总结和整理学术文献？</a></li><li><a href="https://www.zhihu.com/question/26857521" target="_blank" rel="noopener">如何高效管理文献？</a></li><li><a href="https://www.zhihu.com/question/22790506" target="_blank" rel="noopener">如何写好一篇高质量的IEEE/ACM Transaction级别的计算机科学论文?</a></li></ul><p><a name="hosts"></></a></p><h1 id="Bonus-如何访问Google-Scholar"><a href="#Bonus-如何访问Google-Scholar" class="headerlink" title="[Bonus] 如何访问Google Scholar"></a>[Bonus] 如何访问Google Scholar</h1><h2 id="改hosts"><a href="#改hosts" class="headerlink" title="改hosts"></a>改hosts</h2><ul><li>IP v4， <a href="https://raw.githubusercontent.com/googlehosts/hosts/master/hosts-files/hosts" target="_blank" rel="noopener">https://raw.githubusercontent.com/googlehosts/hosts/master/hosts-files/hosts</a>  或短网址 <a href="https://git.io/v5rKk" target="_blank" rel="noopener">https://git.io/v5rKk</a></li><li>IP v6， <a href="https://raw.githubusercontent.com/lennylxx/ipv6-hosts/master/host" target="_blank" rel="noopener">https://raw.githubusercontent.com/lennylxx/ipv6-hosts/master/host</a> 或短网址 <a href="https://git.io/vMjCk" target="_blank" rel="noopener">https://git.io/vMjCk</a></li></ul><h2 id="hosts文件的路径"><a href="#hosts文件的路径" class="headerlink" title="hosts文件的路径"></a>hosts文件的路径</h2><ul><li>Windows：<code>C:\Windows\System32\drivers\etc\hosts</code></li><li>Linux，Mac，Android（均需要root权限）：<code>/etc/hosts</code></li></ul><h1 id="PS"><a href="#PS" class="headerlink" title="PS:"></a>PS:</h1><ul><li><a href="http://karpathy.github.io/2016/09/07/phd/" target="_blank" rel="noopener">A Survival Guide to a PhD</a></li><li><a href="http://pgbovine.net/PhD-memoir.htm" target="_blank" rel="noopener">PhD Grind</a>，中文译文<a href="https://read.douban.com/reader/ebook/6056669/" target="_blank" rel="noopener">研磨记 - 豆瓣阅读</a>，<a href="https://github.com/qipeng/phd-grind-chn/" target="_blank" rel="noopener">博士研磨</a></li></ul><hr><p>飞鸟集</p><blockquote><p>第83<br>那想做好人的，在门外敲着门，那爱人的，看见门敞开着。</p><p>第142<br>让我设想，在群星之中，有一颗星是指导着我的生命通过不可知的黑暗的。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;论文（Paper）是每个研究生读研路上挥之不去的“阴云”。&lt;br&gt;无论是否已经有了一个好的课题或想法，都首先要收集某个研究方向一定数量的论文，来了解相关的工作和最新进展（State of the art &amp;amp; practice）。&lt;br&gt;本文介绍了如何检索、收集计算机科学（CS）专业的论文，还介绍了相关的机构，学术会议和论文数据库。&lt;br&gt;文末有 &lt;a href=&quot;#hosts&quot;&gt;&lt;strong&gt;Bonus&lt;/strong&gt;&lt;/a&gt; 哦;-)&lt;/p&gt;
    
    </summary>
    
      <category term="misc" scheme="https://ying-zhang.github.io/categories/misc/"/>
    
    
  </entry>
  
  <entry>
    <title>虚拟机及docker的存储，快照和镜像</title>
    <link href="https://ying-zhang.github.io/cloud/2016/vm-disk/"/>
    <id>https://ying-zhang.github.io/cloud/2016/vm-disk/</id>
    <published>2016-09-23T16:00:00.000Z</published>
    <updated>2018-06-03T15:09:17.077Z</updated>
    
    <content type="html"><![CDATA[<p>VM的虚拟硬盘让我们能够把整个操作系统和应用软件、配置、数据都 <strong>封装</strong> 在一个（或多个）文件里，这样就实现了VM的迁移，再加上 <strong>差分硬盘</strong> 功能，实现了VM的快速克隆和快照。对VM镜像管理的需求也就随之而来了。</p><a id="more"></a><hr><h1 id="虚拟硬盘"><a href="#虚拟硬盘" class="headerlink" title="虚拟硬盘"></a>虚拟硬盘</h1><p>硬盘被称为 <strong>块设备</strong>，传统的机械硬盘最小的读写单元是一个扇区（sector），而文件系统（FS）在引入了逻辑存储块（block），可能与物理扇区大小相同，也可以是扇区的整数倍。一个文件对应了若干block，多个文件又以文件夹的形式组成一棵树，这是FS的两层结构。</p><p>虚拟硬盘只需要模拟出扇区结构就可以了，上层的逻辑块和文件树由VM里的Guest OS来负责。可以简单地创建一个空白的大文件（raw格式）来作为Guest OS的虚拟硬盘，Guest OS再将其格式化为某种FS。<br>虚拟硬盘在Host上是一个文件（vhd）或若干个相关的文件（vmdk），而其中又有Guest OS创建的文件。</p><p>下面是几种VMM的虚拟硬盘格式。</p><div class="table-container"><table><thead><tr><th>VMM</th><th>虚拟硬盘格式</th><th>备注</th></tr></thead><tbody><tr><td>VirtualBox</td><td><strong>vdi</strong> , virtual disk image</td><td>还支持vmdk，vhd，qcow等多种格式</td></tr><tr><td>VMware</td><td><strong>vmdk</strong> , vm disk</td><td>vmdk有单文件和多文件2种方式</td></tr><tr><td>Hyper-V</td><td><strong>vhd</strong> / <strong>vhdx</strong>, virutal hard disk</td><td></td></tr><tr><td>KVM</td><td><strong>qcow</strong>, qemu copy on write</td><td>还支持vmdk，raw格式</td></tr></tbody></table></div><p>各种虚拟硬盘格式大同小异，其中<a href="https://en.wikipedia.org/wiki/VHD_&#40;file_format&#41;" target="_blank" rel="noopener">vhd格式</a>不仅在vbox和hyper-v中得到支持，Windows7及以后版本的Windows系统中也内置了对它支持，所以用vbox创建VM建议选择vhd格式。Win7及以后的版本内置的<code>diskpart</code>工具（下面会介绍）可以创建vhd的差分镜像，Win8及以后版本可以通过双击挂载vhd镜像。如果vhd镜像的分区是windows支持的NTFS等格式，就可以在不用启动VM的情况下直接读写vhd，这就像把一台机器（VM）的硬盘拆下来拿到其它机器（Host）读写，然后再装回去。</p><p>VMM为了管理虚拟硬盘，还会在虚拟硬盘文件中增加一些元数据信息，比如作为硬盘唯一标识的GUID。在vbox中，如果直接复制一个虚拟硬盘镜像挂载到其它的VM，就会报告已经存在了相同GUID的虚拟硬盘。<br>重置一个虚拟硬盘GUID可以执行下面的命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">VBoxManage internalcommands sethduuid &quot;/path/file.vhd&quot;</span><br></pre></td></tr></table></figure><blockquote><p>vbox支持多种虚拟硬盘格式，使用<code>VBoxManage.exe</code>这个命令行工具还可以进行不同虚拟硬盘格式之间的转换，启停VM等很多操作。<br>VMware可以将物理硬盘转换为虚拟硬盘，这样实际上是把一个物理机器（部分地）克隆到了VM（PM-&gt;VM）。<br>VMware还可以将一个物理硬盘分区直接加载给VM，这样会稍许提高一下访问硬盘的性能。</p></blockquote><p>虚拟硬盘有固定和动态大小两种：</p><ul><li>前者直接分配了全部硬盘空间，创建的时候会比较费时，而且通常会有大部分硬盘空间是空闲的，优势是所需空间已经预先分配好了，访问性能会好一些；</li><li>而动态大小的虚拟硬盘在创建时是一个很小的文件，只有基本的信息。随着Guest OS使用硬盘，才会逐渐自动扩展，这样能极大节约硬盘空间，但动态分配会降低性能。要注意扩展是自动的，一旦扩展就不会收缩回去，哪怕Guest OS格式化了虚拟硬盘。</li></ul><h1 id="部署和迁移"><a href="#部署和迁移" class="headerlink" title="部署和迁移"></a>部署和迁移</h1><p>在VM出现之前，要想批量地安装OS，也就是部署OS的问题，有两种常用的方法</p><ul><li>使用OS本身支持的<code>应答文件</code></li><li>比较常用的方法就是先在一台机器上安装好系统、驱动、应用软件，修改一些配置，然后用ghost克隆操作系统的分区到一个.gho镜像（所谓的基准镜像golden image），然后分别拷贝这个.gho到其它机器上，启动到pe环境，再从.gho镜像恢复系统；也可以从局域网的某个ghost server服务器上获取.gho镜像来恢复系统。gho系统镜像一般有几个GB，就算自动安装的话也要十几分钟。<br>这两种方法效率上相差不多。</li></ul><p>VM将整个OS放在一个虚拟硬盘文件里，在加上一个很小的VM配置文件（比如xml格式的.vbox文件）就是一个完整的计算机了，而且是统一的虚拟设备驱动，把这些文件拷贝到另一个Host上就可以得到一个新的VM。虽然一个虚拟硬盘文件也有几个GB，但只需要拷贝过去，节省了ghost从镜像恢复这一步，还是方便一些的。不足之处是虚拟化带来的一些性能开销，随着硬件对虚拟化的支持，这些开销已经很小了。</p><p>基于虚拟硬盘实现的VM的封装性是虚拟化技术一个很重要的特性，这样就实现了VM的（离线）迁移。在此基础上，还开发出了VMM的 <strong>在线</strong> 迁移技术，就是在VM不停机的情况下迁移到其它Host上。在线迁移跟离线迁移一样需要拷贝虚拟硬盘文件，区别是在线迁移还要拷贝运行时刻的内存，一般有若干GB，经过网络传输比较耗时，所以内存迁移需要几次迭代才能完成。</p><p>VM的迁移虽然是一个可以提高VM可用性的功能，但毕竟虚拟硬盘还是太大了，传统上除了视频文件，网络上很少有这种大流量传输的需求。VM迁移对已有网络的承受能力是一个考验。还有一个问题是很多虚拟硬盘中的数据都是重复的，占用了大量的存储空间。为了解决这些问题，就出现了下面的差分硬盘功能。</p><h1 id="差分硬盘"><a href="#差分硬盘" class="headerlink" title="差分硬盘"></a>差分硬盘</h1><p>虽然可以预先制作一个标准VM镜像，然后批量拷贝得到很多VM，但VM运行后会在虚拟硬盘中写入不同的数据，所以每个VM的虚拟硬盘内的数据都是不同的，迁移时必须要分别拷贝。即便是给VM添加两个虚拟硬盘，一个OS（系统盘），另一个空白硬盘专门保存用户数据（数据盘），还是难以避免Guest OS在系统盘修改文件数据。</p><p>差分硬盘的思路类似内存管理中的copy on write (COW) 技术。基于父虚拟硬盘创建一个差分硬盘（子盘），VM挂载子盘后，看上去跟父盘完全一样，只是后续增删的数据都是保存在子盘上的。</p><p>子盘还可以再继续创建差分盘（孙盘），这样子子孙孙 <strong>纵向</strong> 延续下去。比如vhd可以支持创建127代，而且 <strong>每代差分硬盘的性能基本一致，不受代数层次的影响</strong>。另外，一个父盘还可以有多个子盘，也就是 <strong>横向</strong> 扩展，同一个父盘下面生成子盘的个数没有限制，因为父子关系信息，即父盘的位置和GUID，只保存在子盘里。横向和纵向的差分盘可能形成一棵树。下面就是VMware的快照管理器截图（快照实际上包括虚拟硬盘快照和VM配置快照两部分，显然硬盘快照是占大头的部分）。<img src="/img/vmware-snapshot.png" alt=""></p><p>差分硬盘相比普通虚拟硬盘在性能上会有一点损失，但给运维带来的便利是很大的。微软有一个关于vhd在windows server 2008和2008 R2多种应用场景下的<a href="http://go.microsoft.com/fwlink/p/?LinkId=186519" target="_blank" rel="noopener">性能测试的文档</a>，包括物理硬盘 vs 固定分配的vhd vs 动态分配的vhd vs 差分vhd。结果是动态分配的vhd性能下降比较明显，固定分配的vhd和差分vhd的性能都接近物理硬盘。</p><p>创建一个差分硬盘基本不到1秒钟，于是就可以实现秒级创建/克隆/离线迁移VM，秒级创建快照，克隆是针对多个VM，而快照是针对某一个VM的。<br>理论上来说，所有VM公用的父虚拟硬盘可以只保存一个，会减少很多原来虚拟硬盘占用的实际存储空间，当然这个父盘需要保存在可以远程访问的共享存储上，一般是samba/cifs或者NFS共享目录。</p><h1 id="快照和克隆"><a href="#快照和克隆" class="headerlink" title="快照和克隆"></a><strong>快照和克隆</strong></h1><p>上面截图是VMware的快照功能，可以创建出一棵快照树。VMware这个快照管理器中</p><blockquote><p>“删除”：会将选中快照对应的虚拟硬盘数据 <strong>合并</strong> 到它的差分子盘上，然后删除该差分盘。<strong>不会改变</strong> VM的当前状态，只是删除了选中层次的差分硬盘。合并差分盘是一个比较耗时的操作。要求当前的虚拟硬盘只有一个子盘才能合并。<br>“转到”：将当前位置恢复到选中的快照。</p></blockquote><p>vbox的也有类似的快照功能，不过用起来不太直观。</p><p><img src="/img/vbox-snapshot.png" alt="vbox快照"></p><blockquote><p>注：快照工具栏中的按钮分别是<br><code>快照</code>：只能对“当前状态”生成快照，实际是以“当前状态”的虚拟硬盘为父盘，创建一个差分盘，并将VM的虚拟硬盘设置为这个差分盘，即作为新的“当前状态”。<br><code>恢复</code>：基于选择快照的虚拟硬盘创建一个新的差分盘，并将VM的虚拟硬盘设置为这个差分盘，即作为新的“当前状态”。需要在VM停机状态下才能执行“恢复”操作<br><code>删除</code>：这个功能和VMware的“删除”一样。注意这个功能跟“恢复”的区别，我经常想恢复VM，结果搞不清这两个功能，选择了删除，不但耗时，还把中间的快照层次给弄丢了，相当于版本库中丢失了中间某个版本，虽然对当前版本没有影响，但还是丢掉了一些数据的。创建快照是为了尽可能快速恢复，快照越多，恢复的粒度就越细，重用的VM操作/数据就越多，当然管理起来会增加点工作量，通常情况是没有必要合并快照的，因此这个功能是不太常用的，而且称为 <strong>“合并快照”</strong> 比 <strong>删除快照</strong> 更合适些。<br><code>明细</code>：查看创建快照时写的备注和VM的参数变化。<br><code>克隆</code>：基于当前的VM克隆一个新的VM，既可以选择使用差分硬盘方式（连接），也可以使用传统的复制整个虚拟硬盘。</p></blockquote><h1 id="镜像管理"><a href="#镜像管理" class="headerlink" title="镜像管理"></a>镜像管理</h1><p>“镜像”现在有了两层含义，一个是前面一直说的虚拟硬盘，可以在VM运行中修改从而发生变化，一个是作为基准模板的VM，其中最重要的文件是差分硬盘的父盘。<br>所谓基准模板，或基准镜像 golden image ，与普通的VM并没有什么本质的区别，只是被标识了一个特别的身份而已，最多就是把相关的文件（配置，虚拟硬盘等）都打包在一起。</p><p>随之而来的是基准镜像的管理问题，因为基准镜像也不是一成不变的，其中的软件或者用户应用/数据可能需要更新，这一般都是通过在VM里执行系统维护命令来实现的。基准镜像也不只有一个，为了减少重复操作，应该为常见的功能特征都创建好基准镜像，甚至实现开箱可用的目标。镜像管理要给镜像关联尽可能详细的描述信息，让开发人员方便地找的合适的镜像，避免发明轮子。从基础镜像出发，相当于IaaS的模式，而从一个安装和配置了特定功能的镜像开始，则相当于提升到PaaS的层次了。</p><p>Openstack 中的Glance模块是镜像管理模块，vagrant使用的.box也算是一种简单的镜像管理方案，但与docker的镜像管理功能相比还有一定的差距。</p><h1 id="docker的镜像，容器"><a href="#docker的镜像，容器" class="headerlink" title="docker的镜像，容器"></a>docker的镜像，容器</h1><p>docker一开始就通过公共镜像仓库docker hub和私有仓库docker registery，以及<code>build</code>，<code>pull</code>，<code>push</code>命令内置了镜像管理功能。</p><p>docker为实现镜像管理采用了类似于差分硬盘的<a href="http://coolshell.cn/articles/17061.html" target="_blank" rel="noopener">aufs文件系统</a>。aufs是一个虚拟文件系统，是在某个实际的底层文件系统上重新组织的虚拟文件视图，aufs并不处理底层的硬盘数据块，只是把多个主机上已经存在的不同目录分层次挂载到同一个虚拟的目录下，上层会覆盖下层的同名文件，不同名的文件则会相安无事，这样每个层就类似于差分硬盘的一个子盘。然而aufs是在文件层次实现的，而VM的差分硬盘则是在更底层的数据块层实现的。<br>docker基于镜像创建容器container，容器类似于虚拟机实例，有创建、启动、运行、暂停、停止的生命周期。镜像的层是只读的，容器会重用这些层，然后在最上面新创建一个可读写的层。<br>通过<code>docker commit</code>命令，可以将容器固化成镜像。<br><a name="docker-image"></a><br>docker的镜像管理还有一些不足：</p><ul><li>虽然docker会管理单个Host下的镜像，利用graph功能重用已有的镜像层，但每个Host还是有重复的镜像拷贝。虚拟机为了实现在线迁移，要求VM镜像保存在一个共享目录，恰好实现了部分的去重效果。不过docker有私有的仓库，而且能跟共享目录结合起来就好了。<a href="https://www.usenix.org/node/194431" target="_blank" rel="noopener">FAST16 - Slacker: Fast Distribution with Lazy Docker Containers</a> 这篇文章为了加速Docker容器的启动速度，采用了集中的共享存储镜像仓库和惰性加载镜像的方式，只加载当前使用的镜像到本地，与我们的思路很相近了。另外，Docker镜像分层的结构还可以更精细，以提高重用的可能。</li><li>从dockerfile构造镜像时，每行<code>RUN</code>命令对应一层镜像，需要注意避免分层太多，而一个<code>RUN</code>命令太复杂又会限制了重用镜像的可能，如果能够 <strong>显示地指定分层点</strong> 可能会好些，这也算是镜像分层结构精细化的一部分。</li><li>从dockerfile构造镜像也不是完全可重现的，如果基于同一个dockerfile的2次构建相隔了比较长的时间，而dockerfile中又要从外部获取应用或数据，比如<code>apt</code>安装软件，有可能安装的软件版本就不同了，而且这还涉及到层的重用。docker目前已经通过计算镜像各层内文件的内容的Hash来唯一地确定该层，部分缓解了这一问题。</li></ul><p><code>docker run</code>命令基于镜像创建并运行一个容器。新手容易通过<code>docker run</code>创建很多临时的容器，占用过多物理硬盘空间，这需要在执行<code>docker run</code>命令时加上<code>--rm</code>参数，容器退出后就会被docker删除掉。</p><p>docker官方建议开发人员应尽量避免通过<code>docker exec</code>或<code>ssh</code>进入容器执行操作，而应通过dockerfile将所有操作<code>build</code>到镜像中。这样的好处是所有的操作都在dockerfile中，从而可以被版本管理系统跟踪。对VM的操作一般是经chef，puppet，ansible或salt这类自动化工具，在多个VM上批量执行的。自动化工具的问题是每个VM都需要重复执行，不同VM执行可能会产生错误或不同的结果，而dockerfile只要build一次，然后基于镜像创建容器即可，能更好的保证一致性，而且节约了重复执行的时间和网络流量（没有缓存的情况下）。<br>有人将VM比喻为宠物：一个Host只能支持若干个VM，所以开发人员都小心翼翼地像宠物一样对待VM；而一个Host可以支持多得多的容器，对待容器就像家畜一样，生死都不足惜。</p><p><a name="win-vhd-boot"></a></p><h1 id="Windows的diskpart工具"><a href="#Windows的diskpart工具" class="headerlink" title="Windows的diskpart工具"></a><strong>Windows的diskpart工具</strong></h1><p>因为曾被vbox的“恢复”和“删除”搞晕，所以之前都是用windows的<code>diskpart</code>来创建差分硬盘，然后重新设置VM的硬盘，使用下面的命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\&gt;diskpart</span><br><span class="line"></span><br><span class="line">DISKPART&gt; create vdisk file=c:\diff.vhd parent=c:\parent.vhd</span><br></pre></td></tr></table></figure><h1 id="Windows从VHD启动实现极速快照和恢复"><a href="#Windows从VHD启动实现极速快照和恢复" class="headerlink" title="Windows从VHD启动实现极速快照和恢复"></a><strong>Windows从VHD启动实现极速快照和恢复</strong></h1><p>Windows对vhd的内置支持远不止创建，挂载。最大的特色是支持从vhd启动（vhd native boot）：就是说把windows系统安装到一个vhd中，向普通硬盘分区一样从这个vhd启动windows。</p><ul><li>一种做法是把windows安装文件写入vhd中，然后将其加入BCD启动项，重启后系统会安装vhd在内。</li><li>另一种做法比较费事，需要用安装盘中的维护工具，在命令行执行diskpart创建vhd，挂载并格式化，然后就可以像物理硬盘一样把系统装到vhd了。</li><li>还有一种做法，将已经安装在物理硬盘上的系统用ghost克隆到vhd上，这需要在另一个windows系统或PE下进行，然后添加这个vhd的启动项到BCD。</li></ul><p>vhd加上差分硬盘功能，就可以实现windows的快速恢复了。具体的一种做法是基于一个父vhd创建两个差分vhd，分别称为<code>Current.vhd</code>和<code>Recovery.vhd</code>，分别添加这两个差分vhd的启动项为 <strong>Current</strong> 和 <strong>Recovery</strong>，这样就相当于已经安装了两个windows系统。正常使用 <strong>Current</strong> 系统，需要恢复时重启到 <strong>Recovery</strong> 系统，删除原来的<code>Current.vhd</code>，然后再基于父vhd创建一个新的差分vhd并命名为<code>Current.vhd</code>，再重启到 <strong>Current</strong> 系统，就完成了系统恢复。其中Recovery系统不是必须的，因为只需要能够进行简单的文件操作，用一个PE系统代替也可以。</p><p>系统盘的文件布局如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:.</span><br><span class="line">│  Win8-Current.vhd    #正常工作系统</span><br><span class="line">│  Win8-Recovery.vhd   #恢复用系统</span><br><span class="line">│  Win8.vhd            #父vhd</span><br><span class="line">│  bootmgr             #启动管理器  </span><br><span class="line">└─boot                #系统启动相关文件</span><br><span class="line">        bcd</span><br><span class="line">        memtest.exe</span><br><span class="line">        ...</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p><code>bootice</code>是一个操作vhd和系统启动项的小工具。此外还有<code>EasyBCD</code>和一些PE工具。当然，可以直接使用Windows内置的命令行工具<code>bcdboot</code>和<code>bcdedit</code>。</p><p>Linux <strong>还没有</strong> 类似 vhd native boot的功能。虽然grub支持ramdisk或iso启动项，但功能上还是有些差距。<br>最近推出的CoreOS采用了双分区滚动升级的做法，实现了类似的功能，不过需要占用两倍的系统存储空间（没有差分），好在CoreOS本身比较精简。</p><p>前面提到可以将物理硬盘转换成虚拟硬盘，相当于实现了从物理机到虚拟机的转换 PM -&gt; VM；而 vhd native boot则相当于从 VM -&gt; PM。</p><hr><p>这个介绍数据中心的<a href="http://v.youku.com/v_show/id_XMTMyMTI1ODQ4NA==.html" target="_blank" rel="noopener">视频</a> 里面有一段关于替换故障硬盘的细节值得注意。服务器的CPU，内存，硬盘和网卡 这几个主要部件里，因为硬盘是机械部件，而且一直在运转，不像普通机器大部分时间关机或休眠，所以是最容易出故障的，换硬盘应该是数据中心的日常维护工作了。 即便升级成没有了机械转动部件的SSD，还是有写入寿命的限制。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;VM的虚拟硬盘让我们能够把整个操作系统和应用软件、配置、数据都 &lt;strong&gt;封装&lt;/strong&gt; 在一个（或多个）文件里，这样就实现了VM的迁移，再加上 &lt;strong&gt;差分硬盘&lt;/strong&gt; 功能，实现了VM的快速克隆和快照。对VM镜像管理的需求也就随之而来了。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://ying-zhang.github.io/categories/cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>再说docker及云中的网络连接</title>
    <link href="https://ying-zhang.github.io/cloud/2016/vm-net-2/"/>
    <id>https://ying-zhang.github.io/cloud/2016/vm-net-2/</id>
    <published>2016-09-20T16:00:00.000Z</published>
    <updated>2018-06-03T15:09:19.458Z</updated>
    
    <content type="html"><![CDATA[<p>之前写过一篇<a href="https://ying-zhang.github.io/cloud/2016/vm-net/">关于虚拟机和docker网络的日志</a>，主要介绍的是VM的虚拟网络，顺带提了一下docker的桥接。<br>经过2016年的几次版本升级，docker的网络功能有了很大的改善，已经基本稳定可用了。<br>去年<a href="https://github.com/NAP-GHJ/NetTool/blob/master/blog/%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.md" target="_blank" rel="noopener">与一个大四做毕设的学弟折腾过一段时间docker网络</a>，这里参考浙大SEL实验室的《Docker容器与容器云 第2版》（下面简称《容器云》书） <strong>4.2节 Docker高级网络实战</strong> ，整理一下相关内容。</p><a id="more"></a><hr><h1 id="再说Docker桥接模式，路由器，NAT，交换机"><a href="#再说Docker桥接模式，路由器，NAT，交换机" class="headerlink" title="再说Docker桥接模式，路由器，NAT，交换机"></a>再说Docker桥接模式，路由器，NAT，交换机</h1><p><a href="https://ying-zhang.github.io/cloud/2016/vm-net/index.html#docker-bridge">上篇日志提到Docker的桥接模式（bridge）实际上是NAT方式</a>，也给了两个设置Docker“名副其实”的bridge模式的链接，这点在《容器云》的 “4.2.2 pipework 原理解析：1. 将Docker配置到本地网络环境中” 一节也提到了。<br>实际为NAT的docker bridge模式和类似VM的bridge模式都是用到了Linux bridge虚拟网桥。这个虚拟设备其实既是一个 <strong>虚拟路由器</strong>，也是一个 <strong>虚拟交换机</strong>，因为（家用）路由器的一侧就包括了一个交换机。<br>参考下图。<br><img src="/img/wifi-router.png" alt="家用无线路由器拓扑"></p><ul><li>如果把墙上的网口用网线接到路由器的 <strong>WAN口</strong>，把家里的PC，手机等接到路由器的 <strong>有线LAN口</strong> 或 <strong>wifi</strong>，这是路由器的正常工作模式，即 <strong>NAT模式</strong>，类似于 <strong>docker的bridge模式</strong>。</li><li>如果稍稍开一下脑洞，把网线接到 <strong>有线LAN口中的任意一个</strong>，留着WAN口什么也不接，这时PC，手机等设备还是能连到网络上的！这时只用了路由器的LAN一侧，只工作在 <strong>交换机</strong> 模式，这类似于 <strong>VM的bridge模式</strong>。其实交换机的功能就是把一个网络端口变成多个网络端口。</li></ul><h1 id="Docker跨主机的网络"><a href="#Docker跨主机的网络" class="headerlink" title="Docker跨主机的网络"></a>Docker跨主机的网络</h1><p>上面强调docker的bridge模式名不副实，其实是因为docker早期版本缺少跨主机的网络功能，造成了诸多不便。在“传统的”VM技术中，是使用bridge模式来实现不同物理主机上VM直接联网的，即将VM网络接入到主机网络环境中。docker虽然用了同样的称呼，但没有提供同样的功能，除了端口映射和host模式，没有办法方便地将不同物理主机上的容器互相连通，让docker的用户非常痛苦。<br>多个第三方工具，比如pipework、weave、socketplane、flannel，calico等都是为了实现docker的跨主机网络。最终，在docker 1.9，docker提供了内置的Overlay网络模式。</p><p>回顾一下docker支持的网络模式 <a href="https://docs.docker.com/engine/userguide/networking/" target="_blank" rel="noopener">https://docs.docker.com/engine/userguide/networking/</a> ：</p><ul><li>none：docker撒手不管，由用户或第三方工具提供网络功能，上节中pipework就是这样的工具；</li><li>host：直接使用主机的网络栈，即没有网络隔离；</li><li>bridge：NAT模式，容器可以使用主机的网络访问外部，但外部访问容器的应用需要做端口映射，即在<code>docker run</code>命令中提供<code>-p</code>参数</li><li>overlay, gwbridge：这是ver 1.9引入的覆盖网络，下面会单独介绍。</li></ul><blockquote><p>docker还有一种<code>container</code>模式，使用已有容器的网络。Kubernetes的Pod是依赖于这种网络模式的：一个Pod包括多个功能相关的容器，它们共用一个网络栈，是 <a href="https://github.com/kubernetes/kubernetes/tree/master/build/pause" target="_blank" rel="noopener"><strong>史上最小的docker镜像</strong> <code>pause</code> </a>创建的。<br>新版本（我使用的17.05.0-ce版）的docker使用这种模式的命令参数是<code>docker run --net container:&lt;network-container-name&gt; &lt;image&gt; &lt;entrypoint&gt;</code></p></blockquote><h1 id="跨主机网络的实现机制"><a href="#跨主机网络的实现机制" class="headerlink" title="跨主机网络的实现机制"></a>跨主机网络的实现机制</h1><p>跨主机网络需要处理：</p><ul><li>容器和主机网络的拓扑：即哪个容器子网对应于哪台物理主机。拓扑信息的源头当然是容器启动命令，可以通过标准路由协议在各主机的网络组件守护进程之间交换信息，也可以将拓扑信息写入etcd这样的高可用集中存储。</li><li>数据包的转发：iptables，VXLAN等。</li><li>子网隔离：对跨主机的网络，除了实现不同主机上的容器之间能够联网互通，还要能 <strong>不通</strong>，属于不同子网的容器之间不能通讯。</li></ul><p>不同的实现机制，在功能和性能上有所区别：</p><ul><li>将容器置于主机网络中：类似上面提到的VM的bridge模式，及macvlan方式；这种方式需要 <strong>外部机制</strong> 来支持子网，一般是传统的 <strong>VLAN</strong>，即交换机端口设置不同的VLAN ID；VLAN的12位长度限制了子网的数量，对公有云平台是一个限制，但对企业内的私有云一般是够用了。</li><li>路由转发：如<code>calico</code>，仍然使用docker的bridge模式，但不再使用NAT，而是 <strong>路由转发</strong>；NAT的出现是解决私有子网（<code>10.0.0.0/8， 172.16.0.0/12， 192.168.0.0/24</code>），所以路由器对这几个IP网段特别处理了。如果把这3个网段当成普通的IP网段，容器网络和主机网络就跟普通的多层IP网络是一样的（当然主机可以直接通讯，多数情况不必经过物理的核心路由器）。这样 <strong>虚拟交换机</strong> 就不够用了， 需要 <strong>虚拟路由器</strong>，<code>iptables</code> 就是这样一个虚拟路由器（软件路由器，也被作为防火墙）。可以手动添加iptables的路由条目；也可以使用工具自动化这个过程，比如通过标准的路由协议，或开发非标准的方式。</li><li>overlay网络：docker内置了overlay支持，CoreOS的flannel也是早期比较常用的overlay网络工具，Kubernetes就是使用的flannel。overlay网络是将容器的数据包封装起来，当成普通的数据，到目的主机后再拆开，转发给对应的目的容器。</li></ul><blockquote><p>路由转发和overlay方式都有一个 <strong>限制</strong>：每个物理主机上的容器子网必须在 <strong>不同</strong> 的网段。因为这2种方式都会用到docker网桥（docker0），网桥会聪明地通过子网掩码识别哪些数据包是它负责的本地LAN，只有不是同一子网的数据包才会从这个网桥发出去。<br>不过这个限制可以被绕过去。比如从calico或flannel的设置看起来，不同主机上的容器子网是在同一个IP网段的（比如<code>10.0.0.0/16</code>），但实际上每个主机上的容器子网是更细的网段，比如主机A上是<code>10.0.1.0/24</code>，主机B上是<code>10.0.2.0/24</code>，甚至使用了<code>10.0.0.1/32</code>这样的“子网”。</p><p>早期docker在每个主机上只能设置一个bridge，同一主机上的容器彼此无法隔离。目前版本的docker可以设置多个网络。</p></blockquote><h1 id="macvlan"><a href="#macvlan" class="headerlink" title="macvlan"></a>macvlan</h1><p>Linux bridge是一个软件实现的虚拟网桥，而macvlan则利用了网卡硬件的支持。<br>目前的docker内置了macvlan支持。参考<a href="https://docs.docker.com/engine/userguide/networking/get-started-macvlan/" target="_blank" rel="noopener">docker的macvlan文档</a> 和 <a href="https://github.com/alfredhuang211/study-docker-doc/blob/master/docker%E8%B7%A8%E4%B8%BB%E6%9C%BAmacvlan%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE.md" target="_blank" rel="noopener">数人云的一篇文档 - docker跨主机macvlan网络配置</a>，按下面的例子可以设置macvlan：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 主机IP为10.1.1.10/24，网卡名称ens33，首先开启网卡的混杂模式</span><br><span class="line">ip link set ens33 promisc on</span><br><span class="line"></span><br><span class="line"># 创建名为macvlan_net的docker网络</span><br><span class="line">docker network create -d macvlan --subnet=10.1.1.0/24 --gateway=10.1.1.2 -o parent=ens33 macvlan_net</span><br><span class="line"></span><br><span class="line"># 运行容器时指定或动态分配IP。注意，动态分配的IP可能与主机IP冲突</span><br><span class="line">docker run -ti --net macvlan_net --ip=10.1.1.101  centos:net /bin/bash</span><br><span class="line">docker run -ti --net macvlan_net centos:net /bin/bash</span><br></pre></td></tr></table></figure></p><p>上面使用的<code>centos:net</code>镜像是在centos:7基础上安装了<code>iproute</code>和<code>net-tools</code>软件包，以在镜像内提供<code>ip</code>，<code>ifconfig</code>等网络管理命令。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Dockerfile</span><br><span class="line">FROM centos:7</span><br><span class="line">RUN yum install net-tools iproute -y</span><br><span class="line"></span><br><span class="line"># docker build . -t centos:net</span><br></pre></td></tr></table></figure></p><p>按上面的命令创建的2个容器彼此可以pin通，也可以ping通网关和其它主机，但 <strong>不能ping同本主机</strong>，这是macvlan本身的限制（摊手）。macvlan有4种工作模式，可以参考<a href="https://cizixs.github.io/2017/02/14/network-virtualization-macvlan" target="_blank" rel="noopener">linux 网络虚拟化： macvlan</a>、<a href="https://www.ibm.com/developerworks/cn/linux/1312_xiawc_linuxvirtnet/" target="_blank" rel="noopener">Linux 上虚拟网络与真实网络的映射</a>和<a href="http://backreference.org/2014/03/20/some-notes-on-macvlanmacvtap/" target="_blank" rel="noopener">Some notes on macvlan/macvtap</a>，分别为VEPA（不常用，需交换机支持hairpin模式，又称reflective relay反射中继），桥接，私有和Passthru（直通）。<br>使用macvlan网络的容器被置于主机网络中。子网隔离需要VLAN，但实际上同一主机上的容器都使用主机的网线，对应的是交换机的同一个端口，也就是同一个VLAN ID，所以需要macvlan作为一个虚拟交换机，也支持设置VLAN ID。这方面可以参考 <a href="http://t.cn/RXpdDrf" target="_blank" rel="noopener">基于macvlan的Docker容器网络系统的设计与实现 - 浙江大学硕士学位论文 - 万方</a> 和 <a href="/doc/Virtual_switching_technologies_and_Linux_bridge_ppt.pdf">Virtual switching technologies and Linux bridge - ppt</a>。</p><h1 id="overlay网络"><a href="#overlay网络" class="headerlink" title="overlay网络"></a>overlay网络</h1><p>flannel开始是自己实现的overlay机制，将IP包封装到UDP的数据段，即IP in IP，需要拦截并应答容器的ARP包；后来加入了VXLAN的转发方式。VXLAN是将完整的二层以太网包封装到UDP的数据段，即MAC in IP，提供了完整的虚拟二层网络，而且VXLAN是内核支持的，性能好得多。<br>早期版本flannel的配置可以参考<a href="http://dockone.io/article/618" target="_blank" rel="noopener">一篇文章带你了解Flannel</a>。<br>关于<a href="https://tools.ietf.org/html/rfc7348" target="_blank" rel="noopener">VXLAN</a>，从名字上看似乎是VLAN的扩展，但它跟VLAN的实现方式有很大的差别。<br>VLAN是二层以太网包的一个段。对VLAN的支持和VLAN ID是在交换机上设置的（针对交换机各端口，计算机上不需要特别设置）。虽然把VLAN从12位拓展到24位似乎比较简单直接，但需要 <strong>升级交换机</strong> 才能支持新的以太网数据包格式。所以VXLAN把扩展的24位VLAN ID放到了UDP的数据段。VXLAN数据包的处理是通过虚拟的VTEP网卡实现的，实际上是发生在主机上，对交换机而言是透明的。交换机要支持VXLAN还比较复杂些，看起来VXLAN是为主机上的虚拟交换机量身定制的。VXLAN的下层网络可以手动设置点对点的拓扑，也支持通过组播自动发现并组网，不过这样就比较复杂了。<br><img src="/img/vnet-vxlan.png" alt="">。</p><p>VXLAN设计的一个应用场景是在不同的三层网络（如多个数据中心）之上（即overlay）建立一个虚拟的二层网络，即所谓的“大二层”。大二层的需求是为了应对虚拟机的在线迁移。虚拟机一般使用桥接模式，与主机有相同的网络环境。当VM迁移到另一个主机后，VM的MAC和IP应保持不变，以便减少对VM内应用和其用户的影响（虽然VM的MAC和IP没有变化，但新主机对应于交换机的端口发生了变化，用户会经历一小段时间的网络中断，以等待交换机端口学习新的ARP映射）。如果不同主机在不同的VLAN甚至跨数据中心，那么迁移后VM将无法与原VLAN的节点通讯。所以在线迁移需要没有隔离的大二层网络，但这样会造成广播风暴。点对点的VXLAN overlay网络可以比较好的解决这个矛盾。<br>docker出现后，面临的跨主机网络与大二层需求不同但也有类似之处，docker内置的overlay网络就使用了VXLAN转发。</p><blockquote><p>VLAN作为传统的子网隔离机制，是工作在二层的。除了VLAN ID不同，每个VLAN的IP网段也不同，即三层通过IP子网来隔离。VLAN之间如果需要通讯，则需设置经路由转发。</p></blockquote><p>VXLAN是由VMware为主提出来的，微软提出了类似的<a href="https://tools.ietf.org/html/rfc7637" target="_blank" rel="noopener">NVGRE</a>。NVGRE的数据包格式与VXLAN相比向下兼容性不够好，需要升级设备才能应用。</p><blockquote><p>参考</p><ul><li><a href="http://support.huawei.com/huaweiconnect/enterprise/thread-334207.html" target="_blank" rel="noopener">【华为悦读汇】技术发烧友：认识VXLAN</a></li><li><a href="http://support.huawei.com/huaweiconnect/enterprise/thread-333013.html" target="_blank" rel="noopener">【华为悦读汇】技术发烧友：闲话大二层网络</a></li><li><a href="https://www.zhihu.com/question/24393680" target="_blank" rel="noopener">Overlay 网络技术，最想解决什么问题？</a></li><li><a href="http://t.cn/RXpdege" target="_blank" rel="noopener">基于容器云平台的网络资源管理与配置系统 - 浙江大学硕士论文 - 万方</a></li></ul></blockquote><h1 id="对容器网络的需求"><a href="#对容器网络的需求" class="headerlink" title="对容器网络的需求"></a>对容器网络的需求</h1><ul><li>提供类似传统网络的体验<ul><li>VPS（Virtual Private Server）× n + 虚拟网络 = VPC（Virtual Private Cloud）：不同租户的子网彼此隔离，租户可以指定或被分配IP网段，DHCP或静态指定IP，关联公网IP以便与互联网连通；</li><li>租户可以有多个子网，设置虚拟路由器；</li><li>安全组，防火墙，负载均衡，DNS；</li></ul></li><li>性能：高带宽，低延迟，扩展性。VXLAN和calico是目前性能比较好的2种技术。</li><li>容器与物理主机，虚拟机互联共存：这一点目前还没有比较好的实现。</li></ul><h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><p>关于Calico，可参考<a href="http://docs.projectcalico.org/v2.1/getting-started/docker/" target="_blank" rel="noopener">其官网</a>和<a href="http://blog.dataman-inc.com/shurenyun-docker-133/" target="_blank" rel="noopener">将Docker网络方案进行到底</a>。<br>关于不同网络方式的性能，可参考豆瓣上（是的，豆瓣）的这篇<a href="https://www.douban.com/note/530365327/" target="_blank" rel="noopener">Docker network on cloud 中文</a>或者 <a href="https://cmgs.me/life/docker-network-cloud" target="_blank" rel="noopener">https://cmgs.me/life/docker-network-cloud</a> 。这里盗个图。<br><img src="/img/vnet-pk.png" alt=""></p><h1 id="脑洞"><a href="#脑洞" class="headerlink" title="脑洞"></a>脑洞</h1><p>上面的一堆方案，有的自称为SDN，但实际与SDN还有些差距。SDN是针对网络设备的，而这些方案多是在服务器主机上实现虚拟网络设备（交换机，路由器），更接近NFV的目标。<br><strong>被上面一堆方案搞得头痛的，不妨看看这样一个有意思的想法：<a href="https://coreos.com/blog/jumpers-and-the-software-defined-localhost.html" target="_blank" rel="noopener">Jumpers and the Software Defined Localhost</a>：容器中只有一个loop（127.0.0.1）网卡！完全由外部来管理容器网络。</strong><br>隔离是肯定没问题，都不需要子网的概念了，但都只有一个<code>127.0.0.1</code>的IP，如何与其它容器通讯呢？jumpers使用的是端口，域名应该更好些，Docker 已经为每个容器内置了一个<a href="https://www.infoq.com/news/2016/08/docker-service-load-balancing" target="_blank" rel="noopener">DNS（127.0.0.11）</a>来帮助实现服务发现。</p><p><a href="http://dockone.io/article/2504" target="_blank" rel="noopener">DockOne微信分享（一三零）：探究PaaS网络模型设计</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前写过一篇&lt;a href=&quot;https://ying-zhang.github.io/cloud/2016/vm-net/&quot;&gt;关于虚拟机和docker网络的日志&lt;/a&gt;，主要介绍的是VM的虚拟网络，顺带提了一下docker的桥接。&lt;br&gt;经过2016年的几次版本升级，docker的网络功能有了很大的改善，已经基本稳定可用了。&lt;br&gt;去年&lt;a href=&quot;https://github.com/NAP-GHJ/NetTool/blob/master/blog/%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;与一个大四做毕设的学弟折腾过一段时间docker网络&lt;/a&gt;，这里参考浙大SEL实验室的《Docker容器与容器云 第2版》（下面简称《容器云》书） &lt;strong&gt;4.2节 Docker高级网络实战&lt;/strong&gt; ，整理一下相关内容。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://ying-zhang.github.io/categories/cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>虚拟机及docker的网络连接</title>
    <link href="https://ying-zhang.github.io/cloud/2016/vm-net/"/>
    <id>https://ying-zhang.github.io/cloud/2016/vm-net/</id>
    <published>2016-09-19T16:00:00.000Z</published>
    <updated>2018-10-15T15:54:59.605Z</updated>
    
    <content type="html"><![CDATA[<p>网络是云计算中重要的基础设施。这里比较了VirtualBox（简写为vbox），VMware，Hyper-V，KVM这些虚拟机管理器（VMM）及docker的网络连接方式。</p><a id="more"></a><hr><h1 id="路由器，NAT，交换机"><a href="#路由器，NAT，交换机" class="headerlink" title="路由器，NAT，交换机"></a>路由器，NAT，交换机</h1><p>先简单介绍一下<a href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2" target="_blank" rel="noopener">NAT，Network address translation 网络地址转换</a>。<br>下面是从TP-LINK网站上找的一个图。家用的无线路由器连接了两个网络：LAN和WAN。有线LAN接口和Wi-Fi都在LAN局域网。手机，电脑等设备通过有线接口或无线连接到路由器。它们被分配了私有网段的IP。通常的家用无线路由器使用192.168.0.0，192.168.1.0这样的私有IP网段。这些设备彼此可以通过私网IP通信。<br>路由器的WAN口接到了电信/联通/移动等运营商的网络。WAN口只有一个公网IP，一般是一个Internet（公网）上的动态IP（目前更可能是连到了运营商的 <strong>大路由器</strong>，分配的也是私网IP，比如 B 类172网段，相当于又套了一层网络）。LAN的设备都经过WAN口访问外部网。<br>NAT的作用就是通过重写发出数据包的源IP，使外部来看，所有连接都来自WAN IP，重写接收数据包的目标IP，让它在局域网被对应私网IP的设备接收；又通过记录端口号来区分不同LAN IP到外部的网络连接，从而复用WAN IP。</p><p>网络基础课上讲到IP v4有三类私有IP地址：</p><ul><li>10.0.0.0 ~ 10.255.255.255      （A类）；</li><li>172.16.0.0 ~ 172.31.255.255    （B类）；</li><li>192.168.0.0 ~ 192.168.255.255  （C类）；</li></ul><p><img src="/img/wifi-router.png" alt="家用无线路由器拓扑"></p><p>具体说：<br>1、路由器LAN的设备可以访问外网，这是没有问题的，但外网怎么访问私有IP的内部设备呢？<br>2、外网怎么区分路由器LAN的不同设备呢？</p><p>实际上外部网络什么也不用干，它看到的只是路由器的WAN IP。这两个问题都是路由器通过NAT（网络地址转换）来解决的。内网向外网发送一个数据包时，路由器把数据包的源地址（实际是上还有端口号，即IP:Port格式，比如默认的http是80端口），也就是内网设备的私网IP改成自己的WAN IP，并给不同的设备（随机）分配不同的端口号，并把随机端口号与内网设备的IP:Port的映射关系保存下来。路由器接收到外部返回的应答数据包后，根据端口号查询到实际的内网设备IP:Port，再改写数据包的目标地址，转发给LAN上的内网设备。因此NAT是分两个方向的，分别称为源NAT (SNAT) 和 目标NAT (DNAT)。</p><p>如果外网直接访问路由器的WAN IP，路由器找不到端口映射关系，就会直接drop掉这个数据包，导致外网不能直接访问内部设备。NAT默认要求一个网络通信必须由内部设备发起。也可以在路由器中设置好固定的端口映射，这样路由器就知道该转发给哪个设备，当然它还是可以判断出来是内部设备主动发起的通信，还是由外部设备发起的。还有一种DMZ技术，让路由器直接把一台内网设备暴露给外网，一般总还是有一些空闲的端口的，所以DMZ不会影响其它内网设备的联网。</p><p>把路由器的WAN口那一块去掉，剩下的LAN口那部分功能就是一个交换机了，交换机所有的端口都是对等的，所连接的设备组成了一个LAN。<br>网络基础课上会介绍交换机是二层设备，路由器是三层设备。<strong>所谓二层，即物理链路层，最常见的就是以太网，设备之间以MAC地址区分；三层是网络层，设备之间以IP地址区分。三层的数据是封装在二层之中的。交换机只看数据包的MAC首部，而路由器则只看IP首部。但要是交换机偷看了IP首部也不会爆炸，而是变成更高级的三层交换机来抢路由器的生意了。具体三层交换机跟路由器的差别，因水平有限就不谈了。</strong> 网络编程基本都是在三层（IP）四层（TCP/UDP），很少直接接触二层的（MAC）。<br>另外，家用路由器一端是公网，另一端是不能直接路由的私网IP段，而数据中心或电信路由器各端口（不止两个）连接的一般都是公网，可以直接路由，不需要使用NAT。</p><center>~</center><p>下面的表格是几种虚拟机管理器（VMM）支持的网络连接方式，同一行的网络连接方式实现的功能是基本相同的，不过在不同的VMM里叫法有所不同。</p><p><img src="/img/vnet.png" alt="几种虚拟机的网络连接方式"></p><blockquote><p>注：<strong>NAT网络</strong>，Host-&gt;VM的情况，VMware在Host创建了虚拟网卡，不需要端口映射，Host可以直接通过IP来访问VM。</p></blockquote><h1 id="单机的网络地址转换（NAT）"><a href="#单机的网络地址转换（NAT）" class="headerlink" title="单机的网络地址转换（NAT）"></a>单机的网络地址转换（NAT）</h1><p> 只有vbox支持 <strong>单机NAT</strong> 方式。这种方式与下面的 <strong>NAT网络</strong> 的唯一区别是，不同的VM之间不能互相通信。这个特性是为了方便创建多个单机VM，而不会彼此干扰。<br> 虽然是针对单机的，实际上NAT也有多个网络设备，包括一个网关，IP是<code>10.0.2.2</code>，一个DHCP服务器，也是<code>10.0.2.2</code>，VM的IP一般是<code>10.0.2.15</code>。<br> 不管使用NAT的有多少个VM，它们的IP都是一样的。</p><p> 一个VM可以设置多个网卡，如果这些网卡有多个使用NAT模式，那么它们的IP区段就会递增，分别为<code>10.0.2.0/24</code>，<code>10.0.3.0/24</code>等。不过同一个VM设置多个NAT网卡并没有什么必要。</p><p> VM可以直接访问Host，默认IP也是<code>10.0.2.2</code>，但这个IP在Host是看不到的，即Host跟VM不在同一个LAN，Host不能直接访问VM的IP。<br> Host要想访问VM，需要设置端口映射，即设置<code>HostIP:HostPort</code>与<code>VM-IP:VM-Port</code>的关联，这样Host就可以通过<code>HostIP:HostPort</code>来访问VM的端口了。如果映射的HostIP是可以从外部路由的，那么外部也可以通过<code>HostIP:Host-Port</code>来访问VM的指定端口。<br> 可以添加多个映射规则来暴露不同的端口。</p><h1 id="NAT网络"><a href="#NAT网络" class="headerlink" title="NAT网络"></a>NAT网络</h1><p> 在VMware中则直接称为 <strong>NAT</strong> 。vbox刻意把这 <strong>NAT</strong> 和 <strong>NAT网络</strong> 这2种方式区分开，可能是因为他们认为不仅需要实现网络连通，还要能够实现隔离吧。<br> vbox需要在 <strong>全局配置-&gt;网络</strong> 中增加一个 <strong>NAT网络</strong> 的虚拟网卡才能使用NAT网络，但这个网卡在Host的网络设备里是看不到的。添加的第一个NAT网络的网段是<code>10.0.2.0/24</code>，网关是<code>10.0.2.1</code>，DHCP服务器是<code>10.0.2.3</code>，Host是<code>10.0.2.2</code>，VM的IP是由DHCP自动分配的。<br> 连接到同一个NAT网络的VM组成了一个LAN。这种情况跟前面提到的家用路由器的连接是很相似的，连接到路由器的多个设备是在一个私有IP网段的LAN，路由器有一个外网的IP，各种设备可以通过路由器连接外网，不做端口映射的话，外网不能直接访问内网的设备。</p><blockquote><p>外网是可以与内网通信的，否则我们就不能看到网站返回的网页了，但必须要内网设备发起连接，外网响应。这是因为内网的IP是私有的，在 <strong>公网</strong> 上是不可路由的。<br>这里 <strong>外网</strong> 是Host之外的网络，它可能是一个Internet IP（<strong>公网</strong>），也可能是某个公司内部的私有IP地址的网络。<br>如果可以修改 <strong>外网</strong> 的路由的话，还是可以实现不做端口映射，通过路由协议来路由到内网设备的，但一般只有运营商才有这样的能力。</p></blockquote><p> 连接到不同的虚拟网卡的VM，即便IP网段是相同，也不能连通。<br> vbox可以添加多个NAT网络，它们可以使用相同的默认IP网段<code>10.0.2.0/24</code>，这不会彼此产生冲突，当然也可将其网段改为其它地址，如<code>10.0.3.0/24</code>，或<code>192.168.2.0/24</code>这样的，但<code>192.168.x.x</code>网段的DHCP可能不能正常工作，需设置静态IP。</p><p> VMware的NAT网络设置有所不同。VMware安装后，会在（Windows）Host添加一个VMnet8的虚拟网卡，工作在NAT模式。在VM中选择网卡为VMnet8和设置使用NAT模式的效果是一样的。有了这个虚拟网卡，Host也就在NAT网络的LAN里面了，所以VMware的NAT网络模式下Host是可以直接访问VM的，这点比vbox要方便些。</p><p> VMware内置了VMnet0 ~ VMnet19共20个虚拟网卡可用，每个虚拟网卡对应了一个虚拟LAN，可以工作在 <strong>NAT</strong>、<strong>仅主机</strong> 和 <strong>桥接</strong> 三种不同的模式之一，但又 <strong>限制只能有一个虚拟网卡工作在NAT模式</strong> （这个限制是很奇怪的）。不过VMware在NAT模式下可以更改 <strong>默认网关的IP</strong>，及DHCP、DNS的设置。</p><blockquote><p>注意，vbox在两种NAT模式下都有一个坑：<br>VM在使用DHCP分配IP时能正常访问外网，但如果在VM中设置静态IP，<strong>即便这些值与DHCP分配到的值一模一样，也不能访问外网！</strong><br>虽然不能访问外网，但内网能正常访问，说明可能是DNS设置的问题。</p><p>在这个<a href="http://geekynotebook.orangeonthewall.com/configure-static-ip-on-nat-in-oracle-virtualbox/" target="_blank" rel="noopener">博客</a> 中介绍了同样的问题（博客里的DNS IP <code>10.0.2.3</code>和<code>/etc/resolve.conf</code>设置在ubuntu上不能工作）。<br>对Ubuntu，需在 <code>/etc/network/interfaces</code> 设置网卡</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">auto eth0</span><br><span class="line">iface eth0 inet static</span><br><span class="line">address 10.0.2.15</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 10.0.2.2</span><br><span class="line"></span><br><span class="line">dns-nameservers 10.0.2.1</span><br></pre></td></tr></table></figure><blockquote><p><strong>设置静态IP后，VM还要执行下面2条命令才会使用Host的DNS！</strong><br>vbox在DHCP模式下会自动使用Host的DNS，但设置静态IP后默认不再使用Host的DNS，导致VM无法连接外网。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">VBoxManage modifyvm &quot;VM-Name&quot; --natdnsproxy1 on</span><br><span class="line">VBoxManage modifyvm &quot;VM-Name&quot; --natdnshostresolver1 on</span><br></pre></td></tr></table></figure><blockquote><p>其中<code>VBoxManage</code>是vbox的命令行管理工具，在vbox的安装目录下，默认位置是<code>C:\Program Files\Oracle\VirtualBox\</code>。</p><p>vbox 5.0.0 版有这个坑，而5.0.2 及以后的版本，<strong>NAT网络</strong> 方式已经不需要执行上面2条命令了，但<code>/etc/network/interfaces</code>里dns-nameservers的设置还是需要的。<br>另外，经过实验发现gateway设置为<code>10.0.2.1</code> 或 <code>10.0.2.2</code>都可以连网，但DNS必须是<code>10.0.2.1</code>。</p><p>VMware没有这个坑。</p></blockquote><h1 id="Host-Only-仅主机"><a href="#Host-Only-仅主机" class="headerlink" title="Host-Only 仅主机"></a>Host-Only 仅主机</h1><p> 这种连接方式是4种VMM都支持的，它的使用很简单。<br> Host-Only模式下，vbox、VMware和Hyper-V都会在Host添加一个虚拟网卡，使用同一个虚拟网卡的VM会连接到同一个虚拟LAN，而且Host也在这个LAN。Host，VM之间都可以方便的连通，不需要端口映射，但VM不能访问外网。<br> 当我们创建了多个VM，并把这些VM连接到一个虚拟LAN，这就算是一个小型的 <strong>虚拟 数据中心</strong> 了。一个现实的数据中心里，除了多台服务器，还有 <strong>交换机</strong>，集中式存储设备，比如iSCSI，SAN，NAS等。一个机架里的多台服务器连接到机架顶部的交换机（ToR），多个机架交换机再连接到核心交换机。<br> 实际上数据中心的网络结构是很复杂的，并不只有一个LAN，而是分成了外部网络、内部业务网络、管理网络、存储网络等多个网络，还会划分成多个子网。<br> Host-Only连接方式物相当于机架顶部的交换机（ToR），所以Hyper-V的叫法：<strong>内部交换机</strong> 是很贴切的。</p><p> 还可以添加多个虚拟网卡，组成多个彼此隔离的LAN（Host分别有一个虚拟网卡挂在每个LAN中）。</p><p> 利用Windows的网络共享功能，将外部网络共享给Host的虚拟网卡，然后将VM设置为静态IP，网关和DNS设置为<code>192.168.137.1</code>，这样就可以连接外网了，但只能共享给一个虚拟网卡，而且IP网段必须是<code>192.168.137.0/24</code>。<br> 复杂点的办法是在Host配置NAT，以Hyper-V为例，它没有NAT网络，参考<a href="https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/user-guide/setup-nat-network" target="_blank" rel="noopener">Set up a NAT network for Hyper-V</a>文档，在Powershell下以管理员权限执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">New-VMSwitch -SwitchName &quot;NAT&quot; -SwitchType Internal</span><br></pre></td></tr></table></figure></p><p>查看interfere index：<code>Get-NetAdapter</code>，即下面命令中虚拟网卡的<code>-InterfaceIndex 38</code>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">New-NetIPAddress -IPAddress 10.0.0.2 -PrefixLength 24 -InterfaceIndex 38</span><br><span class="line">New-NetNat -Name NATx -InternalIPInterfaceAddressPrefix 10.0.0.0/24</span><br></pre></td></tr></table></figure></p><p>这样就创建了一个可以通过Host以NAT方式访问外网的 <strong>内部交换机</strong>，不过这个内部交换机还缺少DHCP服务，需要为VM静态分配IP。</p><h1 id="桥接"><a href="#桥接" class="headerlink" title="桥接"></a>桥接</h1><p> 桥接是最方便的一种连接方式。它需要绑定到物理网卡。如果Host的网络连接正常，那么VM一般也就没什么问题了，但如果Host的网络出现了故障，那么VM也无法联网了，即便是同一个Host的VM之间也不能正常通信。<br> 桥接模式下VM与Host的地位是完全对等的。从外部看，VM就像一台真实的机器一样，有自己的MAC和IP。这样极大地简化了网络结构。<br> 不过，在学校的网络环境下，每个IP需要登录web认证后才能访问外网，每个桥接的VM不能都需要登录，而每个账号只能同时登录一个IP的限制导致只能有一个台机器能连上外网，所以不适合采用桥接。</p><p> 另外，虽然名叫 <strong>桥接</strong>，但vbox和VMware都没有用到“网桥”。桥接实际是用所谓的网卡的“混合模式”实现的，即一个网卡可以伪装成不同MAC地址的多个网卡。在Hyper-V中倒是添加了一个虚拟网桥和一个虚拟网卡，功能上是一样的。<br> KVM的各种网络连接方式都需要设置一个bridge，区别在于这个bridge与物理网卡（如eth0）的连接及路由设置。KVM的网络连接不是像vbox，VMware或Hyper-V那样由VMM实现的，而是利用了 <strong>已有的</strong> Linux的bridge-utils，TUN/TAP，iptables等功能。</p><p><a name="docker-bridge"></a></p><h1 id="Docker的桥接模式"><a href="#Docker的桥接模式" class="headerlink" title="Docker的桥接模式"></a>Docker的桥接模式</h1><blockquote><p>注意：docker的网络连接方式也有 <strong>桥接</strong>，但实际上它的工作模式是 <strong>NAT网络</strong>。docker在添加了一个docker0网桥，IP网段在<code>172.17.0.0</code>，如果外网要访问容器，需要做端口映射。这样的网络连接方式下，<strong>不同Host</strong> 的容器是不能直接通信的，这是个很大的局限。<br> 实际上docker也可以实现KVM那样的真正的 <strong>桥接</strong> ，具体可参考文章 <a href="http://my.oschina.net/astute/blog/293944" target="_blank" rel="noopener">桥接模式构建 docker 网络</a> 和<a href="http://blog.oddbit.com/2014/08/11/four-ways-to-connect-a-docker/" target="_blank" rel="noopener">Four ways to connect a docker container to a local network</a> 。看起来这样的连接方式还是比较实现容易的，但目前docker还没有在官方的实现中直接支持这种连接方式。</p></blockquote><h1 id="内部网络-LAN区段"><a href="#内部网络-LAN区段" class="headerlink" title="内部网络/LAN区段"></a>内部网络/LAN区段</h1><p> 这种方式下只有连接到同一内部网络的VM之间能够通信，而VM与Host，与外网都不能通信。<br> 一个内部网络是由网络名来区分的。<br> VMware和Hyper-V的内部网络可以设置网络带宽，丢包率等，方便进行网络方面的实验，不过作为其它场景的实验环境就不太合适了。<br> 内部网络不支持DHCP，可以专门添加一个多网卡的VM作为网络服务器，完成DHCP，网关，路由等功能。</p><h1 id="选择哪种连接方式？"><a href="#选择哪种连接方式？" class="headerlink" title="选择哪种连接方式？"></a>选择哪种连接方式？</h1><ul><li><strong>NAT网络</strong>            ：优点是可以充分共享Host的网络连接，包括VPN；不足是Host和外部访问VM需要端口映射；VM的IP地址不受外部影响，适合搭建 <strong>实验环境</strong> 。</li><li><strong>Host-Only仅主机</strong>    ：优点是Host可以方便地访问VM；不足是不能访问外网；VM的IP地址也不受外部影响，如果NAT网络需要较多的端口映射，可以考虑每台VM设置2个网卡，一个工作在NAT网络模式，另一个工作在Host-Only模式。</li><li><p><strong>桥接</strong>                ：优点是设置简便，很容易实现互联互通；不足是不能共享Host的网络连接（web登录认证，VPN），而且VM的IP地址受外部影响，更换了网络环境，IP地址可能会发生变化。假设用笔记本电脑搭建的实验环境，VM使用桥接模式，在宿舍的IP地址和在会议室的IP地址是不同的，依赖IP的设置都要修改，是很不方便的。</p><p>在 <strong>数据中心</strong> 里，网络环境不经常变化，<strong>桥接</strong> 模式屏蔽了VMM的影响，可以直接应用已有的交换机设备和配置，简化了网络配置操作。如果交换机支持VLAN，那么可以启用VLAN作为VM的网络隔离，虽然有不能超过4096（ $ 2^{12} $，12 bit）个VLAN的数量限制，但对企业内部的私有云场景应该是足够的。<br>此外，虚拟网络还要考虑IP地址的容量，分配和管理方式避免冲突，多租户的隔离，以及故障转移后的IP重用策略等，了解的不多，这里就不多说了。</p></li></ul><h1 id="Bonus"><a href="#Bonus" class="headerlink" title="Bonus"></a>Bonus</h1><p><strong><a href="/doc/The_Datacenter_as_a_Computer_An_Introduction_to_the_Design_of_Warehouse_Scale_Machines_2e_2013.pdf">The Datacenter as a Computer - An Introduction to the Design of Warehouse-Scale Machines - 2e - 2013</a></strong></p><p><img src="http://www.infoq.com/cn/presentations/aws-data-center-and-vpc-secret" alt="AWS 数据中心与 VPC 揭秘 - QCon Beijing 2017 - infoq"></p><p><img src="/img/google_dc1.jpg" alt="Google的数据中心"></p><p><img src="/img/google_dc2.jpg" alt="Google的数据中心"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;网络是云计算中重要的基础设施。这里比较了VirtualBox（简写为vbox），VMware，Hyper-V，KVM这些虚拟机管理器（VMM）及docker的网络连接方式。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://ying-zhang.github.io/categories/cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>双拼输入法</title>
    <link href="https://ying-zhang.github.io/misc/2016/udpnuurufa/"/>
    <id>https://ying-zhang.github.io/misc/2016/udpnuurufa/</id>
    <published>2016-09-18T16:00:00.000Z</published>
    <updated>2018-10-15T15:20:59.981Z</updated>
    
    <content type="html"><![CDATA[<p>双拼输入法一直就在隐藏在我们每天使用的软件中，然而被人们熟视无睹，一旦掌握，用起来非常方便。<br>除了介绍双拼输入法，还有一点关于语音输入的杂想。</p><a id="more"></a><hr><p><a href="https://zh.wikipedia.org/wiki/%E5%8F%8C%E6%8B%BC" target="_blank" rel="noopener">双拼</a>输入法利用了汉语拼音的一个基本属性：包括声母和韵母两个部分。双拼输入法每输入一个汉字都要（最多）两次击键，第一次为声母，第二次为韵母，平均起来比全拼减少了击键次数，比简拼可能相差不多，但简拼一般是的特定短语，否则重码太多，双拼则没有这个限制。<br>双拼能不能显著提高输入汉字的速度没有定论，但它能保证输入速度 <strong>不会太慢</strong>，最重要的一点是每个字都是敲两个键，有很好的 <strong>节奏感</strong>，让思路能很自然地敲出来。</p><blockquote><p>本文主要内容的<a href="/doc/shuang_pin_udpn_cheetsheet.pdf">一页纸PDF文件，亦称Cheetsheet</a></p></blockquote><h1 id="双拼方案"><a href="#双拼方案" class="headerlink" title="双拼方案"></a>双拼方案</h1><p>将汉语拼音中声母和韵母分别对应到键盘上的26个英文字母，这就是双拼方案。下面是微软双拼的方案。</p><h2 id="声母"><a href="#声母" class="headerlink" title="声母"></a>声母</h2><p><code>b p m f d t n l g k h j q x r z c s y w</code>这些单声母都是直接与各自的字母键对应的，对<code>zh ch sh</code>这三个，对应关系是<code>i：ch</code>，<code>u：sh</code>，<code>v：zh</code>；有的拼音不需要声母，比如<code>爱 ai</code>，只有韵母<code>ai</code>，为了保持编码规律，指定它们为 <strong>零声母</strong>，并对应为按键<code>o</code>。</p><h2 id="韵母"><a href="#韵母" class="headerlink" title="韵母"></a>韵母</h2><p>韵母的对应关系稍微复杂一点，</p><ul><li><code>a e i o u</code>这几个元音的对应比较简单；</li><li>对于复杂韵母，<ul><li><code>u o</code>相关的多在第一行键位，</li><li><code>a e</code>相关的多在第二行键位，</li><li><code>i</code>  相关的多在第三行键位。</li></ul></li></ul><p>下面的韵母键位需要记忆。初学时可以把这个图打印出来贴到屏幕边，或者拼到壁纸的一角，需要查看提示时按<code>Win+D</code>显示桌面即可。一般练习一两天就记住了。</p><p><img src="/img/udpn-ms-map.png" alt="微软双拼韵母键位"></p><p>例如，输入“我爱双拼输入法”，对应的击键如下表，</p><p><img src="/img/udpn-demo.png" alt="微软双拼示例"></p><p>说明：</p><ol><li>大部分声母都有直接对应的键位，只有<code>zh ch sh</code>需特别记忆一下。有的拼音没有声母，如<code>爱</code>，这时就需要零声母，即字母<code>o</code>，以表明后面的键是韵母；</li><li>韵母<code>a  e  i  o  u</code>直接与各自的字母键对应，其它韵母的对应关系则需要记忆，注意，韵母<code>ing</code>对应分号键<code>;</code>。</li></ol><p>双拼下也可以使用简拼，但需要用 <code>&#39;</code> 作为分隔符划分音节。如果你刚才 <strong>整句</strong> 地输入过“我爱双拼输入法”，那么试试<code>w&#39;i&#39;u&#39;p&#39;u&#39;r&#39;f</code> ，看看你的输入法软件够不够智能。说实话，简拼用<code>&#39;</code>实在不够方便。如果连续敲的两个键不能组成一个合法的拼音，输入法一般会自动把它识别为简拼的两个拼音。</p><h1 id="双拼输入法的软件"><a href="#双拼输入法的软件" class="headerlink" title="双拼输入法的软件"></a>双拼输入法的软件</h1><p>好像没有专门支持双拼的输入法软件啊？<br>其实Windows及Android上常见的 <strong>拼音输入法软件</strong>，如搜狗、百度、QQ、谷歌、紫光等，及Windows内置的微软拼音，Linux上的Fcitx，都支持双拼，只要在设置中选择一下即可。有的输入法支持 <strong>双拼展开提示</strong>，初学时有所帮助。</p><p>一般输入法软件都支持多种双拼方案，有的还支持自定义方案。上面提到的几款软件都支持微软双拼方案，所以建议使用该方案。百度手机输入法的默认方案就是微软双拼，但韵母<code>ing</code> 对应的是 <strong><code>,</code></strong>。</p><p><img src="/img/udpn-baidu-ime.png" alt="百度拼音设置"></p><hr><h1 id="关于语音输入的杂想"><a href="#关于语音输入的杂想" class="headerlink" title="关于语音输入的杂想"></a>关于语音输入的杂想</h1><p>iPhone上的siri当年是一大卖点（只是不知现在还有没有人用），Google，微软也相继发布类似的语音产品，不过一直都不感冒。前不久某著名相声演员在自家的手机发布会上大力赞扬友商讯飞输入法，看了该相声演员的演示后，马上在手机和PC上都安装了讯飞输入法来体验一下，感觉里预期还是有点差距，总结一些想法：</p><ul><li>首先不想对着手机或电脑大声说，特别是意识到是要讲给一个输入法软件时语气就会有点奇怪。</li><li>语音输入的连续性也需要加强，目前的体验类似于对讲机，讲一句识别一句，确认有没有错误，如果有错误再去修改，不够自然。显然软件是可以根据声音自动断句的，用户应该可以以自然的语速不间断的讲下去，后台进行语音识别，间断输出，同时软件会保存录音，供后期集中校对，校对时可以提供多个备选及原始语音。校对其实就是机器学习里的有监督学习了，众多用户免费进行训练，而且是最真实场景的数据。</li><li>提供上传mp3语音文件转换后输出文本的服务，就像已经有不少识图网站，可以输出上传图片的文字描述，这也是大数据啊~~ Youtube就有一个自动为视频生成字幕的功能；还有不少公司搞即时翻译； 或许讯飞认为他们的识别准确率已经很高，不需要再训练了。。。</li></ul><blockquote><p>手机最初的功能就是语言通话，所以内置的麦克用来做语音识别是足够的，而且可以拿到嘴边轻声说话；<br>但电脑上就不一定有堪用的麦克了，一般笔记本是有麦克的，但效果难说，台式机就需要另外购买麦克了。<br>想到这里，可能淘宝客服最适合用语音识别了;-)<br>要是有一个高灵敏度，降噪，带录音，小巧，长时续航，USB充电，能无线接入电脑的麦克就好了。<br>话说这样的麦克应该接近于一个录音笔了，但增加了可以实时接入电脑作为麦克的功能。<br>弄个新硬件还是比较有难度的，也可以利用手机已有的麦克，在PC上虚拟出一个麦克，或许更容易些。这种思路类似于<code>Sensor offloading</code>，而且已经有了这样的App：<a href="http://wirelessorange.com/womic-zh/" target="_blank" rel="noopener">WO Mic</a>，这个是通过wifi传数据的，需要PC客户端，有时间试用一下，这家还有WO Webcam和HiMic。另外的一个App则是需要一个两头都是3.5mm公头的音频线。</p></blockquote><p>再到<a href="http://www.iflyrec.com/" target="_blank" rel="noopener">讯飞听见</a>的网站，发现了下面这两项产品/服务，看来想法差不多嘛;-) 不过录音笔有点小贵（相对其它品牌来说算是比较便宜了），云转换需要收钱，只好看看<a href="http://cn.technode.com/post/2016-01-13/iflyrec-examination/" target="_blank" rel="noopener">别人的体验</a>了。话说能花钱把会议记录转成文本的，会不会考虑保密的问题？其实关于会议系统还可以做的很多，比如做网络视频会议的思科WebEx。讯飞讯飞智能会议系统可以算是关注了会议结束后，写会议纪要的工作。不过如果能在开会时就转换成文本，开完会就通过了会议纪要，效率不就更高了吗？</p><p><a href="http://z.jd.com/project/details/34481.html" title="讯飞录音笔众筹" target="_blank" rel="noopener"><img src="/img/udpn-iflyrec-rec.png" alt="讯飞录音笔"></a></p><p><img src="/img/udpn-iflyrec-meeting.png" alt="讯飞智能会议系统"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;双拼输入法一直就在隐藏在我们每天使用的软件中，然而被人们熟视无睹，一旦掌握，用起来非常方便。&lt;br&gt;除了介绍双拼输入法，还有一点关于语音输入的杂想。&lt;/p&gt;
    
    </summary>
    
      <category term="misc" scheme="https://ying-zhang.github.io/categories/misc/"/>
    
    
  </entry>
  
  <entry>
    <title>局域网内的远程操作</title>
    <link href="https://ying-zhang.github.io/setup/2016/setup-remote/"/>
    <id>https://ying-zhang.github.io/setup/2016/setup-remote/</id>
    <published>2016-09-17T16:00:00.000Z</published>
    <updated>2018-06-03T15:11:25.941Z</updated>
    
    <content type="html"><![CDATA[<p>一些基础的远程操作，包括ssh，共享文件，远程桌面。</p><a id="more"></a><hr><p>这里简单介绍局域网中Windows与Linux系统之间的一些基本远程操作，包括远程执行命令（<code>ssh</code>），共享文件（<code>Samba</code>）和远程桌面（<code>mstsc</code>和<code>vnc</code>）。<br>远程操作一般是“服务器-客户端”模式，有的服务程序或客户端是操作系统内置的，开箱即用，有的程序则需要手动安装。</p><p>为了方便配置，<strong>建议关闭系统的防火墙</strong>。下面例子使用的远程Linux主机是Ubuntu 16.04，IP是<code>10.1.1.5</code>，用户名<code>ying</code>；Windows的IP是<code>10.1.1.1</code>，用户名也是<code>ying</code>。</p><h1 id="Linux远程执行命令（ssh）"><a href="#Linux远程执行命令（ssh）" class="headerlink" title="Linux远程执行命令（ssh）"></a>Linux远程执行命令（ssh）</h1><p>ssh（<a href="https://en.wikipedia.org/wiki/Secure_Shell" target="_blank" rel="noopener">Secure Shell</a>）通过加密的网络通道在客户端和服务器之间传递命令及其输出。<br>在ssh之前，远程执行命令是通过<code>telnet</code>或<code>rsh</code>等程序实现的，数据是明文传输的，缺乏安全性。ssh提供了一个在网络上认证用户和加密数据的通道，执行命令是直接使用的系统内置的shell。<br>可以在ssh提供的加密通道上完成其它网络通信：如<code>scp</code>是在ssh加密通道上实现的远程拷贝（<code>rcp</code>）；<code>sftp</code>是在ssh加密通道上实现的<code>ftp</code>；<code>git</code>也有使用ssh加密通道传输文件的模式。<br>对于Linux这种主要通过shell命令行交互的系统来说，使用ssh远程登录到服务器上，就跟直接在机器上敲命令就没什么区别了。</p><h2 id="Linux下设置和使用ssh"><a href="#Linux下设置和使用ssh" class="headerlink" title="Linux下设置和使用ssh"></a>Linux下设置和使用ssh</h2><p>Linux系统的ssh服务程序是<code>OpenSSH Server</code>，执行命令<code>sudo apt install openssh-server</code>。<br>安装过程中会将ssh服务程序（<code>sshd</code>）添加为开机启动的系统服务，默认设置允许当前用户通过密码登录ssh。</p><blockquote><p>查看SSH Server状态，执行<code>systemctl status sshd</code><br>启动，停止或重启服务，执行<code>sudo systemctl start/stop/restart sshd</code></p></blockquote><p>一般Linux系统都内置了ssh客户端，执行<br><code>ssh 用户名@主机名或IP</code><br>登录到远程主机（如果用户名与当前登录的用户名相同，可以省略）。<br>登录到本机的命令是<code>ssh localhost</code><br>第一次登录某个主机会提示是否 <strong>信任</strong> 该主机，需要输入<code>yes</code>，之后才会提示输入远程主机的登录密码。</p><blockquote><p>修改<code>/etc/ssh/ssh_config</code>，将其中<code>#   StrictHostKeyChecking ask</code> 改为 <code>StrictHostKeyChecking no</code>，这样在第一次登录时就不会询问是否要信任该主机了。</p></blockquote><p>如果登录到远程主机只是执行一两条命令，可执行<br><code>ssh 用户名@主机名或IP 命令</code><br>当然，每次还是需要输入密码，参考下面的设置密钥登录后就方便多了。</p><h2 id="Windows安装和设置xshell，使用密码ssh登录"><a href="#Windows安装和设置xshell，使用密码ssh登录" class="headerlink" title="Windows安装和设置xshell，使用密码ssh登录"></a>Windows安装和设置xshell，使用密码ssh登录</h2><p>Windows目前没有内置的ssh客户端，可以安装Putty、SecureCRT、xshell等ssh客户端软件，或者使用Cygwin/MinGW，git（包含MinGW），Bash on Windows等附带的ssh命令。</p><blockquote><p>Windows版的<code>git</code>包含一个简化版<code>MinGW</code>，将<code>&lt;git安装目录&gt;\usr\bin</code>这个路径添加到Windows的<code>Path</code>环境变量，就可以在Windows的命令窗口执行<code>ssh</code>，<code>scp</code>及其它很多Linux命令了。<br><code>MinGW</code> 中也包含SSH Server程序<code>sshd</code>，不过估计很少会登录到Windows执行命令行操作吧。</p></blockquote><p>从官网下载并安装 <a href="http://www.netsarang.com/download/down_xsh.html" target="_blank" rel="noopener">xshell</a> （需要注册一个免费的账号，选择免费的Home/School许可），也可以在百度搜索“xshell”，第一条结果即是，注意要选择 <strong>普通下载</strong>。</p><p>启动xshell后，可以直接执行<code>ssh ying@10.1.1.5</code>，会提示输入密码，首次连接也会提示“未知的主机密钥”，选择保存即可。<br><img src="/img/xshell-ui.png" alt=""></p><blockquote><p>工具栏的打开会话按钮，可以从其中选择某个会话，也可以直接在xshell中执行<code>open &lt;会话名&gt;</code>。<br>工具栏的那个带小齿轮的按钮是“默认会话属性”，修改其中的设置会影响新建的会话。<br>每个会话即<code>&lt;用户文档&gt;\NetSarang\Xshell\Sessions</code>下的一个配置文件，会话也可以复制后修改。</p></blockquote><p>为方便后续使用，可以为这个虚拟机创建一个会话。单击工具栏的“新建”按钮，在打开的 <strong>“会话属性”</strong> 对话框中</p><ul><li>在“连接” 输入主机 <code>10.1.1.5</code>，在用户身份验证中选择方法为Password，输入用户名 <code>ying</code> 和 密码；</li><li>在“终端” 修改“编码”为UTF-8；</li><li>在“外观” 修改终端字体和配色方案，我比较习惯黑底绿字的配色，使用Consolas字体，使用闪烁的光标。</li></ul><p><img src="/img/xshell-prop.png" alt=""></p><blockquote><p>注意：Windows的快捷键与Linux终端的快捷键存在冲突，如“复制”<code>Ctrl+C</code>对应的是中断当前命令。<br>xshell中默认“复制”、“粘贴”的快捷键是<code>Ctrl+Ins</code>，<code>Shift+Ins</code>，而不是<code>Ctrl+C</code>，<code>Ctrl+V</code>。<br>可以打开 “工具”-&gt;“选项”，“键盘和鼠标”选项卡，“按键对应”-&gt;“编辑”，将其修改为<code>Ctrl+C</code>，<code>Ctrl+V</code>，而原来Linux终端的快捷键需要加<code>Shift</code>，如中断当前命令的<code>Ctrl+C</code>变成了<code>Ctrl+Shift+C</code>。</p></blockquote><h2 id="scp"><a href="#scp" class="headerlink" title="scp"></a>scp</h2><p>通过ssh加密的通道传输文件。文件路径格式为<code>用户名@主机名或IP:主机上的路径</code>。注意，Windows文件路径中的盘符<code>C:\</code>变成了<code>/c/</code>。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp ying@10.1.1.5:/home/ying/.ssh/id_rsa.pub /c/users/ying/.ssh/</span><br></pre></td></tr></table></figure></p><h2 id="sftp"><a href="#sftp" class="headerlink" title="sftp"></a>sftp</h2><p><code>OpenSSH Server</code>内置了一个<code>sftp</code>服务器，会随<code>sshd</code>服务自动启动。我们还需要一个<code>sftp</code>的客户端即可传送文件。<br>这里使用图形界面的，跨平台的，免费的，开源的<a href="https://filezilla-project.org/download.php?type=client" target="_blank" rel="noopener">Filezilla</a>。下载并安装后，在“快速连接”工具栏输入主机<code>sftp://10.1.1.5</code>，及用户名 <code>ying</code> 和密码，端口为22，单击“快速连接”，然后就可以进行文件传输和管理了。<br><img src="/img/sftp.png" alt=""></p><p>Android上的<code>ES文件浏览器</code>也支持<code>sftp</code>（还支持下面介绍的smb局域网文件共享）。</p><h2 id="设置ssh使用密钥登录"><a href="#设置ssh使用密钥登录" class="headerlink" title="设置ssh使用密钥登录"></a>设置ssh使用密钥登录</h2><p>更安全而且方便的ssh登录方式是使用密钥对(key)。密钥对包含公钥和私钥，其实是两个很长的整数（被编码为字符串）。比如采用<code>rsa</code>算法，公钥和私钥分别保存在两个 <strong>文本</strong> 文件<code>id_rsa.pub</code>和<code>id_rsa</code>中。</p><ul><li>公钥<code>id_rsa.pub</code>保存在要登录的目标机器上（服务器，Github等），</li><li>私钥<code>id_rsa</code>保存在 <strong>发起</strong> 登录的机器上（客户端），私钥要妥善保管，防止泄露。</li></ul><p>Linux主机的密钥对默认保存在<code>~/.ssh/</code>目录。<br>Windows是<code>C:\Users\&lt;Win用户名&gt;\.ssh\</code>目录。在图形界面的文件管理器中不能创建以<code>.</code>开头的文件夹，需要在命令窗口操作：打开Windows的命令窗口（<code>Win键+X，C</code>），执行命令<code>mkdir C:\Users\&lt;Win用户名&gt;\.ssh</code>。</p><h3 id="生成密钥对"><a href="#生成密钥对" class="headerlink" title="生成密钥对"></a>生成密钥对</h3><p>因为加密算法是公开的，有多种工具可以生成密钥。<br>对Linux或MinGW，执行<code>ssh-keygen -t rsa -P &quot;&quot;</code> ，会在<code>~/.ssh/</code>生成密钥对<code>id_rsa.pub</code>和<code>id_rsa</code>。</p><p>xshell也可以生成密钥对：</p><ul><li>打开 “工具”-&gt; “新建用户密钥生成向导” 或 “工具”-&gt; “用户密钥管理者” -&gt; “生成” 生成一个密钥类型为RSA的密钥，向导的最后一步会显示公钥，可以将其保存起来；</li><li>选择刚创建的密钥，单击“导出”按钮，保存私钥，默认的格式与OpenSSH相同；</li><li>选择刚创建的密钥，单击“属性”按钮，在“公钥”选项卡中保存公钥。</li></ul><p><img src="/img/xshell-key.png" alt=""></p><h3 id="分发密钥对"><a href="#分发密钥对" class="headerlink" title="分发密钥对"></a>分发密钥对</h3><p>要启用密钥，需清除其它用户访问私钥的权限（600），并公钥拷贝到远程目标Linux主机的<code>.ssh/authorized_keys</code>文件中。<br>分发密钥对其实就是在在Windows和Linux之间传送文件，可以使用上面提到的<code>scp</code>和<code>sftp</code>，也可以参考后面要介绍的smb文件共享；或者更复杂一些，搭建一个Web服务器，把文件放到上面，在Linux执行<code>wget</code>或<code>curl</code>命令下载，Windows可以通过浏览器下载。下面还有另外两种方法。</p><h4 id="ssh-copy-id"><a href="#ssh-copy-id" class="headerlink" title="ssh-copy-id"></a>ssh-copy-id</h4><p>执行命令<code>ssh-copy-id -i 公钥文件 用户名@主机名或IP</code>，将公钥拷贝到远程Linux主机的<code>/home/&lt;用户名&gt;/.ssh/authorized_keys</code>文件中。当然，这个命令需要用密码访问远程主机。</p><h4 id="复制密钥文本"><a href="#复制密钥文本" class="headerlink" title="复制密钥文本"></a>复制密钥文本</h4><p>如将Linux主机上生成的私钥<code>id_rsa</code>拷贝到Windows上：</p><ul><li>使用xshell用密码登录到Linux，执行<code>cat ~/.ssh/id_rsa</code>，输出私钥的内容，复制输出的文字。</li><li>在Windows文件管理器中打开路径<code>C:\Users\&lt;Win用户名&gt;\.ssh</code>，在其中创建一个名为<code>id_rsa.txt</code>的文本文件，将上一步复制的文字粘贴进去，然后把文件名的<code>.txt</code>扩展名去掉，即改为<code>id_rsa</code>。</li></ul><p>可以参考上面的方式将Windows上生成的公钥拷贝到远程Linux主机上。因为还要从远程Linux主机上执行<code>git</code>、<code>ssh</code>等命令，所以也要把私钥放拷过去。当然，也可以使用不同的密钥对。</p><h3 id="ssh-config设置"><a href="#ssh-config设置" class="headerlink" title="ssh config设置"></a>ssh config设置</h3><p>在<code>~/.ssh/config</code>文件中可以设置多个远程主机的别名，地址，端口，用户名和密钥，简化ssh命令。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Host   别名</span><br><span class="line">    HostName 主机名或IP</span><br><span class="line">    Port     端口</span><br><span class="line">    User     用户名</span><br><span class="line">    IdentityFile   私钥文件</span><br><span class="line"></span><br><span class="line">Host u</span><br><span class="line">    Hostname  10.1.1.5</span><br><span class="line">    Port      22</span><br><span class="line">    User      ying</span><br><span class="line"></span><br><span class="line">Host          10.1.1.6</span><br><span class="line">Port          2222</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>这样就可以直接执行<code>ssh 别名</code>登录指定的主机，而且不同的主机可以使用不同的端口，用户，密钥配置。别名还可以用在<code>scp</code>的路径中。</p><h3 id="踢出ssh会话"><a href="#踢出ssh会话" class="headerlink" title="踢出ssh会话"></a>踢出ssh会话</h3><p>查看在线用户：<code>w</code> 或 <code>who</code>，两者输出格式有所不同。<br>查看自己的连接信息：<code>who am i</code>。<br>踢出其它会话：<code>pkill -9 -t pts/1</code>，其中<code>pts/1</code>是被踢会话的终端。</p><h1 id="远程共享文件（SMB-CIFS）"><a href="#远程共享文件（SMB-CIFS）" class="headerlink" title="远程共享文件（SMB/CIFS）"></a>远程共享文件（SMB/CIFS）</h1><p>“共享文件”（<a href="https://en.wikipedia.org/wiki/Server_Message_Block" target="_blank" rel="noopener">Server Message Block，SMB</a> )，改进的版本称为Common Internet File System，CIFS），是Windows上为局域网用户提供的远程访问文件的功能。Windows内置了smb的服务程序和客户端。<br>Samba是Linux上实现SMB/CIFS协议的开源服务程序及客户端。<br>Linux上与SMB/CIFS功能是类似的是“网络文件系统”（<a href="https://en.wikipedia.org/wiki/Network_File_System" target="_blank" rel="noopener">Network File System，NFS</a> ）。SMB和NFS功能相似，都是文件级别（相比于块级别iSCSI等方式）的远程存储服务。Windows默认没有安装NFS功能，但可以通过<code>控制面板→程序和功能→启用或关闭Windows功能</code>来添加NFS客户端和服务端软件。</p><blockquote><p>注意：只能共享某个文件夹，不能单独共享某个文件。Windows会限制能链接的共享用户数量，如果需要提供共享文件服务，Samba是更好的选择。<br>共享配合文件系统的权限设置，可以实现精细的权限控制，比如 “只能上传，不能下载，不能删除” 这样的需求（上传作业的文件服务器）。</p></blockquote><p>Linux一般内置了smb的客户端（mount.cifs模块）。如果没有，可以执行<code>sudo apt install cifs-utils</code>来安装。</p><h2 id="Samba访问Windows提供的共享文件"><a href="#Samba访问Windows提供的共享文件" class="headerlink" title="Samba访问Windows提供的共享文件"></a>Samba访问Windows提供的共享文件</h2><p>Windows上启用共享文件夹只要在文件夹的<code>属性对话框→共享选项卡→高级共享</code>中设置即可，在这个对话框中还可以指定用户和读写权限。共享名和实际的文件夹名可以不同。如果在共享文件名后添加<code>$</code>，就表示是隐藏的，必须通过输入完整路径才能打开。<br><img src="/img/win-share.png" alt="Windows上启用共享文件夹"></p><p>创建挂载点<code>mkdir ~/z</code>，并在<code>/etc/fstab</code>中添加<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//10.1.1.1/文档 /home/ying/z cifs username=Win用户名,password=Win密码,uid=1000,rw,iocharset=utf8,sec=ntlm 0 0</span><br></pre></td></tr></table></figure></p><p>执行<code>sudo mount -a</code>，挂载<code>/etc/fstab</code>中新增的设置。<br>执行<code>ls ~/z</code>，应列出共享文件夹中的内容，确认挂载成功。</p><blockquote><p>上面的命令将共享文件夹<code>文档</code>挂载到Ubuntu的<code>/home/ying/z</code>，有读写权限。因为设置了终端编码为UTF-8，中文的文件名也能正常显示。<br>其中uid是Ubuntu中用户<code>ying</code>的，具体的值可执行命令<code>id</code>，或在<code>/etc/passwd</code>中查看。</p></blockquote><h2 id="Windows访问Samba的共享文件"><a href="#Windows访问Samba的共享文件" class="headerlink" title="Windows访问Samba的共享文件"></a>Windows访问Samba的共享文件</h2><p>先要安装<code>Samba File Server</code>，执行<code>sudo apt install samba samba-common</code>。</p><blockquote><p>查看Samba Server的运行状态，执行<code>systemctl status smbd</code><br>启动，停止或重启服务，执行<code>sudo systemctl start/stop/restart smbd</code></p></blockquote><p>添加共享文件夹：执行 <code>sudo nano /etc/samba/smb.conf</code>，在末尾添加如下内容，添加了只读的根目录<code>/</code>和可读写的<code>/home/ying</code>目录，但显示为<code>all</code>和<code>ying</code>。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[all]</span><br><span class="line">    comment = fs root directory</span><br><span class="line">    path = /</span><br><span class="line">;   writeable = no</span><br><span class="line">;   browseable = yes</span><br><span class="line">    valid users = ying</span><br><span class="line"></span><br><span class="line">[ying]</span><br><span class="line">    comment = ying&apos;s home</span><br><span class="line">    path = /home/ying</span><br><span class="line">    writeable = yes</span><br><span class="line">    create mask = 0664</span><br><span class="line">    directory mask = 0775</span><br><span class="line">;   browseable = yes</span><br><span class="line">    valid users = ying</span><br></pre></td></tr></table></figure></p><p>将<code>ying</code>添加为smb的共享用户：<code>sudo smbpasswd -a ying</code>， 按提示设置<code>ying</code>的smb密码，<strong>可以与系统密码不同</strong>。<br>重启smbd，使设置生效：<code>sudo systemctl restart smbd</code>。</p><blockquote><p>Samba的权限问题：Samba中的用户需要是Ubuntu已有的用户，还要给Samba的用户设置相关文件和目录的读写权限。</p></blockquote><p>从Windows的文件管理器的地址栏访问 <code>\\10.1.1.5</code> ，会看到刚添加的两个共享文件夹。可以在文件夹上右击，快捷菜单中有 <strong>“映射网络驱动器”</strong> 的选项，也可以像普通文件夹一样创建快捷方式。除了IP地址，还可以通过Ubuntu的机器名来访问，若机器名为u，则地址为<code>\\u</code> 。</p><p>从macOS和Ubuntu访问共享文件（不论Windows或Ubuntu提供的）的路径格式是<code>smb://10.1.1.5</code>或<code>smb://u</code>。macOS会自动把共享文件挂载到<code>/Volumes</code>下。</p><blockquote><p>Windows可以通过机器名来访问Ubuntu是因为Samba默认开启了局域网内的<code>WINS</code>名字服务。<br>另一种方法是在<code>hosts</code>文件中为IP地址指定名字。</p></blockquote><p><img src="/img/smb.png" alt=""></p><blockquote><p>Samba共享文件与<code>sftp</code>的区别在于，<code>sftp</code>不能直接编辑文件，必须要把文件拷贝下来后才能处理，而操作共享文件跟本机的文件没有太大区别。<br>PS, <code>testparm</code>命令可以用来检查<code>smb.conf</code>的配置是否正确。</p><p>参考</p><ul><li><a href="https://wiki.samba.org/index.php/Setting_up_Samba_as_a_Standalone_Server" target="_blank" rel="noopener">Setting up Samba as a Standalone Server - samba wiki</a></li><li><a href="http://lybing.blog.51cto.com/3286625/1676515" target="_blank" rel="noopener">在CentOS 7中Samba服务安装和配置</a></li></ul></blockquote><h2 id="更改Samba的默认端口号"><a href="#更改Samba的默认端口号" class="headerlink" title="更改Samba的默认端口号"></a>更改Samba的默认端口号</h2><p>2017年5月份的勒索病毒WanaCrypt会扫描开放445文件共享端口的Windows设备，导致网络管理员禁封了445端口。如果客户端和服务器在同一局域网，通讯都是在二层，不会受到影响，可以正常使用共享文件，但如果经过路由器，就不能使用了。实际中发现即便是在同一个局域网，另外的实验室也无法访问我们实验室的共享文件，可能两个实验室各自的交换机又连到一个三层交换机上了吧。<br>估计445一封了之，是不会再有解封之日了。好在还可以变通一下，修改Samba的端口号，绕过封锁。不爽的是，Windows的默认端口号是无法修改的，而Linux，macOS，Android的ES文件管理器都支持指定端口号，地址格式是<code>smb://10.1.1.5:4455/home/</code>，其中4455是修改后的端口号。</p><p>修改Samba的端口号只需在<code>/etc/samba/smb.conf</code>中增加<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">   smb ports = 4455 445  # 可以同时监听多个端口号</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><h1 id="远程桌面"><a href="#远程桌面" class="headerlink" title="远程桌面"></a>远程桌面</h1><h2 id="mstsc"><a href="#mstsc" class="headerlink" title="mstsc"></a>mstsc</h2><p>Windows除家庭版之外均内置了远程桌面服务和客户端，使用的是远程桌面协议<a href="https://en.wikipedia.org/wiki/Remote_Desktop_Protocol" target="_blank" rel="noopener">Remote Desktop Protocol，RDP</a>。</p><ul><li>客户端在<code>所有程序→Windows附件→远程桌面连接</code>，或直接执行命令<code>mstsc</code>。</li><li>服务程序：依次打开<code>控制面板→所有控制面板项→系统</code>，或<code>Win+X，Y</code>，然后单击左侧的<code>高级系统设置</code>，打开<code>系统属性</code>对话框，在<code>远程</code>选项卡中的<code>远程桌面</code>部分选中<code>允许远程连接到此计算机</code>，并选择某个用户。<br><img src="/img/win-mstsc.png" alt="Windows上的远程桌面客户端"><br><img src="/img/win-mstsc-svr.png" alt="Windows上启用远程桌面"></li></ul><p>Ubuntu桌面版内置了可以访问Windows远程桌面的客户端；安卓和iOS系统也有远程桌面的App，但这三个系统都没有远程桌面的服务程序，Windows无法通过mstsc远程连接到它们的图形界面。<br>如果是在安卓平板或iPad上使用远程桌面连接到Windows系统，那么Windows会自动切换到触屏模式，就相当于在使用一个Windows系统的平板了，当然是台式机的性能。</p><p>Windows远程桌面一般只支持单个用户访问，如果有用户在使用远程桌面，那么本地的就会锁屏；但是服务器版可以设置支持多个用户同时使用远程桌面，彼此都是独立的窗口。</p><h2 id="vnc"><a href="#vnc" class="headerlink" title="vnc"></a>vnc</h2><p>VNC（<a href="https://en.wikipedia.org/wiki/Virtual_Network_Computing" target="_blank" rel="noopener">Virtual Network Computing</a>）是Linux上的远程桌面共享协议。Linux下有多个桌面环境，如Gnome，KDE，unity，xfce等，VNC对不同桌面系统的支持不同。此外，VNC的客户端及服务端也有多种实现，如x11vnc、realvnc、tigervnc、tightvnc、ultravnc等。Ubuntu Unity下自带了<code>远程共享</code>程序实现了VNC功能。由于vnc远比ssh占用的网络带宽大，而Linux上的大部分操作可以通过ssh来执行，所以不推荐使用VNC。<br>VNC默认桌面会话使用5900端口，可以开启多个桌面会话，新的VNC桌面会话的端口号依次增加。与Windows的远程桌面不同，VNC在远程访问时不会锁屏，而是同步显示默认桌面会话的显示。</p><p>可以参考教程[<a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-vnc-on-ubuntu-16-04" target="_blank" rel="noopener">https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-vnc-on-ubuntu-16-04</a>] ，在Ubuntu上安装和配置xfce桌面及tightvnc服务端。</p><p>Windows上没有内置的VNC客户端，有一些免费的<code>VNC-Viewer</code>程序。</p><blockquote><p>注意： 按上面的设置启用VNC后，使用的是xfce桌面环境，<br>默认的 <code>Tab</code> 键补全终端命令与窗口管理的快捷键冲突，需要在“Settings-&gt; Window Manager -&gt; Keyboard”中清除 <code>Switch Window from same application</code> 关联的快捷键<br>还可以在 “Settings-&gt; Keyboard -&gt; application shortcut” 中设置打开终端的快捷键 <code>exo-open --launch TerminalEmulator ~ Ctrl+Alt+T</code></p></blockquote><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>在局域网之外，如果网络连接比较复杂，mstsc或vnc可能都无法穿过机构强制的防火墙。有一些远程访问软件，比如 <strong><a href="https://www.teamviewer.com" target="_blank" rel="noopener">TeamViewer</a></strong>，<a href="http://sunlogin.oray.com/zh_CN/" target="_blank" rel="noopener">向日葵</a>等，可以实现广域网情形的远程访问，前提是两端的机器都能访问Internet公网，而mstsc和vnc则不要求必须能够访问公网。另一种方法是申请机构内的VPN。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一些基础的远程操作，包括ssh，共享文件，远程桌面。&lt;/p&gt;
    
    </summary>
    
      <category term="setup" scheme="https://ying-zhang.github.io/categories/setup/"/>
    
    
  </entry>
  
  <entry>
    <title>Hello Hexo！</title>
    <link href="https://ying-zhang.github.io/setup/2016/setup-hexo/"/>
    <id>https://ying-zhang.github.io/setup/2016/setup-hexo/</id>
    <published>2016-09-14T16:00:00.000Z</published>
    <updated>2018-10-15T15:19:53.263Z</updated>
    
    <content type="html"><![CDATA[<p>欢迎访问。<br>本博客使用<a href="http://hexo.io/" target="_blank" rel="noopener">Hexo</a>生成。本文记录了设置过程。</p><a id="more"></a><hr><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>是一个基于<a href="https://nodejs.org/" target="_blank" rel="noopener">Node.js</a>的博客生成工具。它把 <a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet" target="_blank" rel="noopener">Markdown 格式</a>的博客文章(Post)转换成一个静态的html博客网站，除了生成文章正文的html页面，还生成了博客列表，分类，tag等辅助页面.<br>hexo有多种博客主题可选，这里使用了 <a href="https://github.com/hejianxian/hexo-theme-jane" target="_blank" rel="noopener">jane 主题</a>。<br><a href="https://github.com" target="_blank" rel="noopener">Github</a>提供了<code>https://[github-userId].github.io</code> 这样的二级域名的静态html站点的托管服务，还可以通过<code>CNAME</code>设置自己的域名（需向域名服务商购买）。</p><p>下面的设置过程参考了<a href="http://mclspace.com/2014/10/19/about-hexo/" target="_blank" rel="noopener">hexo简易教程</a> 和 <a href="http://methor.github.io/%E5%B7%A5%E5%85%B7/hexo/hexo-install-config/" target="_blank" rel="noopener">hexo_install_config</a>。</p><h1 id="在-Ubuntu-上安装所需程序"><a href="#在-Ubuntu-上安装所需程序" class="headerlink" title="在 Ubuntu 上安装所需程序"></a>在 Ubuntu 上安装所需程序</h1><p>在终端执行下面的命令。</p><h2 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install git</span><br></pre></td></tr></table></figure><p>设置 git</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name  &quot;ZHANG Ying&quot;</span><br><span class="line">git config --global user.email &quot;your@email.com&quot;</span><br><span class="line">git config --global core.autocrlf input  # true会将LF转换为CRLF，false则不做任何处理</span><br></pre></td></tr></table></figure><p>git默认使用<code>~/.ssh</code>下的 key，需要在Github上注册对应的public key才能提交代码。</p><h2 id="安装node-js"><a href="#安装node-js" class="headerlink" title="安装node.js"></a>安装node.js</h2><p>a. 从Node.js官网 <a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">https://nodejs.org/en/download/</a> 下载Linux-x64系统的二进制安装包，解压到<code>/usr/local/</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">ver=v8.12.0</span><br><span class="line">wget https://nodejs.org/dist/$&#123;ver&#125;/node-$&#123;ver&#125;-linux-x64.tar.xz</span><br><span class="line"></span><br><span class="line">tar axf node-$&#123;ver&#125;-linux-x64.tar.xz</span><br><span class="line">cd node-$&#123;ver&#125;-linux-x64/</span><br><span class="line">sudo cp -r ./ /usr/local/</span><br><span class="line">cd ..</span><br><span class="line">rm -rf node-$&#123;ver&#125;-linux-x64.tar.xz</span><br></pre></td></tr></table></figure><p>b. 通过添加软件源的方式<br>参考<a href="https://nodejs.org/en/download/package-manager/" target="_blank" rel="noopener">Installing Node.js via package manager</a>，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -</span><br><span class="line">sudo apt install -y nodejs</span><br><span class="line"></span><br><span class="line">sudo apt install -y build-essential #如果npm安装的包需要在本地编译，则需要安装编译工具如gcc等</span><br></pre></td></tr></table></figure><h1 id="在Windows-10上安装所需程序"><a href="#在Windows-10上安装所需程序" class="headerlink" title="在Windows 10上安装所需程序"></a>在Windows 10上安装所需程序</h1><h2 id="安装git-1"><a href="#安装git-1" class="headerlink" title="安装git"></a>安装git</h2><p>从git官网 <a href="https://git-scm.com/downloads" target="_blank" rel="noopener">https://git-scm.com/downloads</a> 下载Windows 系统的 Git客户端安装程序。<br>执行安装程序，建议</p><ul><li>将其安装到<code>C:\git</code>这样比较短的路径下，方便以后敲命令，</li><li>并且选择 Use Git and optional Unix tools from the Windows Command Prompt ，</li><li>还要在 How should Git treat line endings in text files? （处理换行符）选项中选择 Checkout as-is, commit Unix-style line endings 。</li></ul><blockquote><p>安装git的同时会安装<a href="http://www.mingw.org/" target="_blank" rel="noopener">MinGW(Minimalist GNU for Windows)</a>，上面的选项会把git和MinGW的可执行程序添加到<code>PATH</code>环境变量中，这样就可以方便地在Windows命令行窗口直接使用git和其它常用的Unix命令了。<br>安装git后，<code>C:\git\usr\bin</code>下面的<code>.exe</code>程序就是MinGW支持的Unix命令，如bash, ls, mv, cp, grep, cat, sort, head, tail, wc, vim, tar, curl, ssh, scp等。</p></blockquote><p>打开命令窗口（快捷键为Win+X，C或A），参考上面Ubuntu系统的命令设置git 的用户名，Email。<br>Windows系统上git默认使用<code>C:\Users\[UserName]\.ssh</code>下的 key。</p><blockquote><p>以<code>.</code>开头的文件夹需要在命令窗口执行<code>mkdir</code>来创建。</p></blockquote><h2 id="安装node-js-1"><a href="#安装node-js-1" class="headerlink" title="安装node.js"></a>安装node.js</h2><p>从Node.js <a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">https://nodejs.org/en/download/</a> 下载<a href="https://nodejs.org/dist/v8.12.0/node-v8.12.0-x64.msi" target="_blank" rel="noopener">Windows x64系统的二进制安装包</a> 。<br>执行安装程序，建议将其安装到<code>C:\nodejs</code>，并选择将其添加到<code>PATH</code>路径中。</p><h1 id="修改-npm-源"><a href="#修改-npm-源" class="headerlink" title="修改 npm 源"></a>修改 npm 源</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config set registry http://registry.npm.taobao.org/</span><br></pre></td></tr></table></figure><h1 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h1><p>打开命令窗口，执行下面的命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure></p><h1 id="初次设置"><a href="#初次设置" class="headerlink" title="初次设置"></a>初次设置</h1><h2 id="初始化博客文件夹"><a href="#初始化博客文件夹" class="headerlink" title="初始化博客文件夹"></a>初始化博客文件夹</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init blog</span><br></pre></td></tr></table></figure><p>在Github创建一个名为<code>[github-userId].github.io</code>的项目。</p><h2 id="安装rss插件，git插件，math插件"><a href="#安装rss插件，git插件，math插件" class="headerlink" title="安装rss插件，git插件，math插件"></a>安装rss插件，git插件，math插件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-feed --save</span><br><span class="line">npm install hexo-deployer-git   --save</span><br><span class="line">npm install hexo-math           --save</span><br></pre></td></tr></table></figure><h2 id="设置-config-yml"><a href="#设置-config-yml" class="headerlink" title="设置 _config.yml"></a>设置 <code>_config.yml</code></h2><p>在 <code>_config.yml</code> 修改博客名，固定链接格式，主题，deploy repo 等。部分设置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">## Themes: https://hexo.io/themes/</span><br><span class="line">theme: jane</span><br><span class="line"></span><br><span class="line"># Deployment</span><br><span class="line">## Docs: https://hexo.io/docs/deployment.html</span><br><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: git@github.com:ying-zhang/ying-zhang.github.io.git</span><br><span class="line">  branch: master</span><br><span class="line"></span><br><span class="line">math:</span><br><span class="line">  engine: &apos;mathjax&apos;</span><br><span class="line">  mathjax:</span><br><span class="line">    src: https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML</span><br></pre></td></tr></table></figure><h2 id="使用jane主题"><a href="#使用jane主题" class="headerlink" title="使用jane主题"></a>使用<a href="https://github.com/hejianxian/hexo-theme-jane" target="_blank" rel="noopener">jane主题</a></h2><p>这里没有使用git clone来下载 jane 主题的代码库，而是直接下载代码库的zip文件，解压到<code>themes/</code>文件夹。<br>直接在主题文件中修改了等宽字体，及正文的宽度。<br>顺便删除默认主题landscape。</p><blockquote><p>对jane主题的修改：将侧栏移到左侧，这个在项目repo已经<a href="https://github.com/hejianxian/hexo-theme-jane/issues/5" target="_blank" rel="noopener">有人提过issue</a>，作者的方案需要手动修改<code>style.sty</code>，跟我摸索发现的一样，我还修改了滚动条显示的样式。</p></blockquote><h2 id="文件结构"><a href="#文件结构" class="headerlink" title="文件结构"></a>文件结构</h2><div class="table-container"><table><thead><tr><th>文件/文件夹</th><th>说明</th></tr></thead><tbody><tr><td><code>_config.yml</code></td><td>博客的主配置文件</td></tr><tr><td><code>.deploy_git/</code></td><td>用于push到Github、heroku等的git仓库，里面有与<code>public/</code>相同的内容及<code>.git</code>的记录</td></tr><tr><td><code>public/</code></td><td>生成的完整的静态html网站，执行 <code>hexo clean</code> 会清除此文件夹</td></tr><tr><td><code>scaffolds/</code></td><td>里面有三个<code>.md</code>文件，其中<code>post.md</code>是博客文章的默认模板</td></tr><tr><td><code>node_modules/</code></td><td>每个blog的文件夹中安装的hexo插件</td></tr><tr><td><code>source/</code></td><td>撰写的博客文章要放在<code>source/_post</code>下，<code>source/</code>文件夹下的.md文件都会被生成为.html文件，其它类型的文件和文件夹则保持原样复制到 <code>public/</code>。可以在这里新建一个 <code>img/</code> 文件夹用于保存图片，文章中可以用<code>![图片说明](/img/image.png)</code>这样的代码来插入图片。</td></tr><tr><td><code>themes/</code></td><td>存放主题相关文件，各主题也有自己的<code>_config.yml。</code></td></tr></tbody></table></div><h2 id="修改scaffold-post-md模板"><a href="#修改scaffold-post-md模板" class="headerlink" title="修改scaffold/post.md模板"></a>修改<code>scaffold/post.md</code>模板</h2><p>增加catagory，tags，及摘要和正文的分割线<code>&lt;!--more--&gt;</code>。</p><blockquote><p>注意，Markdown对空格和空行敏感。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: &#123;&#123; title &#125;&#125;</span><br><span class="line">date: &#123;&#123; date &#125;&#125;</span><br><span class="line">category: misc</span><br><span class="line">tags: [tag1, tag2]</span><br><span class="line">---</span><br><span class="line">摘要部分</span><br><span class="line">&lt;!--more--&gt;</span><br><span class="line">---</span><br><span class="line">正文部分</span><br></pre></td></tr></table></figure><h2 id="修改-hexo-server默认的4000端口号为80"><a href="#修改-hexo-server默认的4000端口号为80" class="headerlink" title="修改 hexo-server默认的4000端口号为80"></a>修改 hexo-server默认的4000端口号为80</h2><p>如果本机没有跑web服务器占用80端口的话，可以让hexo-server使用80端口而不是默认的4000端口，这样在浏览器直接输入机器名就可以预览blog了。<br>需修改<code>node_modules/hexo-server/index.js</code> 第8行 <code>port</code>。<br>比如我的机器名是z，在chrome地址栏直接输入 <code>z/</code> 即可，ie则需要输入 <a href="http://z/" target="_blank" rel="noopener">http://z/</a></p><h1 id="hexo-基本操作"><a href="#hexo-基本操作" class="headerlink" title="hexo 基本操作"></a>hexo 基本操作</h1><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo s     # server   本地预览，http://localhost:4000 。</span><br><span class="line">hexo d     # deploy   部署整个网站到heroku</span><br><span class="line">hexo g     # generate 生成静态html</span><br><span class="line"></span><br><span class="line">hexo s -g  # 本地预览，编辑了博客文章后，不必重新运行该命令，刷新页面即可，直到按 `Ctrl + C`会退出。</span><br><span class="line">hexo d -g  # 依次执行生成和部署</span><br><span class="line"></span><br><span class="line">hexo clean # 删除 public/ 文件夹下所有内容</span><br></pre></td></tr></table></figure><h2 id="撰写文章"><a href="#撰写文章" class="headerlink" title="撰写文章"></a>撰写文章</h2><p>执行下面的命令，在<code>source/_posts/</code>下生成名为 <code>New-Post.md</code> 的文件。<br>也可以通过常规的文件操作在<code>source/_posts/</code>下新建一个 <code>New-Post.md</code> 文件。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo n &quot;New Post&quot;</span><br></pre></td></tr></table></figure><p>更多详情可参考<a href="http://hexo.io/docs/writing.html" target="_blank" rel="noopener">使用hexo写作</a>的文档。</p><h2 id="发布静态html的博客网站到-Github"><a href="#发布静态html的博客网站到-Github" class="headerlink" title="发布静态html的博客网站到 Github"></a>发布静态html的博客网站到 Github</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo d -g</span><br></pre></td></tr></table></figure><h2 id="为整个blog建立repo"><a href="#为整个blog建立repo" class="headerlink" title="为整个blog建立repo"></a>为整个blog建立repo</h2><p>Hexo可以将生成的静态html博客网站发布到git仓库，但不会同步<code>source/</code>下源文件，<code>_config.yml</code>设置等。<br>如果需要在别的机器上写blog，还要重新设置，并拷贝这些文件。<br>为此，为已经设置好的博客建立一个新的git repo。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd blog/</span><br><span class="line">git init</span><br></pre></td></tr></table></figure><p>编辑<code>.gitignore</code>如下。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.DS_Store</span><br><span class="line">Thumbs.db</span><br><span class="line">node_modules/</span><br><span class="line">themes/</span><br><span class="line">public/</span><br><span class="line">.deploy_git/</span><br><span class="line">.npmignore</span><br></pre></td></tr></table></figure></p><blockquote><p>注意：把<code>node_modules/</code>和<code>themes/</code>排除，但把这两个文件夹分别压缩后，这里使用7zip压缩，生成<code>node_modules.7z</code> 和 <code>themes.7z</code> 会包括在git repo中。</p></blockquote><p>在Github创建一个名为<code>blog</code>的项目，<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m &quot;Init&quot;</span><br><span class="line">git remote add github git@github.com:ying-zhang/blog.git</span><br><span class="line">git push -u github master</span><br></pre></td></tr></table></figure></p><h2 id="克隆已有的blog项目"><a href="#克隆已有的blog项目" class="headerlink" title="克隆已有的blog项目"></a>克隆已有的blog项目</h2><p>需要已经安装好了 git，nodejs 和 hexo。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone git@github.com:ying-zhang/blog.git</span><br><span class="line">cd blog</span><br><span class="line"></span><br><span class="line">git remote rename origin github</span><br><span class="line"></span><br><span class="line">npm install --save</span><br><span class="line">7z x themes.7z</span><br></pre></td></tr></table></figure></p><h1 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h1><p>Windows 下编辑文本需要注意编码，应使用 utf8 无bom 格式的编码，建议使用 VS Code 编辑器。</p><h2 id="编辑数学公式"><a href="#编辑数学公式" class="headerlink" title="编辑数学公式"></a>编辑数学公式</h2><p>注意，需要<code>hexo-math</code>插件，但这个插件的作者已经停止维护了，不知有什么替代的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;% math %&#125;</span><br><span class="line">\begin&#123;align*&#125;</span><br><span class="line">\begin&#123;align*&#125;</span><br><span class="line">-\sum_i&#123;P_i\log_2\frac&#123;P_i&#125;&#123;Q_i&#125;&#125; =&amp; \sum_i&#123;P_i\log_2\frac&#123;Q_i&#125;&#123;P_i&#125;&#125; \\</span><br><span class="line">                                \le&amp; \log_2\sum_i&#123;P_i\frac&#123;Q_i&#125;&#123;P_i&#125;&#125; \tag&#123;Jensen 不等式&#125; \\</span><br><span class="line">                                  =&amp; \log_2\sum_i&#123;Q_i&#125; \\</span><br><span class="line">                                  =&amp; 0</span><br><span class="line">\end&#123;align*&#125;</span><br><span class="line">&#123;% endmath %&#125;</span><br></pre></td></tr></table></figure></p><span>$$\begin{align*}-\sum_i{P_i\log_2\frac{P_i}{Q_i}} =&amp; \sum_i{P_i\log_2\frac{Q_i}{P_i}} \\                                \le&amp; \log_2\sum_i{P_i\frac{Q_i}{P_i}} \tag{Jensen 不等式} \\                                  =&amp; \log_2\sum_i{Q_i} \\                                  =&amp; 0\end{align*}$$</span><!-- Has MathJax --><h2 id="设置代码块不显示行号"><a href="#设置代码块不显示行号" class="headerlink" title="设置代码块不显示行号"></a>设置代码块不显示行号</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;% codeblock line_number:false%&#125;</span><br><span class="line">echo &quot;Hello Hexo!&quot;</span><br><span class="line">&#123;% endcodeblock %&#125;</span><br></pre></td></tr></table></figure><hr><p>飞鸟集 第128</p><blockquote><p>如果你不等待着要说出完全的真理，那末把话说出来是很容易的。</p></blockquote><p>所以，就随便写吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;欢迎访问。&lt;br&gt;本博客使用&lt;a href=&quot;http://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;生成。本文记录了设置过程。&lt;/p&gt;
    
    </summary>
    
      <category term="setup" scheme="https://ying-zhang.github.io/categories/setup/"/>
    
    
  </entry>
  
  <entry>
    <title>罗网是坚韧的</title>
    <link href="https://ying-zhang.github.io/misc/2016/obstinate-are-the-trammels/"/>
    <id>https://ying-zhang.github.io/misc/2016/obstinate-are-the-trammels/</id>
    <published>2016-05-31T16:00:00.000Z</published>
    <updated>2018-06-03T15:11:12.709Z</updated>
    
    <content type="html"><![CDATA[<p>这是一篇吐槽文，想到啥就写啥，不定期吐槽。。。<br>为了清净，把日期改了，手工置底。</p><a id="more"></a><hr><p>吉檀迦利</p><blockquote><p>第28<br>罗网是坚韧的，但是要撕破它的时候我又心痛。<br>我只要自由，为希望自由我却觉得羞愧。<br>我确知那无价之宝是在你那里，而且你是我最好的朋友，但我却舍不得清除我满屋的俗物。<br>我身上披的是尘灰和死亡之衣；我恨它，却又热爱地把它抱紧。<br>我的债务很多，我的失败很大，我的耻辱秘密而又深重；但当我来祈福的时候，我又战栗，唯恐我的祈求得到了允诺。</p></blockquote><p>飞鸟集</p><blockquote><p>第142<br>让我设想，在群星之中，有一颗星是指导着我的生命通过不可知的黑暗的。</p><p>第278<br>我们在热爱世界时便生活在这世界上。</p></blockquote><p><img src="/img/4books_IMG_20150328_201923.jpg" alt=""></p><hr><hr><p>2017年已经过去一周了，真是失败的一年，特别是秋季这个学期。<br>没有什么可总结的，反省吧！</p><hr><h1 id="读书"><a href="#读书" class="headerlink" title="读书"></a>读书</h1><p>每当一段时间心情低落，我就会念两句诗，当然，不是“他”念的『苟利国家生死以，岂因祸福避趋之』，而是泰戈尔的几篇。我是高中时候读的《泰戈尔诗选》，那一版收录了《吉檀迦利》，《飞鸟集》，《新月集》等。我念的是我们县的高中，好多年都没有考上过清华北大的，不过我们的物理老师兼班主任收了班费为我们买了一套语文课列的文学读物，这也算是素质教育了吧。高中读的另外几本好书是《伯克利物理学教程》的力学和电磁学部分，所以本科专业是电气工程；《从一到无穷大》，科普佳作，这几本书都是从高中的校图书馆软磨硬泡混进书架找到的，当时的校图书馆只有一间屋子，不是开放式的书架，而是一个老师在窗口，我们从抽屉里不完整的图书卡片里翻找要借的书；此外还有姥爷的一大本手抄油印的文革后期的《解析几何和高等数学》。</p><p><a href="/doc/walden.pdf">《瓦尔登湖》PDF</a>是工作后才读的。它和《吉檀迦利》都是很安静的，很耐读的书。我记下了分别是2008-09、2009-05工作头一年，2010-07在英国出差独居的大半年，2013-01辞职前两个月和2013-07，2014-04考研前后读了《瓦尔登湖》。链接的PDF文件是我根据纸书，从网上的文字版整理校对排版制作出来的。自己排版当然首先是非常喜欢这本书，还有本科在教务处帮史老师制作毕设Word模板和自己毕设时<a href="https://wenku.baidu.com/view/a668646a1eb91a37f1115c35.html" target="_blank" rel="noopener">积累了一些Word排版知识</a>，再者是受<a href="http://www.sendsms.cn/box/dl/_25B6_25B9_25B0_25EA_25B6_25C1_25CA_25E9/_25BF_25C6_25C6_25D5/_25A1_25B6_25B4_25D3_25D2_25BB_25B5_25BD_25CE_25DE_25C7_25EE_25B4_25F3_25A1_25B7.pdf" target="_blank" rel="noopener">《从一到无穷大》PDF</a> 的启发，这份PDF文件精确还原了纸书的排版，简直是强迫症和完美主义者的福音。不过我排版《瓦尔登湖》的时候没有按照纸书的尺寸排版（原因是不知道准确的尺寸，不过还原了英文初版的封面），第一版使用的字体是宋体，后来改成了仿宋，增加了一些章节的题图。</p><p>其它值得推荐的书就是《中国历代政治得失》（读完再看<a href="https://www.zhihu.com/question/20568811" target="_blank" rel="noopener">知乎的评论</a>）、《小王子》和《平凡的世界》了。</p><p>把上面提到的书列下来：</p><ul><li>泰戈尔诗选：吉檀迦利，飞鸟集，新月集，园丁集，故事诗</li><li>伯克利物理学教程：力学，电磁学，可惜当时高中图书馆没有统计力学和量子力学</li><li>从一到无穷大</li><li>瓦尔登湖</li><li>中国历代政治得失</li><li>小王子</li><li>平凡的世界</li></ul><hr><h1 id="离开是怎样的一种体验？"><a href="#离开是怎样的一种体验？" class="headerlink" title="离开是怎样的一种体验？"></a>离开是怎样的一种体验？</h1><p>转眼半年过去了，很多熟悉的同学离开了，有的是远走异国他乡，有的只在楼下，然而离开就是离开了。旁边的格子来来去去换了两个人了。<br>年初魏大神还一直不想搬下去，我和mio一直劝他搬到三楼独占的办公室去，mio是觊觎他的格子，我则是认为他要尽快换了环境，才好转换身份，适应工作。拖来拖去，直到三楼办公室有了同事，魏大神才搬下去。mio终于如愿获得了角落里的这个格子，据说这个是风水最好的位子了，然而mio很晚才拿到阿里的实习offer，位子刚坐热，就去杭州了。<br>顾博则是坚持发完了paper才奔赴UC Davis，从此再也没有咖啡机的噪音，顾博也不会过来吐槽，时不时揭露我四十岁也不一定能毕业的事实了。<br>预答辩之后，猴子和我在食堂偶遇翔总，正好可以好好向翔总总结一下我们的人生经验，避免重蹈覆辙。来到南大这三年，从来没有像那天说了那么多的话，而且看来对翔总还是有点帮助的。昨天（2017-06-22）系里的毕业典礼，之后吃了最后一顿散伙饭，把他们四个从群里移除去了，然而老板不但没有注意到，还告诫他们“好日子到头了”，难道不会说句“前程似锦”吗？我只好截了图分别转告给当事人。<br>今天看到猴子把桌子收拾干净了，多余打印的毕业论文都扔掉了，拉着箱子等电梯。我犹豫了一下要不要目送他进了电梯，然而还是转身走开了。我去年曾告诉他，2014年我来南大报到时，第一个见到的就是他坐在系楼大厅接待桌。当时已经是下午了，我应该算最后一批报到的了，他还问我是老师还是学生。好吧，我自以为脸上还有学生气，然而实际那时已经是大叔模样了，更不用说三年之后的现在。</p><p>离开是怎样的一种体验？2014年考完研之后，我看到知乎的这个问题，想回答一下离开大亚湾、大鹏镇的体验，但终究没有写，放到这里把。同事的传统是离开之前给科里群发发一封告别的Email。我在离开之前已经收集了好几封了，有调去外地公司的，也有辞职当公务员的，连当年关老板的告别邮件都见到了。<br>然而我只是悄悄的走了。<br>我选了3月18日跟高科说辞职的事，一是为了拿到年终奖（后来发现是多虑了），二来是两轮大修的间隙，再者是取“散了吧”的谐音。Long March即是当时的纠结，也是对不确定的将来的担忧与期待。好在当时老婆坚定地支持我。当然是希望能在长征之后有所作为的。不过即便考研失败，还有希望师傅经过关老板的关系去秦山搞老本行。离开大鹏镇去了嘉兴。那里既有普文两口，又有海盐秦山，再没其他熟人，可以专心复习。<br>走的那天又一轮大修开始了，大家都在通宵停机保驾，我还是灰溜溜地走吧，至少几天前老刘还去吃饭送别了一下呢。和老婆来到嘉兴，QQ上的好友删到只剩十几个，通讯录只剩9个，手机也换了号。QQ的签名从Long March改成了海阔天空。普文留言说，就这点感慨啊，我回复说还没开始感慨呢。因为马上要投入复习，而且离开早是计划之中的事，成为事实，也就没有太多感慨了。<br>真是神奇，居然考上了。虽然离开嘉兴时有点不舍，当时还是满心计划着南京的生活的。现在看来，长征只是开始，而且没有剧透说只有两万五千里，更没想到雪山草地如此难行。<br>三年过去了。头一年住在和园，泡在实验室的时间很少，即便是14级的几位同学也没混熟，后来呆在实验室的时间多了，有的是讨论班、有的是上课小组合作、有的是同去印度出差，之后换了组，居然有猴子，也算是有点缘分吧。<br>然而现在熟悉的人基本都走了。<br>除了离开，留下来看别人离开，可能更难过。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一篇吐槽文，想到啥就写啥，不定期吐槽。。。&lt;br&gt;为了清净，把日期改了，手工置底。&lt;/p&gt;
    
    </summary>
    
      <category term="misc" scheme="https://ying-zhang.github.io/categories/misc/"/>
    
    
  </entry>
  
  <entry>
    <title>如果有一支笔</title>
    <link href="https://ying-zhang.github.io/misc/2016/a-story-of-stylus/"/>
    <id>https://ying-zhang.github.io/misc/2016/a-story-of-stylus/</id>
    <published>2016-05-19T16:00:00.000Z</published>
    <updated>2018-06-03T15:10:59.469Z</updated>
    
    <content type="html"><![CDATA[<p>这是一个我四年前的想法，但一直没有实现。所以说，这也是一个“<a href="https://www.zhihu.com/question/22989105" target="_blank" rel="noopener">就差一个软件工程师了</a>”的悲伤的故事（其实还缺一个硬件工程师）。<br>为了清净，把日期改了，手工置底。</p><a id="more"></a><hr><h1 id="xPen"><a href="#xPen" class="headerlink" title="xPen"></a>xPen</h1><p><a href="https://en.wikipedia.org/wiki/Computer_mouse" target="_blank" rel="noopener">鼠标</a>是图形用户界面的主要输入设备。其实在鼠标（1968年原型诞生）之前，还有一种<a href="https://en.wikipedia.org/wiki/Light_pen" target="_blank" rel="noopener">光笔（1955年）</a>的设备。光笔需要直接在屏幕上操作，其实跟现在的电容笔+触摸板用法差不多，但显然不如鼠标放在桌上操作舒服，现在很少有人听说过这种设备了。笔式输入设备的特点是能提供类似书写的体验，用鼠标写一个字的体验是相当别扭的，但是如果把鼠标做成一个笔的形状，工作原理没有变化，但感觉上就会方便多了。<br>近些年的Surface，iPad等设备也有<a href="https://en.wikipedia.org/wiki/Stylus_%28computing%29" target="_blank" rel="noopener">配套的笔</a>，更早就有PC上用来绘画的的数码笔/绘图笔（Wacom），但普通用户对这些设备都接触不多。这些笔都要有一个 <strong>板子</strong> 来配套，与传统的纸笔对应，一是不方便，二是增加了整体成本。另外，可能用户对笔式输入设备的印象局限在手写或绘图场景，其实它是可以像鼠标那样来操作GUI的光标的，但用户购买这些设备显然是为了手写或绘图。<br>我曾经买过一个几百元的低档数位板，它的鼠标模式需要一直将笔 <strong>悬着保持离板子几毫米的距离</strong>，用起来是很累的，其实如果没有运行支持绘图的应用，完全可以将笔在板子上移动的操作对应为鼠标的移动光标操作。<br>我的想法是设计一种笔式的输入设备，暂叫 <strong>xPen</strong> 吧（好没创意），不再需要配套的 <strong>板子</strong>，只要笔本身即可；当然要以无线的方式连接PC，也可以用到触摸平板等设备上，但主要是面向PC用户，目标是取代鼠标，既提供基础的移动光标功能，也提供手写和绘图等高级功能。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>这样说来 <strong>xPen</strong> 比现有的笔式设备只是少了配套的 <strong>板子</strong>，功能是相近的，要想让普通用户接受，除了价格和使用体验，还要讲好故事，介绍一些更合适的应用场景。在传统的PC办公场景，要把代替鼠标的移动光标功能作为主要功能，而手写和绘图则是增强功能，这样才能引起普通用户的兴趣，而不只是笔式设备的传统用户；教育应该是最适合的一个场景，因为数理化等学科的公式符号等不容易通过键盘鼠标输入，对手写功能有比较强的需求；课堂和会议演示中在ppt手写批注也是一个比较好的场景，理想的情况是能够取代黑板的位置。</p><h2 id="结构设计"><a href="#结构设计" class="headerlink" title="结构设计"></a>结构设计</h2><p>设计xPen，首先需要了解一下我们熟悉的鼠标的工作原理。鼠标的有两个主要组件：定位组件，左右两个按键和中间的滚轮（也是中键）。定位组件是底部的光电模组，激光照射在桌面上，反射到光电传感器，通过比较传感器相邻两次接收的图像，可以计算出鼠标的位移变化（Δx，Δy），即可控制屏幕上的光标按比例移动。</p><blockquote><p>说起来似乎很简单，但不清楚具体算法是如何高效实现的。</p></blockquote><p>比较微妙的是，</p><ul><li>鼠标的物理位置与屏幕光标是相对的，如果拿起鼠标移动一段距离，屏幕上的光标一般是保持不动的；再把鼠标放到桌面上移动，屏幕的光标则从刚才保持的位置开始移动。</li><li>鼠标的物理移动距离与屏幕光标的移动距离有一个换算比例，用户很快就能适应这个换算过程。</li><li>鼠标的形状设计隐含着 <strong>前后朝向</strong> 的区分。</li></ul><p>与鼠标不同，传统的笔式设备定位功能是靠配套的 <strong>板子</strong> 实现的。对于近几年常见的触摸平板，使用手指或笔时，定位都是屏幕的绝对位置；虽然绘图板与屏幕直接存在位置比例变换，但对绘图板而言也是绝对定位。绝对定位的情况就不需要考虑前后朝向的问题了。</p><h3 id="基于光电原理"><a href="#基于光电原理" class="headerlink" title="基于光电原理"></a>基于光电原理</h3><p>没有了 <strong>板子</strong> ，xPen如何实现定位呢？其实已经有把鼠标光电模组小型化后改成的“笔”，原理跟鼠标一样，比如下面两种：</p><p>（Chrome浏览器请单击一下视频，才能允许播放Flash）</p><p>这是<a href="https://v.qq.com/x/page/o0300z5or2g.html" target="_blank" rel="noopener">QQ视频的一个国内产品</a>，有美女哦，广告也就忍了吧~~</p><embed src="https://imgcache.qq.com/tencentvideo_v1/playerv3/TPout.swf?max_age=86400&v=20161117&vid=o0300z5or2g&auto=0" allowfullscreen="true" quality="high" width="480" height="400" align="middle" allowscriptaccess="always" type="application/x-shockwave-flash"><p>下面的是<a href="http://www.bilibili.com/video/av7709459/" target="_blank" rel="noopener">B站的一个视频</a>，介绍的是国外的 <a href="https://www.kickstarter.com/projects/1958554063/phree-make-the-world-your-paper" target="_blank" rel="noopener">Phree</a>。这个产品做的很接近我的想法，但这个视频故事没讲好，说服力不够。</p><embed height="415" width="544" quality="high" allowfullscreen="true" type="application/x-shockwave-flash" src="//static.hdslb.com/miniloader.swf" flashvars="aid=7709459&page=1" pluginspage="//www.adobe.com/shockwave/download/download.cgi?P1_Prod_Version=ShockwaveFlash"><p>Phree是最近推出的产品，明显比上面那个国内的产品漂亮多了，而且没有侧面的一堆按键。如果完全照搬鼠标的设计，手写时还需要按着左键，体验还是不够方便的。笔尖不够尖的话，也影响手写的体验。</p><h3 id="基于陀螺仪，加速度计"><a href="#基于陀螺仪，加速度计" class="headerlink" title="基于陀螺仪，加速度计"></a>基于陀螺仪，加速度计</h3><p><a href="https://www.zhihu.com/question/28532904" target="_blank" rel="noopener">姿态传感器</a>有3轴（陀螺仪或加速度计，x/y/z三个方向）、6轴（陀螺仪+加速度计）、9轴（陀螺仪+加速度计+磁场），在手机和<a href="https://www.zhihu.com/question/52083051" target="_blank" rel="noopener">平板中比较普遍</a>了，无人机也是用它来定位和导航的（结合GPS）。陀螺仪（Gyroscope，测量角速度）和加速度计（Accelerometer）是根据力学原理来测量和计算位置的变化的。<br>下面几篇文章就是用位置传感器实现空中鼠标或笔的功能：</p><ul><li>MobiHeld09 - PhonePoint Pen - using mobile phones to write in air 和 MobiSys11 - Using mobile phones to write in air，使用的是诺基亚N95；</li><li>THMS15 - GyroPen - Gyroscopes for Pen-Input With Mobile Phones（Youtube有演示视频）；</li><li>上海交大08 - 基于微加速度计的Air-Mouse的研究 - 姜晓波</li><li>中科大09 - 基于加速度传感器的电子笔系统的设计 - 王庆召</li><li>华中科技14 - 基于MEMS惯性传感器的空中输入笔研究 - 赵威</li><li>华中科技16 - 基于惯导信号的手写数字识别研究 - 张桂花 - （和上面赵威的导师都是郭鹏老师）</li><li>华中科技16 - 智能机顶盒多功能遥控器的设计与实现 - 陈姿</li><li>基于MPU6050六轴传感器的悬空鼠标设计与实现，李士垚等，电子制作，2016</li></ul><h3 id="xPen的设计考虑"><a href="#xPen的设计考虑" class="headerlink" title="xPen的设计考虑"></a>xPen的设计考虑</h3><p>既然都有产品和文章了，当然还有很多专利，那xPen还能想到什么不一样的地方呢？</p><ul><li>xPen主要是针对 <strong>水平的桌面上使用的场景</strong>，而不是在空中的Air Mouse，因为在桌面上书写更自然，而且后者不够频繁；</li><li>xPen使用陀螺仪和加速度计这种姿态传感器来定位，而不是光电传感器，因为姿态传感器感知的参数更多，潜在的发展方向也更多；鼠标的相对定位特性允许在姿态传感器静止时（其实可以是任何随机时刻） <strong>重置内部的位置状态，避免导航场景中误差积累的问题</strong>；</li><li>xPen有一个 <strong>压感笔尖</strong>。当压感笔尖存在压力输出，对应为“移动光标”；压力 <strong>超过一定阈值</strong>，对应为拖动或书写（特定App下）。这样就不用像鼠标那样书写时需要一直按着左键了；也不像有的数位板，对频繁的控制光标操作却需要保持笔尖悬空。模式切换的 <strong>压力阈值</strong> 是可以通过实验统计获得的，当然用户也可以修改。<strong>压感笔尖和笔式的外形是xPen的关键</strong>；</li><li>对应鼠标的左右键和滚轮，xPen通过压力大小切换为鼠标的移动或拖动；对单击、双击，可以设计笔尖的点击，这跟Phree的思路是差不多的，但它的笔尖就是一个左键，不是连续输出数值（实际是10 bits的1024个等级，或12 bits的4096级）的压力传感器；但只有一个笔尖，右击、滚轮就需要另想办法了，可以在侧面增加右键，而滚轮功能可以用一块 <strong>触摸板</strong> 来实现；也可以定义类似鼠标手势，但需要对操作习惯做出较大的改变；</li><li>如果侧面增加一小块 <strong>触摸板</strong> 来对应鼠标的滚轮的话，其实触摸板也可以识别点击操作对应右击；触摸板的位置既要方便操作，又要避免误触，需要仔细考虑；</li><li>笔的形状是为了适合书写，而且一定要是 <strong>扁的</strong>，不能是 <strong>圆的</strong>，这样才能确定 <strong>前后朝向</strong>，所以最好是前后不对称的，比如横截面做成 <strong>扁的水滴状</strong>；如果横截面做成前后对称的，通过算法来猜哪头是朝前的应该也能实现，或者也可以通过触摸板来感知哪端更靠近手掌。此外，外形设计还要保证有足够的容积，提供内置锂电池的空间。</li></ul><p><img src="/img/phree.jpg" alt="Phree"></p><p><img src="/img/phree-structure.jpg" alt="Phree"></p><p><img src="/img/xpen-shape.jpg" alt="xPen的外形参照"></p><h3 id="其它考虑"><a href="#其它考虑" class="headerlink" title="其它考虑"></a>其它考虑</h3><ul><li>不要再笔尖放上油墨笔芯，因为不能也没必要把油墨书写的内容传到PC，增加这个功能只会增加困惑；</li><li>不要增加激光，同样是不能保证激光点与PC的光标同步；</li><li>不要过分强调手写识别：<ul><li>Windows内置了Digital Ink，配合Office OneNote，可以高效地保存和传输手写内容。书写过程中等待机器识别及修正结果会对用户产生干扰，不如保持手写原样，让人们自己去识别，除非用户选择将其识别为文本；</li><li>突出代替鼠标的功能，才能被普通用户接受，而支持手写则是增值的附加功能。即便单纯的笔状外形，也比鼠标让手腕放松，人体工程学体验更好；</li></ul></li><li>Phree视频中，<ul><li>随时随地书写并不太吸引人：录音，拍照应该是更合适的随时记录想法的手段；</li><li>支持多设备也不太有说服力，手机和触摸平板本身的触控体验应该更好；</li><li>带LCD显示屏，支持语音电话其实也是不太会经常用到的功能，作为卖点不会加分；</li><li>不过，增加麦克风以支持录音应该是比较合适的；</li><li>xPen应定位于能感知多种参数的输入设备，不要集成太多功能；更合适的场景是PC办公，教育，演示等。</li></ul></li><li>姿态传感器的性能：因为人的手移动是比较缓慢的，加速度也不会太大，从而感知角速度的陀螺仪更能反映运动状态。不确定传感器的精度是否能满足要求，但从手机内置的传感器来看还是比较乐观的。</li></ul><h1 id="其它，四年之路"><a href="#其它，四年之路" class="headerlink" title="其它，四年之路"></a>其它，四年之路</h1><p>2013年，我在嘉兴复习备战考研。当时买了一个华为的电视盒子，虽然上面的大部分App都是针对电视遥控器的方向键设计的，但也安装了几个针对触摸屏的普通App，再额外使用一个无线鼠标来操作这些App固然是可以的，但当时就想，有没有可能让遥控器来模拟鼠标操作，结果一搜还真有，就是参考了Wii手柄的，使用陀螺仪的 <strong><a href="http://www.lefant.com.cn/products/%E4%B9%90%E5%B8%86f9-%E7%A9%BA%E4%B8%AD%E9%A3%9E%E9%BC%A0" target="_blank" rel="noopener">飞鼠</a></strong>，买来一个体验一下，虽然可以在空中控制电视屏幕上的光标，但感觉定位不够准确，而且提着胳膊来遥控还是比较累的。为了偷懒，就把飞鼠放在茶几上移动，也能控制光标。于是就有了 <strong>使用姿态传感器的笔式鼠标的想法</strong>，再仔细考虑，就发现不能照搬鼠标按键的设计，于是就想应该使用 <strong>压感笔尖</strong>。<br>想法基本就是这样了，因为在复习，就放在一边了。<br>考研结束后换了带陀螺仪的手机，试验了一下灵敏度，感觉还是足够的，无奈我是个水货，既是编程渣，又不通硬件。后来开始读研，入学不久就真实感受到了自己的差距，毕业基本无望，又想起这个茬，似乎可以申请一个专利来应付毕业，当时确实查过不少专利，庆幸还没有完全一样的想法。找两个老板说了这个想法，不知是我没说清楚或者说的时候没有激情，还是老板不感兴趣，被果断否决了。一个老板还提到已经有类似的产品了，可以让用户像普通的笔那样手写内容，保存起来，然后把内容再传到PC上。我去搜索了一下，感觉最接近他的说法的是Livescribe了（当时还没有Phree）。Livescribe需要在它的专用带特定模式的纸上写字才行，实在不觉得比手机拍照方便多少。<br>再后来jyy师兄给了我一个小Idea，发了一篇C文，结果就转博了……真是自不量力，越走越黑。毕业无望的想法越来越频繁的出现，于是xPen的想法竟成了救命稻草一样的东西，来安慰自己不是没有一点想法也没有，隔一段时间也会看看有没有类似的产品出现，目前最接近的就是Phree了。<br>然而，实际上即便我把它做出来了（当然是不可能做到的），估计对我毕业拿学位也没有什么帮助，毕竟不是本学科的；虽然被老板否决了，其实还是可以申请专利的，而且也相信只要写了申请，基本就能通过，但还是觉得把它写到blog上吧。<br>我要抛开这棵稻草，不要原地打转了，要尽快向前游啊。<br>其实不用看到这篇博客，也应该会有人想到类似的想法的。希望有人能做出这样的产品，像鼠标那样方便亿万的用户。</p><h1 id="罗技的spotlight"><a href="#罗技的spotlight" class="headerlink" title="罗技的spotlight"></a>罗技的spotlight</h1><p>一天晚上（2017-10-15），Wei老师拿来他新买的激光笔给我看，是<a href="https://item.jd.com/4674246.html" target="_blank" rel="noopener">罗技的spotlight</a>，京东卖699元，比Phree便宜多了。他说这个激光笔居然没有激光。我一看，这个不就是没有笔尖的xPen嘛，当然就跟他解释为什么没有激光头！如果一直按着Spotlight最上面那个按键，它就通过内置的3D加速度计和陀螺仪控制屏幕上的光标，相当于一个悬空的无线鼠标，体验了一下，非常平滑流畅，macOS无需安装驱动，Windows 10插上USB接收器还会自动提示安装附加功能驱动（在系统光标上添加一个大黄圈，让光标更显著）。这说明xPen在技术上没有问题了，只要在Spotlight上加一个<strong>笔尖</strong>，不需要用户一直按某个键就可以了！</p><p>Yeah！</p><p>只可惜不是我把它造出来~~</p><p><img src="/img/spotlitght-design.jpg" alt=""></p><p><img src="/img/spotlitght-spec.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一个我四年前的想法，但一直没有实现。所以说，这也是一个“&lt;a href=&quot;https://www.zhihu.com/question/22989105&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;就差一个软件工程师了&lt;/a&gt;”的悲伤的故事（其实还缺一个硬件工程师）。&lt;br&gt;为了清净，把日期改了，手工置底。&lt;/p&gt;
    
    </summary>
    
      <category term="misc" scheme="https://ying-zhang.github.io/categories/misc/"/>
    
    
  </entry>
  
</feed>
